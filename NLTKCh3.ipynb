{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3   Processing Raw Text\n",
    "\n",
    "# The most important source of texts is undoubtedly the Web. It's convenient to have existing text collections to explore, such as the \n",
    "# corpora we saw in the previous chapters. However, you probably have your own text sources in mind, and need to learn how to access \n",
    "# them.\n",
    "\n",
    "# The goal of this chapter is to answer the following questions:\n",
    "\n",
    "# How can we write programs to access text from local files and from the web, in order to get hold of an unlimited range of language \n",
    "# material?\n",
    "# How can we split documents up into individual words and punctuation symbols, so we can carry out the same kinds of analysis we did \n",
    "# with text corpora in earlier chapters?\n",
    "# How can we write programs to produce formatted output and save it in a file?\n",
    "# In order to address these questions, we will be covering key concepts in NLP, including tokenization and stemming. Along the way \n",
    "# you will consolidate your Python knowledge and learn about strings, files, and regular expressions. Since so much text on the web \n",
    "# is in HTML format, we will also see how to dispense with markup.\n",
    "\n",
    "# Note\n",
    "\n",
    "# Important: From this chapter onwards, our program samples will assume you begin your interactive session or your program with the \n",
    "# following import statements:\n",
    "\n",
    "from __future__ import division  # Python 2 users only\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1   Accessing Text from the Web and from Disk\n",
    "\n",
    "# Electronic Books\n",
    "\n",
    "# A small sample of texts from Project Gutenberg appears in the NLTK corpus collection. However, you may be interested in analyzing \n",
    "# other texts from Project Gutenberg. You can browse the catalog of 25,000 free online books at http://www.gutenberg.org/catalog/, \n",
    "# and obtain a URL to an ASCII text file. Although 90% of the texts in Project Gutenberg are in English, it includes material in over \n",
    "# 50 other languages, including Catalan, Chinese, Dutch, Finnish, French, German, Italian, Portuguese and Spanish (with more than 100 \n",
    "# texts each).\n",
    "\n",
    "# Text number 2554 is an English translation of Crime and Punishment, and we can access it as follows.\n",
    "\n",
    "from urllib2 import urlopen\n",
    "# Import urlopen from urllib2 module\n",
    "\n",
    "url = \"http://www.gutenberg.org/files/2554/2554.txt\"\n",
    "# Specify url as this particular text string\n",
    "\n",
    "response = urlopen(url)\n",
    "# what does urlopen do?\n",
    "\n",
    "raw = response.read().decode('utf8')\n",
    "# we decode... I need to understand the unicode stuff.\n",
    "\n",
    "type(raw)\n",
    "# what is the type of the raw string data we read? Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176896"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)\n",
    "# number of characters (including spaces) from this text file from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]\n",
    "# what are the first 75 characters from this text file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: add this revised code to the GitHub issue tracker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variable raw contains a string with 1,176,893 characters. (We can see that it is a string, using type(raw).) This is the raw \n",
    "# content of the book, including many details we are not interested in such as whitespace, line breaks and blank lines. Notice the \\r \n",
    "# and \\n in the opening line of the file, which is how Python displays the special carriage return and line feed characters (the file \n",
    "# must have been created on a Windows machine). For our language processing, we want to break up the string into words and \n",
    "# punctuation, as we saw in 1.. This step is called tokenization, and it produces our familiar structure, a list of words and \n",
    "# punctuation.\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "# word_tokenize converts raw string data into word tokens\n",
    "\n",
    "type(tokens)\n",
    "# Shows that these tokens are placed in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254352"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)\n",
    "# Return the number of word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The',\n",
       " u'Project',\n",
       " u'Gutenberg',\n",
       " u'EBook',\n",
       " u'of',\n",
       " u'Crime',\n",
       " u'and',\n",
       " u'Punishment',\n",
       " u',',\n",
       " u'by']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]\n",
    "# let's return the first 10 words/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that NLTK was needed for tokenization, but not for any of the earlier tasks of opening a URL and reading it into a string. \n",
    "# If we now take the further step of creating an NLTK text from this list, we can carry out all of the other linguistic processing we \n",
    "# saw in 1., along with the regular list operations like slicing:\n",
    "\n",
    "text = nltk.Text(tokens)\n",
    "# Convert tokens list into a format NLTK can understand and process\n",
    "\n",
    "type(text)\n",
    "# Now we have an NLTK text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'CHAPTER',\n",
       " u'I',\n",
       " u'On',\n",
       " u'an',\n",
       " u'exceptionally',\n",
       " u'hot',\n",
       " u'evening',\n",
       " u'early',\n",
       " u'in',\n",
       " u'July',\n",
       " u'a',\n",
       " u'young',\n",
       " u'man',\n",
       " u'came',\n",
       " u'out',\n",
       " u'of',\n",
       " u'the',\n",
       " u'garret',\n",
       " u'in',\n",
       " u'which',\n",
       " u'he',\n",
       " u'lodged',\n",
       " u'in',\n",
       " u'S.',\n",
       " u'Place',\n",
       " u'and',\n",
       " u'walked',\n",
       " u'slowly',\n",
       " u',',\n",
       " u'as',\n",
       " u'though',\n",
       " u'in',\n",
       " u'hesitation',\n",
       " u',',\n",
       " u'towards',\n",
       " u'K.',\n",
       " u'bridge',\n",
       " u'.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1024:1062]\n",
    "# return this subset of words/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; Nikodim Fomitch; young man; Ilya Petrovitch; n't know;\n",
      "Project Gutenberg; Dmitri Prokofitch; Andrey Semyonovitch; Hay Market\n"
     ]
    }
   ],
   "source": [
    "text.collocations()\n",
    "\n",
    "# Remember, \"Collocations are expressions of multiple words which commonly co-occur.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5338"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that Project Gutenberg appears as a collocation. This is because each text downloaded from Project Gutenberg contains a \n",
    "# header with the name of the text, the author, the names of people who scanned and corrected the text, a license, and so on. \n",
    "# Sometimes this information appears in a footer at the end of the file. We cannot reliably detect where the content begins and ends, \n",
    "# and so have to resort to manual inspection of the file, to discover unique strings that mark the beginning and the end, before \n",
    "# trimming raw to be just the content and nothing else:\n",
    "\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157746"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Project Gutenberg's Crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we essentially subset raw to be the \"raw\" content, and no header/metadata.\n",
    "\n",
    "raw = raw[5338:1157743]\n",
    "raw.find(\"PART I\")\n",
    "\n",
    "# The find() and rfind() (\"reverse find\") methods help us get the right index values to use for slicing the string [1]. We overwrite \n",
    "# raw with this slice, so now it begins with \"PART I\" and goes up to (but not including) the phrase that marks the end of the content.\n",
    "\n",
    "# This was our first brush with the reality of the web: texts found on the web may contain unwanted material, and there may not be an \n",
    "# automatic way to remove it. But with a small amount of extra work we can extract the material we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with HTML\n",
    "\n",
    "# Much of the text on the web is in the form of HTML documents. You can use a web browser to save a page as text to a local file, \n",
    "# then access this as described in the section on files below. However, if you're going to do this often, it's easiest to get Python \n",
    "# to do the work directly. The first step is the same as before, using urlopen. For fun we'll pick a BBC News story called Blondes to \n",
    "# die out in 200 years, an urban legend passed along by the BBC as established scientific fact:\n",
    "\n",
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "\n",
    "# Remember, we use urlopen instead of request.urlopen\n",
    "html = urlopen(url).read().decode('utf8')\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'BBC',\n",
       " u'NEWS',\n",
       " u'|',\n",
       " u'Health',\n",
       " u'|',\n",
       " u'Blondes',\n",
       " u\"'to\",\n",
       " u'die',\n",
       " u'out',\n",
       " u'in',\n",
       " u'200',\n",
       " u\"years'\",\n",
       " u'NEWS',\n",
       " u'SPORT',\n",
       " u'WEATHER',\n",
       " u'WORLD',\n",
       " u'SERVICE',\n",
       " u'A-Z',\n",
       " u'INDEX',\n",
       " u'SEARCH',\n",
       " u'You',\n",
       " u'are',\n",
       " u'in',\n",
       " u':',\n",
       " u'Health',\n",
       " u'News',\n",
       " u'Front',\n",
       " u'Page',\n",
       " u'Africa',\n",
       " u'Americas',\n",
       " u'Asia-Pacific',\n",
       " u'Europe',\n",
       " u'Middle',\n",
       " u'East',\n",
       " u'South',\n",
       " u'Asia',\n",
       " u'UK',\n",
       " u'Business',\n",
       " u'Entertainment',\n",
       " u'Science/Nature',\n",
       " u'Technology',\n",
       " u'Health',\n",
       " u'Medical',\n",
       " u'notes',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'-',\n",
       " u'Talking',\n",
       " u'Point',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'-',\n",
       " u'Country',\n",
       " u'Profiles',\n",
       " u'In',\n",
       " u'Depth',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'-',\n",
       " u'Programmes',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'-',\n",
       " u'SERVICES',\n",
       " u'Daily',\n",
       " u'E-mail',\n",
       " u'News',\n",
       " u'Ticker',\n",
       " u'Mobile/PDAs',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'-',\n",
       " u'Text',\n",
       " u'Only',\n",
       " u'Feedback',\n",
       " u'Help',\n",
       " u'EDITIONS',\n",
       " u'Change',\n",
       " u'to',\n",
       " u'UK',\n",
       " u'Friday',\n",
       " u',',\n",
       " u'27',\n",
       " u'September',\n",
       " u',',\n",
       " u'2002',\n",
       " u',',\n",
       " u'11:51',\n",
       " u'GMT',\n",
       " u'12:51',\n",
       " u'UK',\n",
       " u'Blondes',\n",
       " u\"'to\",\n",
       " u'die',\n",
       " u'out',\n",
       " u'in',\n",
       " u'200',\n",
       " u\"years'\",\n",
       " u'Scientists',\n",
       " u'believe',\n",
       " u'the',\n",
       " u'last',\n",
       " u'blondes',\n",
       " u'will',\n",
       " u'be',\n",
       " u'in',\n",
       " u'Finland',\n",
       " u'The',\n",
       " u'last',\n",
       " u'natural',\n",
       " u'blondes',\n",
       " u'will',\n",
       " u'die',\n",
       " u'out',\n",
       " u'within',\n",
       " u'200',\n",
       " u'years',\n",
       " u',',\n",
       " u'scientists',\n",
       " u'believe',\n",
       " u'.',\n",
       " u'A',\n",
       " u'study',\n",
       " u'by',\n",
       " u'experts',\n",
       " u'in',\n",
       " u'Germany',\n",
       " u'suggests',\n",
       " u'people',\n",
       " u'with',\n",
       " u'blonde',\n",
       " u'hair',\n",
       " u'are',\n",
       " u'an',\n",
       " u'endangered',\n",
       " u'species',\n",
       " u'and',\n",
       " u'will',\n",
       " u'become',\n",
       " u'extinct',\n",
       " u'by',\n",
       " u'2202',\n",
       " u'.',\n",
       " u'Researchers',\n",
       " u'predict',\n",
       " u'the',\n",
       " u'last',\n",
       " u'truly',\n",
       " u'natural',\n",
       " u'blonde',\n",
       " u'will',\n",
       " u'be',\n",
       " u'born',\n",
       " u'in',\n",
       " u'Finland',\n",
       " u'-',\n",
       " u'the',\n",
       " u'country',\n",
       " u'with',\n",
       " u'the',\n",
       " u'highest',\n",
       " u'proportion',\n",
       " u'of',\n",
       " u'blondes',\n",
       " u'.',\n",
       " u'The',\n",
       " u'frequency',\n",
       " u'of',\n",
       " u'blondes',\n",
       " u'may',\n",
       " u'drop',\n",
       " u'but',\n",
       " u'they',\n",
       " u'wo',\n",
       " u\"n't\",\n",
       " u'disappear',\n",
       " u'Prof',\n",
       " u'Jonathan',\n",
       " u'Rees',\n",
       " u',',\n",
       " u'University',\n",
       " u'of',\n",
       " u'Edinburgh',\n",
       " u'But',\n",
       " u'they',\n",
       " u'say',\n",
       " u'too',\n",
       " u'few',\n",
       " u'people',\n",
       " u'now',\n",
       " u'carry',\n",
       " u'the',\n",
       " u'gene',\n",
       " u'for',\n",
       " u'blondes',\n",
       " u'to',\n",
       " u'last',\n",
       " u'beyond',\n",
       " u'the',\n",
       " u'next',\n",
       " u'two',\n",
       " u'centuries',\n",
       " u'.',\n",
       " u'The',\n",
       " u'problem',\n",
       " u'is',\n",
       " u'that',\n",
       " u'blonde',\n",
       " u'hair',\n",
       " u'is',\n",
       " u'caused',\n",
       " u'by',\n",
       " u'a',\n",
       " u'recessive',\n",
       " u'gene',\n",
       " u'.',\n",
       " u'In',\n",
       " u'order',\n",
       " u'for',\n",
       " u'a',\n",
       " u'child',\n",
       " u'to',\n",
       " u'have',\n",
       " u'blonde',\n",
       " u'hair',\n",
       " u',',\n",
       " u'it',\n",
       " u'must',\n",
       " u'have',\n",
       " u'the',\n",
       " u'gene',\n",
       " u'on',\n",
       " u'both',\n",
       " u'sides',\n",
       " u'of',\n",
       " u'the',\n",
       " u'family',\n",
       " u'in',\n",
       " u'the',\n",
       " u'grandparents',\n",
       " u\"'\",\n",
       " u'generation',\n",
       " u'.',\n",
       " u'Dyed',\n",
       " u'rivals',\n",
       " u'The',\n",
       " u'researchers',\n",
       " u'also',\n",
       " u'believe',\n",
       " u'that',\n",
       " u'so-called',\n",
       " u'bottle',\n",
       " u'blondes',\n",
       " u'may',\n",
       " u'be',\n",
       " u'to',\n",
       " u'blame',\n",
       " u'for',\n",
       " u'the',\n",
       " u'demise',\n",
       " u'of',\n",
       " u'their',\n",
       " u'natural',\n",
       " u'rivals',\n",
       " u'.',\n",
       " u'They',\n",
       " u'suggest',\n",
       " u'that',\n",
       " u'dyed-blondes',\n",
       " u'are',\n",
       " u'more',\n",
       " u'attractive',\n",
       " u'to',\n",
       " u'men',\n",
       " u'who',\n",
       " u'choose',\n",
       " u'them',\n",
       " u'as',\n",
       " u'partners',\n",
       " u'over',\n",
       " u'true',\n",
       " u'blondes',\n",
       " u'.',\n",
       " u'Bottle-blondes',\n",
       " u'like',\n",
       " u'Ann',\n",
       " u'Widdecombe',\n",
       " u'may',\n",
       " u'be',\n",
       " u'to',\n",
       " u'blame',\n",
       " u'But',\n",
       " u'Jonathan',\n",
       " u'Rees',\n",
       " u',',\n",
       " u'professor',\n",
       " u'of',\n",
       " u'dermatology',\n",
       " u'at',\n",
       " u'the',\n",
       " u'University',\n",
       " u'of',\n",
       " u'Edinburgh',\n",
       " u'said',\n",
       " u'it',\n",
       " u'was',\n",
       " u'unlikely',\n",
       " u'blondes',\n",
       " u'would',\n",
       " u'die',\n",
       " u'out',\n",
       " u'completely',\n",
       " u'.',\n",
       " u'``',\n",
       " u'Genes',\n",
       " u'do',\n",
       " u\"n't\",\n",
       " u'die',\n",
       " u'out',\n",
       " u'unless',\n",
       " u'there',\n",
       " u'is',\n",
       " u'a',\n",
       " u'disadvantage',\n",
       " u'of',\n",
       " u'having',\n",
       " u'that',\n",
       " u'gene',\n",
       " u'or',\n",
       " u'by',\n",
       " u'chance',\n",
       " u'.',\n",
       " u'They',\n",
       " u'do',\n",
       " u\"n't\",\n",
       " u'disappear',\n",
       " u',',\n",
       " u\"''\",\n",
       " u'he',\n",
       " u'told',\n",
       " u'BBC',\n",
       " u'News',\n",
       " u'Online',\n",
       " u'.',\n",
       " u'``',\n",
       " u'The',\n",
       " u'only',\n",
       " u'reason',\n",
       " u'blondes',\n",
       " u'would',\n",
       " u'disappear',\n",
       " u'is',\n",
       " u'if',\n",
       " u'having',\n",
       " u'the',\n",
       " u'gene',\n",
       " u'was',\n",
       " u'a',\n",
       " u'disadvantage',\n",
       " u'and',\n",
       " u'I',\n",
       " u'do',\n",
       " u'not',\n",
       " u'think',\n",
       " u'that',\n",
       " u'is',\n",
       " u'the',\n",
       " u'case',\n",
       " u'.',\n",
       " u'``',\n",
       " u'The',\n",
       " u'frequency',\n",
       " u'of',\n",
       " u'blondes',\n",
       " u'may',\n",
       " u'drop',\n",
       " u'but',\n",
       " u'they',\n",
       " u'wo',\n",
       " u\"n't\",\n",
       " u'disappear',\n",
       " u'.',\n",
       " u\"''\",\n",
       " u'See',\n",
       " u'also',\n",
       " u':',\n",
       " u'28',\n",
       " u'Mar',\n",
       " u'01',\n",
       " u'|',\n",
       " u'Education',\n",
       " u'What',\n",
       " u'is',\n",
       " u'it',\n",
       " u'about',\n",
       " u'blondes',\n",
       " u'?',\n",
       " u'09',\n",
       " u'Apr',\n",
       " u'99',\n",
       " u'|',\n",
       " u'Health',\n",
       " u'Platinum',\n",
       " u'blondes',\n",
       " u'are',\n",
       " u'labelled',\n",
       " u'as',\n",
       " u'dumb',\n",
       " u'17',\n",
       " u'Apr',\n",
       " u'02',\n",
       " u'|',\n",
       " u'Health',\n",
       " u'Hair',\n",
       " u'dye',\n",
       " u'cancer',\n",
       " u'alert',\n",
       " u'Internet',\n",
       " u'links',\n",
       " u':',\n",
       " u'University',\n",
       " u'of',\n",
       " u'Edinburgh',\n",
       " u'The',\n",
       " u'BBC',\n",
       " u'is',\n",
       " u'not',\n",
       " u'responsible',\n",
       " u'for',\n",
       " u'the',\n",
       " u'content',\n",
       " u'of',\n",
       " u'external',\n",
       " u'internet',\n",
       " u'sites',\n",
       " u'Top',\n",
       " u'Health',\n",
       " u'stories',\n",
       " u'now',\n",
       " u':',\n",
       " u'Heart',\n",
       " u'risk',\n",
       " u'link',\n",
       " u'to',\n",
       " u'big',\n",
       " u'families',\n",
       " u'Back',\n",
       " u'pain',\n",
       " u'drug',\n",
       " u\"'may\",\n",
       " u'aid',\n",
       " u\"diabetics'\",\n",
       " u'Congo',\n",
       " u'Ebola',\n",
       " u'outbreak',\n",
       " u'confirmed',\n",
       " u'Vegetables',\n",
       " u'ward',\n",
       " u'off',\n",
       " u\"Alzheimer's\",\n",
       " u'Polio',\n",
       " u'campaign',\n",
       " u'launched',\n",
       " u'in',\n",
       " u'Iraq',\n",
       " u'Gene',\n",
       " u'defect',\n",
       " u'explains',\n",
       " u'high',\n",
       " u'blood',\n",
       " u'pressure',\n",
       " u'Botox',\n",
       " u\"'may\",\n",
       " u'cause',\n",
       " u'new',\n",
       " u\"wrinkles'\",\n",
       " u'Alien',\n",
       " u\"'abductees\",\n",
       " u\"'\",\n",
       " u'show',\n",
       " u'real',\n",
       " u'symptoms',\n",
       " u'Links',\n",
       " u'to',\n",
       " u'more',\n",
       " u'Health',\n",
       " u'stories',\n",
       " u'are',\n",
       " u'at',\n",
       " u'the',\n",
       " u'foot',\n",
       " u'of',\n",
       " u'the',\n",
       " u'page',\n",
       " u'.',\n",
       " u'E-mail',\n",
       " u'this',\n",
       " u'story',\n",
       " u'to',\n",
       " u'a',\n",
       " u'friend',\n",
       " u'Links',\n",
       " u'to',\n",
       " u'more',\n",
       " u'Health',\n",
       " u'stories',\n",
       " u'In',\n",
       " u'This',\n",
       " u'Section',\n",
       " u'Heart',\n",
       " u'risk',\n",
       " u'link',\n",
       " u'to',\n",
       " u'big',\n",
       " u'families',\n",
       " u'Back',\n",
       " u'pain',\n",
       " u'drug',\n",
       " u\"'may\",\n",
       " u'aid',\n",
       " u\"diabetics'\",\n",
       " u'Congo',\n",
       " u'Ebola',\n",
       " u'outbreak',\n",
       " u'confirmed',\n",
       " u'Vegetables',\n",
       " u'ward',\n",
       " u'off',\n",
       " u\"Alzheimer's\",\n",
       " u'Polio',\n",
       " u'campaign',\n",
       " u'launched',\n",
       " u'in',\n",
       " u'Iraq',\n",
       " u'Gene',\n",
       " u'defect',\n",
       " u'explains',\n",
       " u'high',\n",
       " u'blood',\n",
       " u'pressure',\n",
       " u'Botox',\n",
       " u\"'may\",\n",
       " u'cause',\n",
       " u'new',\n",
       " u\"wrinkles'\",\n",
       " u'Alien',\n",
       " u\"'abductees\",\n",
       " u\"'\",\n",
       " u'show',\n",
       " u'real',\n",
       " u'symptoms',\n",
       " u'How',\n",
       " u'sperm',\n",
       " u'wriggle',\n",
       " u'Bollywood',\n",
       " u'told',\n",
       " u'to',\n",
       " u'stub',\n",
       " u'it',\n",
       " u'out',\n",
       " u'Fears',\n",
       " u'over',\n",
       " u'tuna',\n",
       " u'health',\n",
       " u'risk',\n",
       " u'to',\n",
       " u'babies',\n",
       " u'Public',\n",
       " u'can',\n",
       " u'be',\n",
       " u'taught',\n",
       " u'to',\n",
       " u'spot',\n",
       " u'strokes',\n",
       " u'^^',\n",
       " u'Back',\n",
       " u'to',\n",
       " u'top',\n",
       " u'News',\n",
       " u'Front',\n",
       " u'Page',\n",
       " u'|',\n",
       " u'Africa',\n",
       " u'|',\n",
       " u'Americas',\n",
       " u'|',\n",
       " u'Asia-Pacific',\n",
       " u'|',\n",
       " u'Europe',\n",
       " u'|',\n",
       " u'Middle',\n",
       " u'East',\n",
       " u'|',\n",
       " u'South',\n",
       " u'Asia',\n",
       " u'|',\n",
       " u'UK',\n",
       " u'|',\n",
       " u'Business',\n",
       " u'|',\n",
       " u'Entertainment',\n",
       " u'|',\n",
       " u'Science/Nature',\n",
       " u'|',\n",
       " u'Technology',\n",
       " u'|',\n",
       " u'Health',\n",
       " u'|',\n",
       " u'Talking',\n",
       " u'Point',\n",
       " u'|',\n",
       " u'Country',\n",
       " u'Profiles',\n",
       " u'|',\n",
       " u'In',\n",
       " u'Depth',\n",
       " u'|',\n",
       " u'Programmes',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'To',\n",
       " u'BBC',\n",
       " u'Sport',\n",
       " u'>',\n",
       " u'>',\n",
       " u'|',\n",
       " u'To',\n",
       " u'BBC',\n",
       " u'Weather',\n",
       " u'>',\n",
       " u'>',\n",
       " u'|',\n",
       " u'To',\n",
       " u'BBC',\n",
       " u'World',\n",
       " u'Service',\n",
       " u'>',\n",
       " u'>',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'--',\n",
       " u'\\xa9',\n",
       " u'MMIII',\n",
       " u'|',\n",
       " u'News',\n",
       " u'Sources',\n",
       " u'|',\n",
       " u'Privacy',\n",
       " u'<',\n",
       " u'!',\n",
       " u'--',\n",
       " u'var',\n",
       " u'pCid=',\n",
       " u\"''\",\n",
       " u'uk_bbc_0',\n",
       " u\"''\",\n",
       " u';',\n",
       " u'var',\n",
       " u'w0=1',\n",
       " u';',\n",
       " u'var',\n",
       " u'refR=escape',\n",
       " u'(',\n",
       " u'document.referrer',\n",
       " u')',\n",
       " u';',\n",
       " u'if',\n",
       " u'(',\n",
       " u'refR.length',\n",
       " u'>',\n",
       " u'=252',\n",
       " u')',\n",
       " u'refR=refR.substring',\n",
       " u'(',\n",
       " u'0,252',\n",
       " u')',\n",
       " u'+',\n",
       " u\"''\",\n",
       " u'...',\n",
       " u\"''\",\n",
       " u';',\n",
       " u'//',\n",
       " u'--',\n",
       " u'>',\n",
       " u'<',\n",
       " u'!',\n",
       " u'--',\n",
       " u'var',\n",
       " u'w0=0',\n",
       " u';',\n",
       " u'//',\n",
       " u'--',\n",
       " u'>',\n",
       " u'<',\n",
       " u'!',\n",
       " u'--',\n",
       " u'if',\n",
       " u'(',\n",
       " u'w0',\n",
       " u')',\n",
       " u'{',\n",
       " u'var',\n",
       " u'imgN=',\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'img',\n",
       " u'src=',\n",
       " u\"''\",\n",
       " u'http',\n",
       " u':',\n",
       " u'//server-uk.imrworldwide.com/cgi-bin/count',\n",
       " u'?',\n",
       " u\"ref='+\",\n",
       " u'refR+',\n",
       " u\"'\",\n",
       " u'&',\n",
       " u\"cid='+pCid+\",\n",
       " u\"'\",\n",
       " u\"''\",\n",
       " u'width=1',\n",
       " u'height=1',\n",
       " u'>',\n",
       " u\"'\",\n",
       " u';',\n",
       " u'if',\n",
       " u'(',\n",
       " u'navigator.userAgent.indexOf',\n",
       " u'(',\n",
       " u\"'Mac\",\n",
       " u\"'\",\n",
       " u')',\n",
       " u'!',\n",
       " u'=-1',\n",
       " u')',\n",
       " u'{',\n",
       " u'document.write',\n",
       " u'(',\n",
       " u'imgN',\n",
       " u')',\n",
       " u';',\n",
       " u'}',\n",
       " u'else',\n",
       " u'{',\n",
       " u'document.write',\n",
       " u'(',\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'applet',\n",
       " u'code=',\n",
       " u\"''\",\n",
       " u'Measure.class',\n",
       " u\"''\",\n",
       " u\"'+\",\n",
       " u\"'codebase=\",\n",
       " u\"''\",\n",
       " u'http',\n",
       " u':',\n",
       " u'//server-uk.imrworldwide.com/',\n",
       " u\"''\",\n",
       " u\"'+'width=1\",\n",
       " u'height=2',\n",
       " u'>',\n",
       " u\"'+\",\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'param',\n",
       " u'name=',\n",
       " u\"''\",\n",
       " u'ref',\n",
       " u\"''\",\n",
       " u'value=',\n",
       " u\"''\",\n",
       " u\"'+refR+\",\n",
       " u\"'\",\n",
       " u\"''\",\n",
       " u'>',\n",
       " u\"'+\",\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'param',\n",
       " u'name=',\n",
       " u\"''\",\n",
       " u'cid',\n",
       " u\"''\",\n",
       " u'value=',\n",
       " u\"''\",\n",
       " u\"'+pCid+\",\n",
       " u\"'\",\n",
       " u\"''\",\n",
       " u'>',\n",
       " u'<',\n",
       " u'textflow',\n",
       " u'>',\n",
       " u\"'+imgN+\",\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'/textflow',\n",
       " u'>',\n",
       " u'<',\n",
       " u'/applet',\n",
       " u'>',\n",
       " u\"'\",\n",
       " u')',\n",
       " u';',\n",
       " u'}',\n",
       " u'}',\n",
       " u'document.write',\n",
       " u'(',\n",
       " u'``',\n",
       " u'<',\n",
       " u'COMMENT',\n",
       " u'>',\n",
       " u\"''\",\n",
       " u')',\n",
       " u';',\n",
       " u'//',\n",
       " u'--',\n",
       " u'>',\n",
       " u'var',\n",
       " u'si',\n",
       " u'=',\n",
       " u'document.location+',\n",
       " u\"''\",\n",
       " u\"''\",\n",
       " u';',\n",
       " u'var',\n",
       " u'tsi',\n",
       " u'=',\n",
       " u'si.replace',\n",
       " u'(',\n",
       " u'``',\n",
       " u'.stm',\n",
       " u\"''\",\n",
       " u',',\n",
       " u\"''\",\n",
       " u\"''\",\n",
       " u')',\n",
       " u'.substr',\n",
       " u'(',\n",
       " u'si.length-11',\n",
       " u',',\n",
       " u'si.length',\n",
       " u')',\n",
       " u';',\n",
       " u'if',\n",
       " u'(',\n",
       " u'!',\n",
       " u'tsi.match',\n",
       " u'(',\n",
       " u'/\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d/',\n",
       " u')',\n",
       " u')',\n",
       " u'{',\n",
       " u'tsi',\n",
       " u'=',\n",
       " u'0',\n",
       " u';',\n",
       " u'}',\n",
       " u'document.write',\n",
       " u'(',\n",
       " u\"'\",\n",
       " u'<',\n",
       " u'img',\n",
       " u'src=',\n",
       " u\"''\",\n",
       " u'http',\n",
       " u':',\n",
       " u'//stats.bbc.co.uk/o.gif',\n",
       " u'?',\n",
       " u'~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~',\n",
       " u\"'\",\n",
       " u'+',\n",
       " u'tsi',\n",
       " u'+',\n",
       " u\"'~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~\",\n",
       " u'(',\n",
       " u'none',\n",
       " u')',\n",
       " u'~RS~a~RS~International~RS~q~RS~~RS~z~RS~28~RS~',\n",
       " u\"''\",\n",
       " u'>',\n",
       " u\"'\",\n",
       " u')',\n",
       " u';']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can type print(html) to see the HTML content in all its glory, including meta tags, an image map, JavaScript, forms, and tables.\n",
    "\n",
    "# To get text out of HTML we will use a Python library called BeautifulSoup, available from \n",
    "# http://www.crummy.com/software/BeautifulSoup/:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, \"lxml\").get_text() # Note: added ,\"lxml\"\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "# This still contains unwanted material concerning site navigation and related stories. With some trial and error you can find the \n",
    "# start and end indexes of the content and select the tokens of interest, and initialize a text as before.\n",
    "\n",
    "tokens = tokens[110:390]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Processing Search Engine Results\n",
    "\n",
    "# The web can be thought of as a huge corpus of unannotated text. Web search engines provide an efficient means of searching this large \n",
    "# quantity of text for relevant linguistic examples. The main advantage of search engines is size: since you are searching such a large \n",
    "# set of documents, you are more likely to find any linguistic pattern you are interested in. Furthermore, you can make use of very \n",
    "# specific patterns, which would only match one or two examples on a smaller example, but which might match tens of thousands of \n",
    "# examples when run on the web. A second advantage of web search engines is that they are very easy to use. Thus, they provide a very \n",
    "# convenient tool for quickly checking a theory, to see if it is reasonable.\n",
    "\n",
    "# Unfortunately, search engines have some significant shortcomings. First, the allowable range of search patterns is severely \n",
    "# restricted. Unlike local corpora, where you write programs to search for arbitrarily complex patterns, search engines generally only \n",
    "# allow you to search for individual words or strings of words, sometimes with wildcards. Second, search engines give inconsistent \n",
    "# results, and can give widely different figures when used at different times or in different geographical regions. When content has \n",
    "# been duplicated across multiple sites, search results may be boosted. Finally, the markup in the result returned by a search engine \n",
    "# may change unpredictably, breaking any pattern-based method of locating particular content (a problem which is ameliorated by the use \n",
    "# of search engine APIs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named feedparser",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3bc8d023a026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# Universal Feed Parser, available from https://pypi.python.org/pypi/feedparser, we can access the content of a blog, as shown below:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;31m# I typed the following at the Windows Command prompt: \"pip install feedparser\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named feedparser"
     ]
    }
   ],
   "source": [
    "# Processing RSS Feeds\n",
    "\n",
    "# The blogosphere is an important source of text, in both formal and informal registers. With the help of a Python library called the \n",
    "# Universal Feed Parser, available from https://pypi.python.org/pypi/feedparser, we can access the content of a blog, as shown below:\n",
    "\n",
    "import feedparser\n",
    "# I typed the following at the Windows Command prompt: \"pip install feedparser\"\n",
    "\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post = llog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(content).get_text()\n",
    "word_tokenize(raw)\n",
    "\n",
    "# With some further work, we can write programs to create a small corpus of blog posts, and use this as the basis for our NLP work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading Local Files\n",
    "\n",
    "# In order to read a local file, we need to use Python's built-in open() function, followed by the read() method. Suppose you have a \n",
    "# file document.txt, you can load its contents like this:\n",
    "\n",
    "# first create a document.txt in c:\\cgraph\n",
    "\n",
    "f = open('document.txt')\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Causal Extractor Oct 2015.ipynb',\n",
       " 'data.csv',\n",
       " 'data_big.csv',\n",
       " 'data_original.csv',\n",
       " 'document.txt',\n",
       " 'NLTK Book Notes.docx',\n",
       " 'NLTKCh1.ipynb',\n",
       " 'NLTKCh2.ipynb',\n",
       " 'NLTKCh3.ipynb',\n",
       " 'NLTKCh4.ipynb',\n",
       " \"NLTKCh5 (Bob-HP's conflicted copy 2015-08-30).ipynb\",\n",
       " 'NLTKCh5.ipynb',\n",
       " 'NLTKCh6.ipynb',\n",
       " \"NLTKCh7 (Bob-HP's conflicted copy 2015-08-30).ipynb\",\n",
       " 'NLTKCh7.ipynb',\n",
       " 'Simple_Causal_Extractor.ipynb',\n",
       " 't2.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check that the file that you are trying to open is really in the right directory, use IDLE's Open command in the File menu; this\n",
    "# will display a list of all the files in the directory where IDLE is running. An alternative is to examine the current directory \n",
    "# from within Python:\n",
    "\n",
    "import os\n",
    "os.listdir('.')\n",
    "\n",
    "# Note, I can use this in the context of my Migraine Dropbox folders, etc. Very useful. Also reference this in Learning Python book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another possible problem you might have encountered when accessing a text file is the newline conventions, which are different for \n",
    "# different operating systems. The built-in open() function has a second parameter for controlling how the file is opened: \n",
    "# open('document.txt', 'rU') — 'r' means to open the file for reading (the default), and 'U' stands for \"Universal\", which lets us \n",
    "# ignore the different conventions used for marking newlines.\n",
    "\n",
    "# Assuming that you can open the file, there are several methods for reading it. The read() method creates a string with the contents\n",
    "# of the entire file:\n",
    "\n",
    "f.read()\n",
    "\n",
    "# Recall that the '\\n' characters are newlines; this is equivalent to pressing Enter on a keyboard and starting a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample document for the NLTK Book, Chapter 3.\n",
      "I am so excited to work in NLTK and with NLP.\n",
      "In no time, I will be a super star!\n"
     ]
    }
   ],
   "source": [
    "# We can also read a file one line at a time using a for loop:\n",
    "\n",
    "f = open('document.txt', 'rU')\n",
    "for line in f:\n",
    "    print(line.strip())\n",
    "    \n",
    "# Here we use the strip() method to remove the newline character at the end of the input line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLTK's corpus files can also be accessed using these methods. We simply have to use nltk.data.find() to get the filename for any \n",
    "# corpus item. Then we can open and read it in the way we just demonstrated above:\n",
    "\n",
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "raw = open(path, 'rU').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text: Bob\n"
     ]
    }
   ],
   "source": [
    "# Extracting Text from PDF, MSWord and other Binary Formats\n",
    "\n",
    "# ASCII text and HTML text are human readable formats. Text often comes in binary formats — like PDF and MSWord — that can only be \n",
    "# opened using specialized software. Third-party libraries such as pypdf and pywin32 provide access to these formats. Extracting \n",
    "# text from multi-column documents is particularly challenging. For once-off conversion of a few documents, it is simpler to open the \n",
    "# document with a suitable application, then save it as text to your local drive, and access it as described below. If the document \n",
    "# is already on the web, you can enter its URL in Google's search box. The search result often includes a link to an HTML version of \n",
    "# the document, which you can save as text.\n",
    "\n",
    "# Capturing User Input\n",
    "\n",
    "# Sometimes we want to capture the text that a user inputs when she is interacting with our program. To prompt the user to type a \n",
    "# line of input, call the Python function input(). After saving the input to a variable, we can manipulate it just as we have done \n",
    "# for other strings.\n",
    "\n",
    "s = raw_input(\"Enter some text: \")\n",
    "\n",
    "# For some reason, the input statement does not work!\n",
    "\n",
    "# Note: I need to use raw_input() instead of input() in Python. This was mentioned earlier in NLTK book as well.\n",
    "# Note: input works for Python 3. For Python 2, I need to use raw_input...\n",
    "# Update NLTK folks with this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You typed', 1, 'words.')\n"
     ]
    }
   ],
   "source": [
    "print(\"You typed\", len(word_tokenize(s)), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The NLP Pipeline\n",
    "# 3.1 summarizes what we have covered in this section, including the process of building a vocabulary that we saw in 1.. \n",
    "# (One step, normalization, will be discussed in 3.6.)\n",
    "\n",
    "# Figure 3.1: The Processing Pipeline: We open a URL and read its HTML content, remove the markup and select a slice of characters; \n",
    "# this is then tokenized and optionally converted into an nltk.Text object; we can also lowercase all the words and extract the \n",
    "# vocabulary.\n",
    "\n",
    "# There's a lot going on in this pipeline. To understand it properly, it helps to be clear about the type of each variable that it \n",
    "# mentions. We find out the type of any Python object x using type(x), e.g. type(1) is <int> since 1 is an integer.\n",
    "\n",
    "# When we load the contents of a URL or file, and when we strip out HTML markup, we are dealing with strings, Python's <str> data \n",
    "# type. (We will learn more about strings in 3.2):\n",
    "\n",
    "# Remember I created document.txt\n",
    "raw = open('document.txt').read()\n",
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "['This', 'is', 'a', 'sample', 'document', 'for', 'the', 'NLTK', 'Book', ',', 'Chapter', '3', '.', 'I', 'am', 'so', 'excited', 'to', 'work', 'in', 'NLTK', 'and', 'with', 'NLP', '.', 'In', 'no', 'time', ',', 'I', 'will', 'be', 'a', 'super', 'star', '!']\n"
     ]
    }
   ],
   "source": [
    "# When we tokenize a string we produce a list (of words), and this is Python's <list> type. Normalizing and sorting lists produces \n",
    "# other lists:\n",
    "\n",
    "# Note that word_tokenize is from the NLTK library (as imported above)\n",
    "tokens = word_tokenize(raw)\n",
    "\n",
    "print type(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "['this', 'is', 'a', 'sample', 'document', 'for', 'the', 'nltk', 'book', ',', 'chapter', '3', '.', 'i', 'am', 'so', 'excited', 'to', 'work', 'in', 'nltk', 'and', 'with', 'nlp', '.', 'in', 'no', 'time', ',', 'i', 'will', 'be', 'a', 'super', 'star', '!']\n"
     ]
    }
   ],
   "source": [
    "# Here we make all tokens lower case and turn into a new list words\n",
    "\n",
    "words = [w.lower() for w in tokens]\n",
    "print(type(words))\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "['!', ',', '.', '3', 'a', 'am', 'and', 'be', 'book', 'chapter', 'document', 'excited', 'for', 'i', 'in', 'is', 'nlp', 'nltk', 'no', 'sample', 'so', 'star', 'super', 'the', 'this', 'time', 'to', 'will', 'with', 'work']\n"
     ]
    }
   ],
   "source": [
    "# We take our lower case words, apply set (to get the \"set\" of words or vocabulary)\n",
    "# Then we sort it and save to a new variable, vocab\n",
    "\n",
    "vocab = sorted(set(words))\n",
    "print(type(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', ',', '.', '3', 'a', 'am', 'and', 'be', 'book', 'chapter', 'document', 'excited', 'for', 'i', 'in', 'is', 'nlp', 'nltk', 'no', 'sample', 'so', 'star', 'super', 'the', 'this', 'time', 'to', 'will', 'with', 'work', 'blog']\n"
     ]
    }
   ],
   "source": [
    "# The type of an object determines what operations you can perform on it. So, for example, we can append to a list but not to a \n",
    "# string:\n",
    "\n",
    "vocab.append('blog')\n",
    "print (vocab)\n",
    "\n",
    "# note, every time I rerun this code, I add \"blog\" to the end of it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-56663587abea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'blog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "raw.append('blog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample document for the NLTK Book, Chapter 3.\n",
      "I am so excited to work in NLTK and with NLP.\n",
      "In no time, I will be a super star! blog\n"
     ]
    }
   ],
   "source": [
    "# Above is an error... HOwever, I could do the following?\n",
    "\n",
    "raw = raw + \" blog\"\n",
    "print (raw)\n",
    "\n",
    "# Yay! I can..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'list' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-89cfbc3e9c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;31m# but we cannot concatenate a string to a list...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbeatles\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'list' objects"
     ]
    }
   ],
   "source": [
    "# Similarly, we can concatenate strings with strings, and lists with lists, but we cannot concatenate strings with lists:\n",
    "\n",
    "# query is a string\n",
    "query = 'Who knows?'\n",
    "\n",
    "# beatles is a list\n",
    "\n",
    "beatles = ['john', 'paul', 'george', 'ringo']\n",
    "\n",
    "# but we cannot concatenate a string to a list...\n",
    "query + beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john', 'paul', 'george', 'ringo', 'Who knows?']\n"
     ]
    }
   ],
   "source": [
    "# But, in my estimation, we could append the string to the list as follows:\n",
    "\n",
    "beatles.append(query)\n",
    "print (beatles)\n",
    "\n",
    "# yes, this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2   Strings: Text Processing at the Lowest Level\n",
    "\n",
    "# It's time to examine a fundamental data type that we've been studiously avoiding so far. In earlier chapters we focused on a text as \n",
    "# a list of words. We didn't look too closely at words and how they are handled in the programming language. By using NLTK's corpus \n",
    "# interface we were able to ignore the files that these texts had come from. The contents of a word, and of a file, are represented \n",
    "# by programming languages as a fundamental data type known as a string. In this section we explore strings in detail, and show the \n",
    "# connection between strings, words, texts and files.\n",
    "\n",
    "# Basic Operations with Strings\n",
    "\n",
    "# Strings are specified using single quotes [1] or double quotes [2], as shown below. If a string contains a single quote, we must\n",
    "# backslash-escape the quote [3] so Python knows a literal quote character is intended, or else put the string in double quotes [2]. \n",
    "# Otherwise, the quote inside the string [4] will be interpreted as a close quote, and the Python interpreter will report a syntax \n",
    "# error:\n",
    "\n",
    "monty = 'Monty Python'\n",
    "monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circus = \"Monty Python's Flying Circus\"\n",
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circus = 'Monty Python\\'s Flying Circus'\n",
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-af18724384f6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-af18724384f6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    circus = 'Monty Python's Flying Circus'\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "circus = 'Monty Python's Flying Circus'\n",
    "\n",
    "# Note: this gives us an error because it interpreted the second single quote as the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "# Sometimes strings go over several lines. Python provides us with various ways of entering them. In the next example, a sequence of \n",
    "# two strings is joined into a single string. We need to use backslash [1] or parentheses [2] so that the interpreter knows that the \n",
    "# statement is not complete after the first line.\n",
    "\n",
    "couplet = \"Shall I compare thee to a Summer's day?\"\\\n",
    "           \"Thou are more lovely and more temperate:\"\n",
    "print couplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "couplet = (\"Rough winds do shake the darling buds of May,\"\n",
    "           \"And Summer's lease hath all too short a date:\")\n",
    "print couplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?\n",
      "Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "# Unfortunately the above methods do not give us a newline between the two lines of the sonnet. Instead, we can use a triple-quoted \n",
    "# string as follows:\n",
    "\n",
    "couplet = \"\"\"Shall I compare thee to a Summer's day?\n",
    "Thou are more lovely and more temperate:\"\"\"\n",
    "print(couplet)\n",
    "\n",
    "# Note here that the second line is determined literally by how it is types from the leftmost space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,\n",
      "And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "couplet = '''Rough winds do shake the darling buds of May,\n",
    "And Summer's lease hath all too short a date:'''\n",
    "print(couplet)\n",
    "# This does the same thing. It does not matter whether this is single or double quotes, just as long as there are 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we can define strings, we can try some simple operations on them. First let's look at the + operation, known as \n",
    "# concatenation [1]. It produces a new string that is a copy of the two original strings pasted together end-to-end. Notice that \n",
    "# concatenation doesn't do anything clever like insert a space between the words. We can even multiply strings [2]:\n",
    "\n",
    "'very' + 'very' + 'very'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9449c26ae470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m# subtraction or division with strings:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;34m'very'\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# We've seen that the addition and multiplication operations apply to strings, not just numbers. However, note that we cannot use \n",
    "# subtraction or division with strings:\n",
    "\n",
    "'very' - 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-5ecc12bf7cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;34m'very'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "'very' / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n"
     ]
    }
   ],
   "source": [
    "# These error messages are another example of Python telling us that we have got our data types in a muddle. In the first case, we are \n",
    "# told that the operation of subtraction (i.e., -) cannot apply to objects of type str (strings), while in the second, we are told \n",
    "# that division cannot take str and int as its two operands.\n",
    "\n",
    "# Printing Strings\n",
    "\n",
    "# So far, when we have wanted to look at the contents of a variable or see the result of a calculation, we have just typed the \n",
    "# variable name into the interpreter. We can also see the contents of a variable using the print statement:\n",
    "\n",
    "print(monty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty PythonHoly Grail\n"
     ]
    }
   ],
   "source": [
    "# Notice that there are no quotation marks this time. When we inspect a variable by typing its name in the interpreter, the \n",
    "# interpreter prints the Python representation of its value. Since it's a string, the result is quoted. However, when we tell the \n",
    "# interpreter to print the contents of the variable, we don't see quotation characters since there are none inside the string.\n",
    "\n",
    "# The print statement allows us to display more than one item on a line in various ways, as shown below:\n",
    "\n",
    "grail = 'Holy Grail'\n",
    "print(monty + grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Monty Python', 'Holy Grail')\n"
     ]
    }
   ],
   "source": [
    "print(monty, grail)\n",
    "# Here, it looks like it creates a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Monty Python', 'and the', 'Holy Grail')\n"
     ]
    }
   ],
   "source": [
    "print(monty, \"and the\", grail)\n",
    "# Again, we get another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Individual Characters\n",
    "\n",
    "# As we saw in 2 for lists, strings are indexed, starting from zero. When we index a string, we get one of its characters \n",
    "# (or letters). A single character is nothing special — it's just a string of length 1.\n",
    "\n",
    "# first element\n",
    "monty[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fourth element\n",
    "monty[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sixth element\n",
    "monty[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2294e35d6957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# As with lists, if we try to access an index that is outside of the string we get an error:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmonty\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# As with lists, if we try to access an index that is outside of the string we get an error:\n",
    "\n",
    "monty[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again as with lists, we can use negative indexes for strings, where -1 is the index of the last character [1]. Positive and \n",
    "# negative indexes give us two ways to refer to any position in a string. In this case, when the string had a length of 12, indexes \n",
    "# 5 and -7 both refer to the same character (a space). (Notice that 5 = len(monty) - 7.)\n",
    "\n",
    "# Access last character\n",
    "monty[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c o l o r l e s s   g r e e n   i d e a s   s l e e p   f u r i o u s l y\n"
     ]
    }
   ],
   "source": [
    "# We can write for loops to iterate over the characters in strings. This print function includes the \n",
    "# optional end=' ' parameter, which is how we tell Python to print a space instead of a newline at the end.\n",
    "\n",
    "sent = 'colorless green ideas sleep furiously'\n",
    "for char in sent:\n",
    "    print char,\n",
    "# example from the book doesn't work here. It does print (char, end=' ')\n",
    "# In Python 2.X, what I did above is fine. I got this from Learning Python (5th ed) page 201."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'e', 117092), (u't', 87996), (u'a', 77916), (u'o', 69326), (u'n', 65617)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can count individual characters as well. We should ignore the case distinction by normalizing \n",
    "# everything to lowercase, and filter out non-alphabetic characters:\n",
    "\n",
    "# import gutenberg from nltk.corpus - reference it as gutenberg\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# extract raw string data\n",
    "raw = gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# generate frequency distribution after we Loop through every alphabet character, and turn it into \n",
    "# lowercase\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "\n",
    "# Find most common characters represented in Moby Dick.\n",
    "fdist.most_common(5)\n",
    "\n",
    "# It happens to be 'e', 't', 'a', 'o', and 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'e',\n",
       " u't',\n",
       " u'a',\n",
       " u'o',\n",
       " u'n',\n",
       " u'i',\n",
       " u's',\n",
       " u'h',\n",
       " u'r',\n",
       " u'l',\n",
       " u'd',\n",
       " u'u',\n",
       " u'm',\n",
       " u'c',\n",
       " u'w',\n",
       " u'f',\n",
       " u'g',\n",
       " u'p',\n",
       " u'b',\n",
       " u'y',\n",
       " u'v',\n",
       " u'k',\n",
       " u'q',\n",
       " u'j',\n",
       " u'x',\n",
       " u'z']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for (char, count) in fdist.most_common()]\n",
    "\n",
    "# This gives us the letters of the alphabet, with the most frequently occurring letters listed first \n",
    "# (this is quite complicated and we'll explain it more carefully below). You might like to visualize \n",
    "# the distribution using fdist.plot(). The relative character frequencies of a text can be used in \n",
    "# automatically identifying the language of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pyth'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing Substrings\n",
    "# Figure 3.2: String Slicing: The string \"Monty Python\" is shown along with its positive and negative \n",
    "# indexes; two substrings are selected using \"slice\" notation. The slice [m,n] contains the characters \n",
    "# from position m through n-1.\n",
    "\n",
    "# A substring is any continuous section of a string that we want to pull out for further processing. We \n",
    "# can easily access substrings using the same slice notation we used for lists (see 3.2). For example, \n",
    "# the following code accesses the substring starting at index 6, up to (but not including) index 10:\n",
    "\n",
    "monty[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we see the characters are 'P', 'y', 't', and 'h' which correspond to monty[6] ... monty[9] but \n",
    "# not monty[10]. This is because a slice starts at the first index but finishes one before the end index.\n",
    "\n",
    "# We can also slice with negative indexes — the same basic rule of starting from the start index and \n",
    "# stopping one before the end index applies; here we stop before the space character.\n",
    "\n",
    "monty[-12:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As with list slices, if we omit the first value, the substring begins at the start of the string. If \n",
    "# we omit the second value, the substring continues to the end of the string:\n",
    "monty[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We test if a string contains a particular substring using the in operator, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found \"thing\"\n"
     ]
    }
   ],
   "source": [
    "phrase = 'And now for something completely different'\n",
    "if 'thing' in phrase:\n",
    "    print('found \"thing\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also find the position of a substring within a string, using find():\n",
    "monty.find('Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More operations on strings\n",
    "\n",
    "# Python has comprehensive support for processing strings. A summary, including some operations we \n",
    "# haven't seen yet, is shown in 3.2. For more information on strings, type help(str) at the Python prompt.\n",
    "\n",
    "# Table 3.2:\n",
    "# Useful String Methods: operations on strings in addition to the string tests shown in 4.2; all methods \n",
    "# produce a new string or list\n",
    "\n",
    "# The Difference between Lists and Strings\n",
    "\n",
    "# Strings and lists are both kinds of sequence. We can pull them apart by indexing and slicing them, and \n",
    "# we can join them together by concatenating them. However, we cannot join strings and lists:\n",
    "\n",
    "query = 'Who knows?'\n",
    "beatles = ['John', 'Paul', 'George', 'Ringo']\n",
    "query[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wh'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Who knows? I don't\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query + \" I don't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-fa447bb3f680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeatles\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Brian'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "beatles + 'Brian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul', 'George', 'Ringo', 'Brian', 'Bob']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles + ['Brian', 'Bob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul', 'George', 'Ringo', 'Brian']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles + ['Brian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John Lennon', 'Paul', 'George']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we open a file for reading into a Python program, we get a string corresponding to the contents of\n",
    "# the whole file. If we use a for loop to process the elements of this string, all we can pick out are the \n",
    "# individual characters — we don't get to choose the granularity. By contrast, the elements of a list can \n",
    "# be as big or small as we like: for example, they could be paragraphs, sentences, phrases, words, \n",
    "# characters. So lists have the advantage that we can be flexible about the elements they contain, and \n",
    "# correspondingly flexible about any downstream processing. Consequently, one of the first things we are \n",
    "# likely to do in a piece of NLP code is tokenize a string into a list of strings (3.7). Conversely, when \n",
    "# we want to write our results to a file, or to a terminal, we will usually format them as a string (3.9).\n",
    "\n",
    "# Lists and strings do not have exactly the same functionality. Lists have the added power that you can \n",
    "# change their elements:\n",
    "\n",
    "beatles[0] = \"John Lennon\"\n",
    "del beatles[-1]\n",
    "beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-ef5d4bd908a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m# we get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'F'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m# This is because strings are immutable — you can't change a string once you have created it. However,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# On the other hand if we try to do that with a string — changing the 0th character in query to 'F' — \n",
    "# we get:\n",
    "\n",
    "query[0] = 'F'\n",
    "\n",
    "# This is because strings are immutable — you can't change a string once you have created it. However, \n",
    "# lists are mutable, and their contents can be modified at any time. As a result, lists support \n",
    "# operations that modify the original value rather than producing a new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3.3 Text Processing with Unicode\n",
    "\n",
    "# Our programs will often need to deal with different languages, and different character sets. The concept\n",
    "# of \"plain text\" is a fiction. If you live in the English-speaking world you probably use ASCII, possibly \n",
    "# without realizing it. If you live in Europe you might use one of the extended Latin character sets, \n",
    "# containing such characters as \"ø\" for Danish and Norwegian, \"ő\" for Hungarian, \"ñ\" for Spanish and \n",
    "# Breton, and \"ň\" for Czech and Slovak. In this section, we will give an overview of how to use Unicode \n",
    "# for processing texts that use non-ASCII character sets.\n",
    "\n",
    "# What is Unicode?\n",
    "\n",
    "# Unicode supports over a million characters. Each character is assigned a number, called a code point. \n",
    "# In Python, code points are written in the form \\uXXXX, where XXXX is the number in 4-digit hexadecimal \n",
    "# form.\n",
    "\n",
    "# Within a program, we can manipulate Unicode strings just like normal strings. However, when Unicode \n",
    "# characters are stored in files or displayed on a terminal, they must be encoded as a stream of bytes. \n",
    "# Some encodings (such as ASCII and Latin-2) use a single byte per code point, so they can only support \n",
    "# a small subset of Unicode, enough for a single language. Other encodings (such as UTF-8) use multiple \n",
    "# bytes and can represent the full range of Unicode characters.\n",
    "\n",
    "# Text in files will be in a particular encoding, so we need some mechanism for translating it into \n",
    "# Unicode — translation into Unicode is called decoding. Conversely, to write out Unicode to a file or a \n",
    "# terminal, we first need to translate it into a suitable encoding — this translation out of Unicode is \n",
    "# called encoding, and is illustrated in 3.3.\n",
    "\n",
    "# From a Unicode perspective, characters are abstract entities which can be realized as one or more \n",
    "# glyphs. Only glyphs can appear on a screen or be printed on paper. A font is a mapping from characters \n",
    "# to glyphs.\n",
    "\n",
    "# Extracting encoded text from files\n",
    "\n",
    "# Let's assume that we have a small text file, and that we know how it is encoded. For example, \n",
    "# polish-lat2.txt, as the name suggests, is a snippet of Polish text (from the Polish Wikipedia; see \n",
    "# http://pl.wikipedia.org/wiki/Biblioteka_Pruska). This file is encoded as Latin-2, also known as \n",
    "# ISO-8859-2. The function nltk.data.find() locates the file for us.\n",
    "\n",
    "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n"
     ]
    }
   ],
   "source": [
    "# The Python open() function can read encoded data into Unicode strings, and write out Unicode strings \n",
    "# in encoded form. It takes a parameter to specify the encoding of the file being read or written. So \n",
    "# let's open our Polish file with the encoding 'latin2' and inspect the contents of the file:\n",
    "\n",
    "import codecs\n",
    "\n",
    "f = codecs.open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line)\n",
    "    \n",
    "# To open the file with latin-2 encoding in Python 2.X, we need to codecs.open instead of open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Pa\\u0144stwowa. Jej dawne zbiory znane pod nazw\\u0105\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafi\\u0142y do Biblioteki\n",
      "Jagiello\\u0144skiej w Krakowie, obejmuj\\u0105 ponad 500 tys. zabytkowych\n",
      "archiwali\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n"
     ]
    }
   ],
   "source": [
    "# If this does not display correctly on your terminal, or if we want to see the underlying numerical \n",
    "# values (or \"codepoints\") of the characters, then we can convert all non-ASCII characters into their \n",
    "# two-digit \\xXX and four-digit \\uXXXX representations:\n",
    "\n",
    "f = codecs.open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line.encode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[324]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note - this discussion on Unicode characters can help with Google Calendar...\n",
    "\n",
    "# The first line above illustrates a Unicode escape string preceded by the \\u escape string, namely \n",
    "# \\u0144 . The relevant Unicode character will be dislayed on the screen as the glyph ń. In the third \n",
    "# line of the preceding example, we see \\xf3, which corresponds to the glyph ó, and is within the \n",
    "# 128-255 range.\n",
    "\n",
    "# In Python 3, source code is encoded using UTF-8 by default, and you can include Unicode characters in \n",
    "# strings if you are using IDLE or another program editor that supports Unicode. Arbitrary Unicode \n",
    "# characters can be included using the \\uXXXX escape sequence. We find the integer ordinal of a character \n",
    "# using ord(). For example:\n",
    "\n",
    "#ord(\"ń\")\n",
    "[ord(x) for x in u'ń'] # This works for Python 2 - inform Bird et al\n",
    "\n",
    "# It doesn't work here... Let's stop here for now (3/19/2015 @ 7:15p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x144'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The hexadecimal 4 digit notation for 324 is 0144 (type hex(324) to discover this), and we can define a string with the appropriate \n",
    "# escape sequence.\n",
    "\n",
    "hex(324)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\u0144'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacute = '\\u0144'\n",
    "nacute\n",
    "# This doesn't work for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\u0144\n"
     ]
    }
   ],
   "source": [
    "# Note\n",
    "\n",
    "# There are many factors determining what glyphs are rendered on your screen. If you are sure that you have the correct encoding, but \n",
    "# your Python code is still failing to produce the glyphs you expected, you should also check that you have the necessary fonts \n",
    "# installed on your system. It may be necessary to configure your locale to render UTF-8 encoded characters, then use \n",
    "# print(nacute.encode('utf8')) in order to see the ń displayed in your terminal.\n",
    "\n",
    "print(nacute.encode('utf8'))\n",
    "\n",
    "# Still did not work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\u0144'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also see how this character is represented as a sequence of bytes inside a text file:\n",
    "nacute.encode('utf8')\n",
    "# Still doesn't work - something wrong with Python here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niemc\\xf3w pod koniec II wojny \\u015bwiatowej na Dolny \\u015al\\u0105sk, zosta\\u0142y\\n\n"
     ]
    }
   ],
   "source": [
    "# The module unicodedata lets us inspect the properties of Unicode characters. In the following example, we select all characters in \n",
    "# the third line of our Polish text outside the ASCII range and print their UTF-8 byte sequence, followed by their code point integer \n",
    "# using the standard Unicode convention (i.e., prefixing the hex digits with U+), followed by their Unicode name.\n",
    "\n",
    "import unicodedata\n",
    "lines = codecs.open(path, encoding='latin2').readlines() # codecs.open for Python 2.X\n",
    "line = lines[2]\n",
    "print(line.encode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ó U+00f3 LATIN SMALL LETTER O WITH ACUTE\n",
      "ś U+015b LATIN SMALL LETTER S WITH ACUTE\n",
      "Ś U+015a LATIN CAPITAL LETTER S WITH ACUTE\n",
      "ą U+0105 LATIN SMALL LETTER A WITH OGONEK\n",
      "ł U+0142 LATIN SMALL LETTER L WITH STROKE\n"
     ]
    }
   ],
   "source": [
    "for c in line:\n",
    "    if ord(c) > 127:\n",
    "        print('{} U+{:04x} {}'.format(c.encode('utf8'), ord(c), unicodedata.name(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next examples illustrate how Python string methods and the re module can work with Unicode characters. (We will take a close \n",
    "# look at the re module in the following section. The \\w matches a \"word character\", cf 3.4).\n",
    "\n",
    "line.find('zosta\\u0142y')\n",
    "# I don't think it found anything here - probably something with UNicode characters in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'niemc\\xf3w pod koniec ii wojny \\u015bwiatowej na dolny \\u015bl\\u0105sk, zosta\\u0142y\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = line.lower()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niemc\\\\xf3w pod koniec ii wojny \\\\u015bwiatowej na dolny \\\\u015bl\\\\u0105sk, zosta\\\\u0142y\\\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.encode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-a27539d9d845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\u015b\\w*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# Generated an error. Don't worry about for now...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "m = re.search('\\u015b\\w*', line)\n",
    "m.group()\n",
    "\n",
    "# Generated an error. Don't worry about for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'niemc\\xf3w',\n",
       " u'pod',\n",
       " u'koniec',\n",
       " u'ii',\n",
       " u'wojny',\n",
       " u'\\u015bwiatowej',\n",
       " u'na',\n",
       " u'dolny',\n",
       " u'\\u015bl\\u0105sk',\n",
       " u',',\n",
       " u'zosta\\u0142y']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK tokenizers allow Unicode strings as input, and correspondingly yield Unicode strings as output.\n",
    "\n",
    "word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Skipped small section \"Using your local encoding in Python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Regular Expressions for Detecting Word Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Many linguistic processing tasks involve pattern matching. For example, we can find words ending with ed using endswith('ed'). \n",
    "# We saw a variety of such \"word tests\" in 4.2 (in Chapter 1). Regular expressions give us a more powerful and flexible method for \n",
    "# describing the character patterns we are interested in.\n",
    "\n",
    "# Note\n",
    "\n",
    "# There are many other published introductions to regular expressions, organized around the syntax of regular expressions and \n",
    "# applied to searching text files. Instead of doing this again, we focus on the use of regular expressions at different stages of \n",
    "# linguistic processing. As usual, we'll adopt a problem-based approach and present new features only as they are needed to solve \n",
    "# practical problems. In our discussion we will mark regular expressions using chevrons like this: «patt»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To use regular expressions in Python we need to import the re library using: import re. We also need a list of words to search; \n",
    "# we'll use the Words Corpus again (4). We will preprocess it to remove any proper names.\n",
    "\n",
    "# Import Python's regular expression library\n",
    "import re\n",
    "\n",
    "# nltk.corpus.words.words('en') is a list of all English words in its corpus\n",
    "# We find all lower case words (so that we don't repeat with capitalized words) and place them in wordlist\n",
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'abaissed',\n",
       " u'abandoned',\n",
       " u'abased',\n",
       " u'abashed',\n",
       " u'abatised',\n",
       " u'abed',\n",
       " u'aborted',\n",
       " u'abridged',\n",
       " u'abscessed',\n",
       " u'absconded',\n",
       " u'absorbed',\n",
       " u'abstracted',\n",
       " u'abstricted',\n",
       " u'accelerated',\n",
       " u'accepted',\n",
       " u'accidented',\n",
       " u'accoladed',\n",
       " u'accolated',\n",
       " u'accomplished',\n",
       " u'accosted',\n",
       " u'accredited',\n",
       " u'accursed',\n",
       " u'accused',\n",
       " u'accustomed',\n",
       " u'acetated',\n",
       " u'acheweed',\n",
       " u'aciculated',\n",
       " u'aciliated',\n",
       " u'acknowledged',\n",
       " u'acorned',\n",
       " u'acquainted',\n",
       " u'acquired',\n",
       " u'acquisited',\n",
       " u'acred',\n",
       " u'aculeated',\n",
       " u'addebted',\n",
       " u'added',\n",
       " u'addicted',\n",
       " u'addlebrained',\n",
       " u'addleheaded',\n",
       " u'addlepated',\n",
       " u'addorsed',\n",
       " u'adempted',\n",
       " u'adfected',\n",
       " u'adjoined',\n",
       " u'admired',\n",
       " u'admitted',\n",
       " u'adnexed',\n",
       " u'adopted',\n",
       " u'adossed',\n",
       " u'adreamed',\n",
       " u'adscripted',\n",
       " u'aduncated',\n",
       " u'advanced',\n",
       " u'advised',\n",
       " u'aeried',\n",
       " u'aethered',\n",
       " u'afeared',\n",
       " u'affected',\n",
       " u'affectioned',\n",
       " u'affined',\n",
       " u'afflicted',\n",
       " u'affricated',\n",
       " u'affrighted',\n",
       " u'affronted',\n",
       " u'aforenamed',\n",
       " u'afterfeed',\n",
       " u'aftershafted',\n",
       " u'afterthoughted',\n",
       " u'afterwitted',\n",
       " u'agazed',\n",
       " u'aged',\n",
       " u'agglomerated',\n",
       " u'aggrieved',\n",
       " u'agminated',\n",
       " u'agnamed',\n",
       " u'agonied',\n",
       " u'agreed',\n",
       " u'agueweed',\n",
       " u'ahungered',\n",
       " u'aiguilletted',\n",
       " u'ailweed',\n",
       " u'airbrained',\n",
       " u'airified',\n",
       " u'aiseweed',\n",
       " u'aisled',\n",
       " u'alarmed',\n",
       " u'alated',\n",
       " u'alimonied',\n",
       " u'aliped',\n",
       " u'alleyed',\n",
       " u'allied',\n",
       " u'alligatored',\n",
       " u'allseed',\n",
       " u'almsdeed',\n",
       " u'aloed',\n",
       " u'altared',\n",
       " u'alveolated',\n",
       " u'amazed',\n",
       " u'ameed',\n",
       " u'amiced',\n",
       " u'amphitheatered',\n",
       " u'ampullated',\n",
       " u'amused',\n",
       " u'anchored',\n",
       " u'angled',\n",
       " u'anguiped',\n",
       " u'anguished',\n",
       " u'angulated',\n",
       " u'angulinerved',\n",
       " u'anhungered',\n",
       " u'animated',\n",
       " u'aniseed',\n",
       " u'annodated',\n",
       " u'annulated',\n",
       " u'anomaliped',\n",
       " u'anserated',\n",
       " u'anteflected',\n",
       " u'anteflexed',\n",
       " u'antimoniated',\n",
       " u'antimoniureted',\n",
       " u'antimoniuretted',\n",
       " u'antiquated',\n",
       " u'antired',\n",
       " u'antiweed',\n",
       " u'antlered',\n",
       " u'apertured',\n",
       " u'apexed',\n",
       " u'apicifixed',\n",
       " u'apiculated',\n",
       " u'apocopated',\n",
       " u'apostrophied',\n",
       " u'appearanced',\n",
       " u'appellatived',\n",
       " u'appendaged',\n",
       " u'appendiculated',\n",
       " u'applied',\n",
       " u'appressed',\n",
       " u'aralkylated',\n",
       " u'arbored',\n",
       " u'arched',\n",
       " u'architraved',\n",
       " u'arcked',\n",
       " u'arcuated',\n",
       " u'ared',\n",
       " u'areolated',\n",
       " u'ariled',\n",
       " u'arillated',\n",
       " u'armchaired',\n",
       " u'armed',\n",
       " u'armied',\n",
       " u'armillated',\n",
       " u'armored',\n",
       " u'armoried',\n",
       " u'arpeggiated',\n",
       " u'arpeggioed',\n",
       " u'arrased',\n",
       " u'arrowed',\n",
       " u'arrowheaded',\n",
       " u'arrowweed',\n",
       " u'arseneted',\n",
       " u'arsenetted',\n",
       " u'arseniureted',\n",
       " u'articled',\n",
       " u'articulated',\n",
       " u'ashamed',\n",
       " u'ashlared',\n",
       " u'ashweed',\n",
       " u'aspersed',\n",
       " u'asphyxied',\n",
       " u'assented',\n",
       " u'assessed',\n",
       " u'assigned',\n",
       " u'assistanted',\n",
       " u'associated',\n",
       " u'assonanced',\n",
       " u'assorted',\n",
       " u'assumed',\n",
       " u'assured',\n",
       " u'asteriated',\n",
       " u'astonied',\n",
       " u'aswooned',\n",
       " u'atrophiated',\n",
       " u'atrophied',\n",
       " u'attached',\n",
       " u'attired',\n",
       " u'attrited',\n",
       " u'augmented',\n",
       " u'aurated',\n",
       " u'auricled',\n",
       " u'auriculated',\n",
       " u'authorized',\n",
       " u'autoinhibited',\n",
       " u'autosensitized',\n",
       " u'autosled',\n",
       " u'averted',\n",
       " u'avowed',\n",
       " u'awearied',\n",
       " u'awned',\n",
       " u'awninged',\n",
       " u'axed',\n",
       " u'axhammered',\n",
       " u'axised',\n",
       " u'axled',\n",
       " u'axseed',\n",
       " u'axweed',\n",
       " u'azoted',\n",
       " u'azured',\n",
       " u'babied',\n",
       " u'babished',\n",
       " u'babyfied',\n",
       " u'baccated',\n",
       " u'backboned',\n",
       " u'backed',\n",
       " u'backhanded',\n",
       " u'backwatered',\n",
       " u'baconweed',\n",
       " u'badgerweed',\n",
       " u'bagged',\n",
       " u'bagwigged',\n",
       " u'baked',\n",
       " u'balanced',\n",
       " u'balconied',\n",
       " u'baldachined',\n",
       " u'baldricked',\n",
       " u'balled',\n",
       " u'ballweed',\n",
       " u'balsamweed',\n",
       " u'balustered',\n",
       " u'balustraded',\n",
       " u'bandannaed',\n",
       " u'banded',\n",
       " u'bandoleered',\n",
       " u'bangled',\n",
       " u'banked',\n",
       " u'bankweed',\n",
       " u'bannered',\n",
       " u'barbated',\n",
       " u'barbed',\n",
       " u'barebacked',\n",
       " u'bareboned',\n",
       " u'barefaced',\n",
       " u'barefooted',\n",
       " u'barehanded',\n",
       " u'bareheaded',\n",
       " u'barelegged',\n",
       " u'barenecked',\n",
       " u'barmybrained',\n",
       " u'barred',\n",
       " u'barreled',\n",
       " u'bartizaned',\n",
       " u'basebred',\n",
       " u'based',\n",
       " u'basehearted',\n",
       " u'basifixed',\n",
       " u'basilweed',\n",
       " u'basined',\n",
       " u'basinerved',\n",
       " u'basqued',\n",
       " u'bastioned',\n",
       " u'bated',\n",
       " u'bathroomed',\n",
       " u'battered',\n",
       " u'batteried',\n",
       " u'battled',\n",
       " u'battlemented',\n",
       " u'bayed',\n",
       " u'bayoneted',\n",
       " u'beached',\n",
       " u'beaded',\n",
       " u'beaked',\n",
       " u'bealtared',\n",
       " u'beamed',\n",
       " u'beanweed',\n",
       " u'beaproned',\n",
       " u'bearded',\n",
       " u'beautied',\n",
       " u'beavered',\n",
       " u'beballed',\n",
       " u'bebannered',\n",
       " u'bebed',\n",
       " u'bebelted',\n",
       " u'bebled',\n",
       " u'bebothered',\n",
       " u'bebouldered',\n",
       " u'bebuttoned',\n",
       " u'becassocked',\n",
       " u'bechained',\n",
       " u'bechignoned',\n",
       " u'becircled',\n",
       " u'becoiffed',\n",
       " u'becombed',\n",
       " u'becousined',\n",
       " u'becrinolined',\n",
       " u'becuffed',\n",
       " u'becurtained',\n",
       " u'becushioned',\n",
       " u'bed',\n",
       " u'bedaggered',\n",
       " u'bedangled',\n",
       " u'bedded',\n",
       " u'bediademed',\n",
       " u'bediamonded',\n",
       " u'beedged',\n",
       " u'beefheaded',\n",
       " u'beeheaded',\n",
       " u'beeswinged',\n",
       " u'beetled',\n",
       " u'beetleheaded',\n",
       " u'beetleweed',\n",
       " u'beeweed',\n",
       " u'befamilied',\n",
       " u'befanned',\n",
       " u'befathered',\n",
       " u'beferned',\n",
       " u'befetished',\n",
       " u'befezzed',\n",
       " u'befilleted',\n",
       " u'befilmed',\n",
       " u'beforested',\n",
       " u'befountained',\n",
       " u'befrocked',\n",
       " u'befrogged',\n",
       " u'befurbelowed',\n",
       " u'befurred',\n",
       " u'begabled',\n",
       " u'begarlanded',\n",
       " u'begartered',\n",
       " u'beggarweed',\n",
       " u'beglobed',\n",
       " u'begoggled',\n",
       " u'begowned',\n",
       " u'behatted',\n",
       " u'behaviored',\n",
       " u'beheadlined',\n",
       " u'behooped',\n",
       " u'beinked',\n",
       " u'bekilted',\n",
       " u'beknived',\n",
       " u'beknotted',\n",
       " u'belaced',\n",
       " u'belated',\n",
       " u'belatticed',\n",
       " u'belavendered',\n",
       " u'beledgered',\n",
       " u'belfried',\n",
       " u'beliked',\n",
       " u'belimousined',\n",
       " u'belled',\n",
       " u'bellied',\n",
       " u'bellmouthed',\n",
       " u'bellweed',\n",
       " u'beloved',\n",
       " u'belozenged',\n",
       " u'belted',\n",
       " u'bemazed',\n",
       " u'bemedaled',\n",
       " u'bemedalled',\n",
       " u'bemitered',\n",
       " u'bemitred',\n",
       " u'bemused',\n",
       " u'bemuslined',\n",
       " u'bended',\n",
       " u'beneaped',\n",
       " u'beneficed',\n",
       " u'beneighbored',\n",
       " u'benempted',\n",
       " u'benighted',\n",
       " u'bennetweed',\n",
       " u'benumbed',\n",
       " u'benweed',\n",
       " u'benzoated',\n",
       " u'benzoinated',\n",
       " u'bepastured',\n",
       " u'bepatched',\n",
       " u'beperiwigged',\n",
       " u'bepewed',\n",
       " u'bepillared',\n",
       " u'bepistoled',\n",
       " u'beplaided',\n",
       " u'beplumed',\n",
       " u'beribanded',\n",
       " u'beribboned',\n",
       " u'beringed',\n",
       " u'beringleted',\n",
       " u'berobed',\n",
       " u'berouged',\n",
       " u'berried',\n",
       " u'berthed',\n",
       " u'beruffed',\n",
       " u'beruffled',\n",
       " u'beshawled',\n",
       " u'besieged',\n",
       " u'beslushed',\n",
       " u'besotted',\n",
       " u'bespecked',\n",
       " u'bespectacled',\n",
       " u'besped',\n",
       " u'bespeed',\n",
       " u'bespelled',\n",
       " u'bespurred',\n",
       " u'bestatued',\n",
       " u'bestayed',\n",
       " u'bestrapped',\n",
       " u'bestubbled',\n",
       " u'besweatered',\n",
       " u'betattered',\n",
       " u'betaxed',\n",
       " u'betowered',\n",
       " u'betrothed',\n",
       " u'betrousered',\n",
       " u'betted',\n",
       " u'betuckered',\n",
       " u'beturbaned',\n",
       " u'betusked',\n",
       " u'betutored',\n",
       " u'betwattled',\n",
       " u'beuniformed',\n",
       " u'beveled',\n",
       " u'bevelled',\n",
       " u'bevesseled',\n",
       " u'bevesselled',\n",
       " u'bevined',\n",
       " u'bevoiled',\n",
       " u'bewaitered',\n",
       " u'bewhiskered',\n",
       " u'bewigged',\n",
       " u'bewildered',\n",
       " u'bewinged',\n",
       " u'bewired',\n",
       " u'bewrathed',\n",
       " u'biangulated',\n",
       " u'biarcuated',\n",
       " u'biarticulated',\n",
       " u'bicarbureted',\n",
       " u'biciliated',\n",
       " u'bicolored',\n",
       " u'bicorned',\n",
       " u'bidented',\n",
       " u'bifanged',\n",
       " u'bifidated',\n",
       " u'biflected',\n",
       " u'biforked',\n",
       " u'biformed',\n",
       " u'bifronted',\n",
       " u'bifurcated',\n",
       " u'bigeminated',\n",
       " u'bighearted',\n",
       " u'bigmouthed',\n",
       " u'bigoted',\n",
       " u'bigwigged',\n",
       " u'bilamellated',\n",
       " u'bilaminated',\n",
       " u'billed',\n",
       " u'bilobated',\n",
       " u'bilobed',\n",
       " u'bilsted',\n",
       " u'bimaculated',\n",
       " u'bimotored',\n",
       " u'bindweed',\n",
       " u'bineweed',\n",
       " u'binominated',\n",
       " u'binucleated',\n",
       " u'biparted',\n",
       " u'bipectinated',\n",
       " u'biped',\n",
       " u'bipennated',\n",
       " u'bipinnated',\n",
       " u'bipinnatiparted',\n",
       " u'bipinnatisected',\n",
       " u'biradiated',\n",
       " u'birdmouthed',\n",
       " u'birdseed',\n",
       " u'birdweed',\n",
       " u'birostrated',\n",
       " u'birthbed',\n",
       " u'bisexed',\n",
       " u'bishopweed',\n",
       " u'bistered',\n",
       " u'bistipuled',\n",
       " u'bisubstituted',\n",
       " u'bitted',\n",
       " u'bitterhearted',\n",
       " u'bitterweed',\n",
       " u'bituberculated',\n",
       " u'bitumed',\n",
       " u'bivalved',\n",
       " u'bivaulted',\n",
       " u'bivocalized',\n",
       " u'blackhearted',\n",
       " u'blackseed',\n",
       " u'blackshirted',\n",
       " u'bladderseed',\n",
       " u'bladderweed',\n",
       " u'bladed',\n",
       " u'blakeberyed',\n",
       " u'blamed',\n",
       " u'blanked',\n",
       " u'blanketed',\n",
       " u'blanketweed',\n",
       " u'blasted',\n",
       " u'bleached',\n",
       " u'bleared',\n",
       " u'bleed',\n",
       " u'blended',\n",
       " u'blessed',\n",
       " u'blighted',\n",
       " u'blinded',\n",
       " u'blindfolded',\n",
       " u'blindweed',\n",
       " u'blinked',\n",
       " u'blinkered',\n",
       " u'blistered',\n",
       " u'blisterweed',\n",
       " u'blithehearted',\n",
       " u'bloated',\n",
       " u'blobbed',\n",
       " u'blocked',\n",
       " u'blockheaded',\n",
       " u'blooded',\n",
       " u'bloodied',\n",
       " u'bloodshed',\n",
       " u'bloodstained',\n",
       " u'bloodweed',\n",
       " u'blossomed',\n",
       " u'blotched',\n",
       " u'bloused',\n",
       " u'blowzed',\n",
       " u'bludgeoned',\n",
       " u'bluebelled',\n",
       " u'bluehearted',\n",
       " u'blueweed',\n",
       " u'blunderheaded',\n",
       " u'blunthearted',\n",
       " u'blurred',\n",
       " u'bobbed',\n",
       " u'bobsled',\n",
       " u'bobtailed',\n",
       " u'bodiced',\n",
       " u'bodied',\n",
       " u'boiled',\n",
       " u'boldhearted',\n",
       " u'bolectioned',\n",
       " u'boled',\n",
       " u'boleweed',\n",
       " u'bolled',\n",
       " u'bombed',\n",
       " u'bonded',\n",
       " u'boned',\n",
       " u'boneheaded',\n",
       " u'bonneted',\n",
       " u'booked',\n",
       " u'booted',\n",
       " u'bootied',\n",
       " u'boozed',\n",
       " u'bordered',\n",
       " u'bordured',\n",
       " u'bosomed',\n",
       " u'bossed',\n",
       " u'bosselated',\n",
       " u'botched',\n",
       " u'botherheaded',\n",
       " u'bothsided',\n",
       " u'bottled',\n",
       " u'bottomed',\n",
       " u'boughed',\n",
       " u'bounded',\n",
       " u'bountied',\n",
       " u'bowed',\n",
       " u'boweled',\n",
       " u'bowlegged',\n",
       " u'bowstringed',\n",
       " u'braced',\n",
       " u'braceleted',\n",
       " u'brackened',\n",
       " u'bracted',\n",
       " u'braided',\n",
       " u'brambled',\n",
       " u'branched',\n",
       " u'branded',\n",
       " u'brandied',\n",
       " u'brangled',\n",
       " u'bravehearted',\n",
       " u'brawned',\n",
       " u'brazenfaced',\n",
       " u'breasted',\n",
       " u'breastweed',\n",
       " u'breathed',\n",
       " u'brecciated',\n",
       " u'bred',\n",
       " u'breeched',\n",
       " u'breed',\n",
       " u'breviped',\n",
       " u'bridebed',\n",
       " u'brideweed',\n",
       " u'bridged',\n",
       " u'bridled',\n",
       " u'briered',\n",
       " u'brimmed',\n",
       " u'bristled',\n",
       " u'broadhearted',\n",
       " u'brocaded',\n",
       " u'brocked',\n",
       " u'brokenhearted',\n",
       " u'bromoiodized',\n",
       " u'bronzed',\n",
       " u'brooked',\n",
       " u'brookweed',\n",
       " u'broomweed',\n",
       " u'broozled',\n",
       " u'browed',\n",
       " u'brownweed',\n",
       " u'bruckled',\n",
       " u'brushed',\n",
       " u'buboed',\n",
       " u'bucked',\n",
       " u'buckled',\n",
       " u'buckskinned',\n",
       " u'buffed',\n",
       " u'bugled',\n",
       " u'bugleweed',\n",
       " u'bugseed',\n",
       " u'bugweed',\n",
       " u'bulbed',\n",
       " u'bulked',\n",
       " u'bulkheaded',\n",
       " u'bullated',\n",
       " u'bulldogged',\n",
       " u'bulleted',\n",
       " u'bulletheaded',\n",
       " u'bullheaded',\n",
       " u'bullweed',\n",
       " u'bummed',\n",
       " u'bundlerooted',\n",
       " u'bundweed',\n",
       " u'bunted',\n",
       " u'buried',\n",
       " u'burled',\n",
       " u'burned',\n",
       " u'burnoosed',\n",
       " u'burntweed',\n",
       " u'burred',\n",
       " u'burroweed',\n",
       " u'burseed',\n",
       " u'burweed',\n",
       " u'bushed',\n",
       " u'busied',\n",
       " u'busked',\n",
       " u'buskined',\n",
       " u'busted',\n",
       " u'bustled',\n",
       " u'busybodied',\n",
       " u'buttered',\n",
       " u'butterfingered',\n",
       " u'butterweed',\n",
       " u'butteryfingered',\n",
       " u'buttocked',\n",
       " u'buttoned',\n",
       " u'buttonweed',\n",
       " u'cabled',\n",
       " u'caboshed',\n",
       " u'caddiced',\n",
       " u'caddised',\n",
       " u'cadenced',\n",
       " u'cadweed',\n",
       " u'caftaned',\n",
       " u'caged',\n",
       " u'cairned',\n",
       " u'caissoned',\n",
       " u'calced',\n",
       " u'calcified',\n",
       " u'calcined',\n",
       " u'calculated',\n",
       " u'calibered',\n",
       " u'calicoed',\n",
       " u'caligated',\n",
       " u'calpacked',\n",
       " u'calved',\n",
       " u'calycled',\n",
       " u'calyculated',\n",
       " u'camailed',\n",
       " u'camerated',\n",
       " u'cammed',\n",
       " u'campanulated',\n",
       " u'campshed',\n",
       " u'camused',\n",
       " u'canaliculated',\n",
       " u'cancellated',\n",
       " u'cancered',\n",
       " u'cancerweed',\n",
       " u'candied',\n",
       " u'candlelighted',\n",
       " u'candlesticked',\n",
       " u'candyweed',\n",
       " u'canioned',\n",
       " u'cankered',\n",
       " u'cankerweed',\n",
       " u'canned',\n",
       " u'cannelated',\n",
       " u'cannelured',\n",
       " u'cannoned',\n",
       " u'cannulated',\n",
       " u'canted',\n",
       " u'cantilevered',\n",
       " u'cantoned',\n",
       " u'cantred',\n",
       " u'caped',\n",
       " u'capernoited',\n",
       " u'capeweed',\n",
       " u'capitaled',\n",
       " u'capitated',\n",
       " u'capped',\n",
       " u'capriped',\n",
       " u'capsulated',\n",
       " u'capuched',\n",
       " u'carapaced',\n",
       " u'carbolated',\n",
       " u'carboyed',\n",
       " u'carbuncled',\n",
       " u'carcaneted',\n",
       " u'carded',\n",
       " u'carinated',\n",
       " u'carkled',\n",
       " u'carnaged',\n",
       " u'carnationed',\n",
       " u'carpetweed',\n",
       " u'carried',\n",
       " u'carrotweed',\n",
       " u'carucated',\n",
       " u'carunculated',\n",
       " u'cased',\n",
       " u'casemated',\n",
       " u'casemented',\n",
       " u'caseweed',\n",
       " u'casqued',\n",
       " u'castellated',\n",
       " u'castled',\n",
       " u'castorized',\n",
       " u'catamited',\n",
       " u'cataracted',\n",
       " u'catarrhed',\n",
       " u'catchweed',\n",
       " u'catenated',\n",
       " u'caterpillared',\n",
       " u'catfaced',\n",
       " u'catfooted',\n",
       " u'cathedraled',\n",
       " u'caudated',\n",
       " u'caverned',\n",
       " u'cavitied',\n",
       " u'cayenned',\n",
       " u'cedared',\n",
       " u'ceilinged',\n",
       " u'celebrated',\n",
       " u'cellated',\n",
       " u'celled',\n",
       " u'cellulated',\n",
       " u'celluloided',\n",
       " u'centered',\n",
       " u'centriffed',\n",
       " u'centuried',\n",
       " u'cerated',\n",
       " u'cered',\n",
       " u'certified',\n",
       " u'chafeweed',\n",
       " u'chaffseed',\n",
       " u'chaffweed',\n",
       " u'chafted',\n",
       " u'chained',\n",
       " u'chaliced',\n",
       " u'chambered',\n",
       " u'chamberleted',\n",
       " u'chamberletted',\n",
       " u'chanceled',\n",
       " u'channeled',\n",
       " u'channelled',\n",
       " u'chaped',\n",
       " u'chapleted',\n",
       " u'chapournetted',\n",
       " u'chapped',\n",
       " u'charioted',\n",
       " u'charqued',\n",
       " u'chartered',\n",
       " u'chasmed',\n",
       " u'chasteweed',\n",
       " u'chasubled',\n",
       " u'checked',\n",
       " u'checkered',\n",
       " u'checkrowed',\n",
       " u'cheered',\n",
       " u'cheliped',\n",
       " u'cherried',\n",
       " u'chickenbreasted',\n",
       " u'chickenhearted',\n",
       " u'chickenweed',\n",
       " u'chickweed',\n",
       " u'chicqued',\n",
       " u'chiggerweed',\n",
       " u'chignoned',\n",
       " u'childbed',\n",
       " u'childed',\n",
       " u'chilled',\n",
       " u'chined',\n",
       " u'chinned',\n",
       " u'chipped',\n",
       " u'chiseled',\n",
       " u'chitinized',\n",
       " u'chokered',\n",
       " u'chokeweed',\n",
       " u'cholterheaded',\n",
       " u'chopped',\n",
       " u'choppered',\n",
       " u'chorded',\n",
       " u'chowderheaded',\n",
       " u'christened',\n",
       " u'chubbed',\n",
       " u'chuckleheaded',\n",
       " u'churchified',\n",
       " u'churled',\n",
       " u'ciliated',\n",
       " u'cingulated',\n",
       " u'cinnamoned',\n",
       " u'cinquefoiled',\n",
       " u'circled',\n",
       " u'circumscribed',\n",
       " u'circumstanced',\n",
       " u'cirrated',\n",
       " u'cirrhosed',\n",
       " u'cirriped',\n",
       " u'cisted',\n",
       " u'citied',\n",
       " u'citified',\n",
       " u'citrated',\n",
       " u'civilized',\n",
       " u'clammed',\n",
       " u'clammyweed',\n",
       " u'clanned',\n",
       " u'clapped',\n",
       " u'classed',\n",
       " u'classified',\n",
       " u'clavated',\n",
       " u'clavellated',\n",
       " u'clawed',\n",
       " u'claybrained',\n",
       " u'clayweed',\n",
       " u'cleaded',\n",
       " u'cleanhanded',\n",
       " u'cleanhearted',\n",
       " u'clearheaded',\n",
       " u'clearhearted',\n",
       " u'clearweed',\n",
       " u'cled',\n",
       " u'cleeked',\n",
       " u'clefted',\n",
       " u'clerestoried',\n",
       " u'cliented',\n",
       " u'cliffed',\n",
       " u'cliffweed',\n",
       " u'clipped',\n",
       " u'cloaked',\n",
       " u'clocked',\n",
       " u'clodpated',\n",
       " u'cloistered',\n",
       " u'closed',\n",
       " u'closefisted',\n",
       " u'closehanded',\n",
       " u'closehearted',\n",
       " u'closemouthed',\n",
       " u'clotweed',\n",
       " u'clouded',\n",
       " u'clouted',\n",
       " u'clovered',\n",
       " u'clubbed',\n",
       " u'clubfisted',\n",
       " u'clubfooted',\n",
       " u'clubweed',\n",
       " u'clustered',\n",
       " u'coaged',\n",
       " u'coaggregated',\n",
       " u'coated',\n",
       " u'coattailed',\n",
       " u'cobbed',\n",
       " u'cocashweed',\n",
       " u'cochleated',\n",
       " u'cockaded',\n",
       " u'cocked',\n",
       " u'cockeyed',\n",
       " u'cockled',\n",
       " u'cockneybred',\n",
       " u'cockscombed',\n",
       " u'cockweed',\n",
       " u'codheaded',\n",
       " u'coed',\n",
       " u'coelongated',\n",
       " u'coembedded',\n",
       " u'coequated',\n",
       " u'coexpanded',\n",
       " u'coffeeweed',\n",
       " u'cogged',\n",
       " u'coifed',\n",
       " u'coiled',\n",
       " u'coldhearted',\n",
       " u'coleseed',\n",
       " u'colicweed',\n",
       " u'collared',\n",
       " u'collected',\n",
       " u'collied',\n",
       " u'colloped',\n",
       " u'colonnaded',\n",
       " u'colored',\n",
       " u'columnated',\n",
       " u'columned',\n",
       " u'combed',\n",
       " u'combined',\n",
       " u'compacted',\n",
       " u'complected',\n",
       " u'complexioned',\n",
       " u'complicated',\n",
       " u'componed',\n",
       " u'componented',\n",
       " u'composed',\n",
       " u'compressed',\n",
       " u'comprised',\n",
       " u'compulsed',\n",
       " u'conamed',\n",
       " u'concamerated',\n",
       " u'concealed',\n",
       " u'conceded',\n",
       " u'conceited',\n",
       " u'concentrated',\n",
       " u'concerned',\n",
       " u'concerted',\n",
       " u'conched',\n",
       " u'conchyliated',\n",
       " u'condemned',\n",
       " u'condensed',\n",
       " u'conditioned',\n",
       " u'conduplicated',\n",
       " u'coned',\n",
       " u'confated',\n",
       " u'conferted',\n",
       " u'confined',\n",
       " u'confirmed',\n",
       " u'conflated',\n",
       " u'confounded',\n",
       " u'confused',\n",
       " u'congested',\n",
       " u'conjoined',\n",
       " u'conjugated',\n",
       " u'connected',\n",
       " u'conred',\n",
       " u'consecrated',\n",
       " u'considered',\n",
       " u'consolidated',\n",
       " u'constrained',\n",
       " u'constricted',\n",
       " u'consumpted',\n",
       " u'contagioned',\n",
       " u'contented',\n",
       " u'contextured',\n",
       " u'continued',\n",
       " u'contorted',\n",
       " u'contortioned',\n",
       " u'contracted',\n",
       " u'contractured',\n",
       " u'contusioned',\n",
       " u'converted',\n",
       " u'convexed',\n",
       " u'convinced',\n",
       " u'convoluted',\n",
       " u'coolheaded',\n",
       " u'coolweed',\n",
       " u'copied',\n",
       " u'copleased',\n",
       " u'copped',\n",
       " u'coppernosed',\n",
       " u'copperytailed',\n",
       " u'coppiced',\n",
       " u'coppled',\n",
       " u'copsewooded',\n",
       " u'copygraphed',\n",
       " u'coraled',\n",
       " u'corded',\n",
       " u'corduroyed',\n",
       " u'cored',\n",
       " u'coreflexed',\n",
       " u'corked',\n",
       " u'cornered',\n",
       " u'cornified',\n",
       " u'cornuated',\n",
       " u'cornuted',\n",
       " u'corollated',\n",
       " u'coronaled',\n",
       " u'coronated',\n",
       " u'coroneted',\n",
       " u'coronetted',\n",
       " u'corpusculated',\n",
       " u'corrected',\n",
       " u'correlated',\n",
       " u'corridored',\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Basic Meta-Characters\n",
    "\n",
    "# Let's find words ending with ed using the regular expression «ed$». We will use the re.search(p, s) function to check whether \n",
    "# the pattern p can be found somewhere inside the string s. We need to specify the characters of interest, and use the dollar sign \n",
    "# which has a special behavior in the context of regular expressions in that it matches the end of the word:\n",
    "\n",
    "[w for w in wordlist if re.search('ed$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'abjectly',\n",
       " u'adjuster',\n",
       " u'dejected',\n",
       " u'dejectly',\n",
       " u'injector',\n",
       " u'majestic',\n",
       " u'objectee',\n",
       " u'objector',\n",
       " u'rejecter',\n",
       " u'rejector',\n",
       " u'unjilted',\n",
       " u'unjolted',\n",
       " u'unjustly']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The . wildcard symbol matches any single character. Suppose we have room in a crossword puzzle for an 8-letter word with j as \n",
    "# its third letter and t as its sixth letter. In place of each blank cell we use a period:\n",
    "\n",
    "[w for w in wordlist if re.search('^..j..t..$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'abjectedness',\n",
       " u'abjection',\n",
       " u'abjective',\n",
       " u'abjectly',\n",
       " u'abjectness',\n",
       " u'adjection',\n",
       " u'adjectional',\n",
       " u'adjectival',\n",
       " u'adjectivally',\n",
       " u'adjective',\n",
       " u'adjectively',\n",
       " u'adjectivism',\n",
       " u'adjectivitis',\n",
       " u'adjustable',\n",
       " u'adjustably',\n",
       " u'adjustage',\n",
       " u'adjustation',\n",
       " u'adjuster',\n",
       " u'adjustive',\n",
       " u'adjustment',\n",
       " u'antejentacular',\n",
       " u'antiprojectivity',\n",
       " u'bijouterie',\n",
       " u'coadjustment',\n",
       " u'cojusticiar',\n",
       " u'conjective',\n",
       " u'conjecturable',\n",
       " u'conjecturably',\n",
       " u'conjectural',\n",
       " u'conjecturalist',\n",
       " u'conjecturality',\n",
       " u'conjecturally',\n",
       " u'conjecture',\n",
       " u'conjecturer',\n",
       " u'coprojector',\n",
       " u'counterobjection',\n",
       " u'dejected',\n",
       " u'dejectedly',\n",
       " u'dejectedness',\n",
       " u'dejectile',\n",
       " u'dejection',\n",
       " u'dejectly',\n",
       " u'dejectory',\n",
       " u'dejecture',\n",
       " u'disjection',\n",
       " u'guanajuatite',\n",
       " u'inadjustability',\n",
       " u'inadjustable',\n",
       " u'injectable',\n",
       " u'injection',\n",
       " u'injector',\n",
       " u'injustice',\n",
       " u'insubjection',\n",
       " u'interjection',\n",
       " u'interjectional',\n",
       " u'interjectionalize',\n",
       " u'interjectionally',\n",
       " u'interjectionary',\n",
       " u'interjectionize',\n",
       " u'interjectiveness',\n",
       " u'interjector',\n",
       " u'interjectorily',\n",
       " u'interjectory',\n",
       " u'interjectural',\n",
       " u'interobjective',\n",
       " u'intersubjective',\n",
       " u'introjection',\n",
       " u'introjective',\n",
       " u'majestic',\n",
       " u'majestical',\n",
       " u'majestically',\n",
       " u'majesticalness',\n",
       " u'majesticness',\n",
       " u'majestious',\n",
       " u'majestyship',\n",
       " u'maladjusted',\n",
       " u'maladjustive',\n",
       " u'maladjustment',\n",
       " u'microinjection',\n",
       " u'microprojector',\n",
       " u'misconjecture',\n",
       " u'munjistin',\n",
       " u'nonadjectival',\n",
       " u'nonadjustable',\n",
       " u'nonadjustive',\n",
       " u'nonadjustment',\n",
       " u'nonconjectural',\n",
       " u'nonejection',\n",
       " u'nonobjection',\n",
       " u'nonobjective',\n",
       " u'nonprojection',\n",
       " u'nonprojective',\n",
       " u'nonprojectively',\n",
       " u'nonrejection',\n",
       " u'nonsubjective',\n",
       " u'objectable',\n",
       " u'objectation',\n",
       " u'objectative',\n",
       " u'objectee',\n",
       " u'objecthood',\n",
       " u'objectification',\n",
       " u'objectify',\n",
       " u'objection',\n",
       " u'objectionability',\n",
       " u'objectionable',\n",
       " u'objectionableness',\n",
       " u'objectionably',\n",
       " u'objectional',\n",
       " u'objectioner',\n",
       " u'objectionist',\n",
       " u'objectival',\n",
       " u'objectivate',\n",
       " u'objectivation',\n",
       " u'objective',\n",
       " u'objectively',\n",
       " u'objectiveness',\n",
       " u'objectivism',\n",
       " u'objectivist',\n",
       " u'objectivistic',\n",
       " u'objectivity',\n",
       " u'objectivize',\n",
       " u'objectization',\n",
       " u'objectize',\n",
       " u'objectless',\n",
       " u'objectlessly',\n",
       " u'objectlessness',\n",
       " u'objector',\n",
       " u'outjetting',\n",
       " u'overjutting',\n",
       " u'overobjectify',\n",
       " u'preadjectival',\n",
       " u'preadjective',\n",
       " u'preadjustable',\n",
       " u'preadjustment',\n",
       " u'preconjecture',\n",
       " u'prejustification',\n",
       " u'prejustify',\n",
       " u'preobjection',\n",
       " u'preobjective',\n",
       " u'prerejection',\n",
       " u'presubjection',\n",
       " u'projectable',\n",
       " u'projectedly',\n",
       " u'projectile',\n",
       " u'projecting',\n",
       " u'projectingly',\n",
       " u'projection',\n",
       " u'projectional',\n",
       " u'projectionist',\n",
       " u'projective',\n",
       " u'projectively',\n",
       " u'projectivity',\n",
       " u'projector',\n",
       " u'projectress',\n",
       " u'projectrix',\n",
       " u'projecture',\n",
       " u'readjustable',\n",
       " u'readjuster',\n",
       " u'readjustment',\n",
       " u'rejectable',\n",
       " u'rejectableness',\n",
       " u'rejectage',\n",
       " u'rejectamenta',\n",
       " u'rejecter',\n",
       " u'rejectingly',\n",
       " u'rejection',\n",
       " u'rejective',\n",
       " u'rejectment',\n",
       " u'rejector',\n",
       " u'rejustification',\n",
       " u'rejustify',\n",
       " u'reobjectivization',\n",
       " u'reobjectivize',\n",
       " u'resubjection',\n",
       " u'retrojection',\n",
       " u'semiadjectively',\n",
       " u'subjectability',\n",
       " u'subjectable',\n",
       " u'subjectdom',\n",
       " u'subjected',\n",
       " u'subjectedly',\n",
       " u'subjectedness',\n",
       " u'subjecthood',\n",
       " u'subjectibility',\n",
       " u'subjectible',\n",
       " u'subjectification',\n",
       " u'subjectify',\n",
       " u'subjectile',\n",
       " u'subjection',\n",
       " u'subjectional',\n",
       " u'subjectist',\n",
       " u'subjective',\n",
       " u'subjectively',\n",
       " u'subjectiveness',\n",
       " u'subjectivism',\n",
       " u'subjectivist',\n",
       " u'subjectivistic',\n",
       " u'subjectivistically',\n",
       " u'subjectivity',\n",
       " u'subjectivize',\n",
       " u'subjectivoidealistic',\n",
       " u'subjectless',\n",
       " u'subjectlike',\n",
       " u'subjectness',\n",
       " u'subjectship',\n",
       " u'superdejection',\n",
       " u'superinjustice',\n",
       " u'superjustification',\n",
       " u'superobjection',\n",
       " u'superobjectionable',\n",
       " u'teleobjective',\n",
       " u'trajectile',\n",
       " u'trajection',\n",
       " u'trajectitious',\n",
       " u'trajectory',\n",
       " u'transsubjective',\n",
       " u'unadjectived',\n",
       " u'unadjustably',\n",
       " u'unadjusted',\n",
       " u'unadjustment',\n",
       " u'unconjecturable',\n",
       " u'unconjectured',\n",
       " u'undejected',\n",
       " u'underadjustment',\n",
       " u'unejected',\n",
       " u'uninjectable',\n",
       " u'uninjected',\n",
       " u'uninterjected',\n",
       " u'unjesting',\n",
       " u'unjilted',\n",
       " u'unjolted',\n",
       " u'unjostled',\n",
       " u'unjustice',\n",
       " u'unjusticiable',\n",
       " u'unjustifiable',\n",
       " u'unjustifiableness',\n",
       " u'unjustifiably',\n",
       " u'unjustified',\n",
       " u'unjustifiedly',\n",
       " u'unjustifiedness',\n",
       " u'unjustify',\n",
       " u'unjustled',\n",
       " u'unjustly',\n",
       " u'unjustness',\n",
       " u'unmajestic',\n",
       " u'unobjected',\n",
       " u'unobjectionable',\n",
       " u'unobjectionableness',\n",
       " u'unobjectionably',\n",
       " u'unobjectional',\n",
       " u'unobjective',\n",
       " u'unprojected',\n",
       " u'unprojecting',\n",
       " u'unrejectable',\n",
       " u'unsubjectable',\n",
       " u'unsubjected',\n",
       " u'unsubjectedness',\n",
       " u'unsubjection',\n",
       " u'unsubjective',\n",
       " u'unsubjectlike']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note\n",
    "\n",
    "# Your Turn: The caret symbol ^ matches the start of a string, just like the $ matches the end. What results do we get with the above \n",
    "# example if we leave out both of these, and search for «..j..t..»?\n",
    "[w for w in wordlist if re.search('..j..t..', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally, the ? symbol specifies that the previous character is optional. Thus «^e-?mail$» will match both email and e-mail. We \n",
    "# could count the total number of occurrences of this word (in either spelling) in a text using \n",
    "# sum(1 for w in text if re.search('^e-?mail$', w))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ranges and Closures\n",
    "\n",
    "# The T9 system is used for entering text on mobile phones (see 3.5). Two or more words that are entered with the same sequence \n",
    "# of keystrokes are known as textonyms. For example, both hole and golf are entered by pressing the sequence 4653. What other words \n",
    "# could be produced with the same sequence? Here we use the regular expression «^[ghi][mno][jlk][def]$»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'gold', u'golf', u'hold', u'hole']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]\n",
    "# word can be the concatenation of [g|h|i] [m|n|o] [j|l|k] [d|e|f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The first part of the expression, «^[ghi]», matches the start of a word followed by g, h, or i. The next part of the expression, \n",
    "# «[mno]», constrains the second character to be m, n, or o. The third and fourth characters are also constrained. Only four words \n",
    "# satisfy all these constraints. Note that the order of characters inside the square brackets is not significant, so we could have \n",
    "# written «^[hig][nom][ljk][fed]$» and matched the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'g',\n",
       " u'ghoom',\n",
       " u'gig',\n",
       " u'giggling',\n",
       " u'gigolo',\n",
       " u'gilim',\n",
       " u'gill',\n",
       " u'gilling',\n",
       " u'gilo',\n",
       " u'gim',\n",
       " u'gin',\n",
       " u'ging',\n",
       " u'gingili',\n",
       " u'gink',\n",
       " u'ginkgo',\n",
       " u'ginning',\n",
       " u'gio',\n",
       " u'glink',\n",
       " u'glom',\n",
       " u'glonoin',\n",
       " u'gloom',\n",
       " u'glooming',\n",
       " u'gnomon',\n",
       " u'go',\n",
       " u'gog',\n",
       " u'gogo',\n",
       " u'goi',\n",
       " u'going',\n",
       " u'gol',\n",
       " u'goli',\n",
       " u'gon',\n",
       " u'gong',\n",
       " u'gonion',\n",
       " u'goo',\n",
       " u'googol',\n",
       " u'gook',\n",
       " u'gool',\n",
       " u'goon',\n",
       " u'h',\n",
       " u'hi',\n",
       " u'high',\n",
       " u'hill',\n",
       " u'him',\n",
       " u'hin',\n",
       " u'hing',\n",
       " u'hinoki',\n",
       " u'ho',\n",
       " u'hog',\n",
       " u'hoggin',\n",
       " u'hogling',\n",
       " u'hoi',\n",
       " u'hoin',\n",
       " u'holing',\n",
       " u'holl',\n",
       " u'hollin',\n",
       " u'hollo',\n",
       " u'hollong',\n",
       " u'holm',\n",
       " u'homo',\n",
       " u'homologon',\n",
       " u'hong',\n",
       " u'honk',\n",
       " u'hook',\n",
       " u'hoon',\n",
       " u'i',\n",
       " u'igloo',\n",
       " u'ihi',\n",
       " u'ilk',\n",
       " u'ill',\n",
       " u'imi',\n",
       " u'imino',\n",
       " u'immi',\n",
       " u'in',\n",
       " u'ing',\n",
       " u'ingoing',\n",
       " u'inion',\n",
       " u'ink',\n",
       " u'inkling',\n",
       " u'inlook',\n",
       " u'inn',\n",
       " u'inning',\n",
       " u'io',\n",
       " u'ion',\n",
       " u'j',\n",
       " u'jhool',\n",
       " u'jig',\n",
       " u'jing',\n",
       " u'jingling',\n",
       " u'jingo',\n",
       " u'jinjili',\n",
       " u'jink',\n",
       " u'jinn',\n",
       " u'jinni',\n",
       " u'jo',\n",
       " u'jog',\n",
       " u'johnin',\n",
       " u'join',\n",
       " u'joining',\n",
       " u'joll',\n",
       " u'joom',\n",
       " u'k',\n",
       " u'kiki',\n",
       " u'kil',\n",
       " u'kilhig',\n",
       " u'kilim',\n",
       " u'kill',\n",
       " u'killing',\n",
       " u'kiln',\n",
       " u'kilo',\n",
       " u'kim',\n",
       " u'kimono',\n",
       " u'kin',\n",
       " u'king',\n",
       " u'kingling',\n",
       " u'kink',\n",
       " u'kino',\n",
       " u'klom',\n",
       " u'knoll',\n",
       " u'ko',\n",
       " u'kohl',\n",
       " u'koi',\n",
       " u'koil',\n",
       " u'koilon',\n",
       " u'koinon',\n",
       " u'kokil',\n",
       " u'kokio',\n",
       " u'koko',\n",
       " u'kokoon',\n",
       " u'kolo',\n",
       " u'kolokolo',\n",
       " u'kon',\n",
       " u'kongoni',\n",
       " u'konini',\n",
       " u'l',\n",
       " u'li',\n",
       " u'lignin',\n",
       " u'liin',\n",
       " u'likin',\n",
       " u'liking',\n",
       " u'liknon',\n",
       " u'lill',\n",
       " u'lim',\n",
       " u'liming',\n",
       " u'limn',\n",
       " u'limonin',\n",
       " u'lin',\n",
       " u'ling',\n",
       " u'lingo',\n",
       " u'linin',\n",
       " u'lining',\n",
       " u'link',\n",
       " u'linking',\n",
       " u'linn',\n",
       " u'lino',\n",
       " u'linolin',\n",
       " u'linon',\n",
       " u'lion',\n",
       " u'lo',\n",
       " u'log',\n",
       " u'loggin',\n",
       " u'logging',\n",
       " u'login',\n",
       " u'logion',\n",
       " u'logoi',\n",
       " u'loin',\n",
       " u'loll',\n",
       " u'long',\n",
       " u'longing',\n",
       " u'loo',\n",
       " u'look',\n",
       " u'looking',\n",
       " u'loom',\n",
       " u'looming',\n",
       " u'loon',\n",
       " u'm',\n",
       " u'mho',\n",
       " u'mi',\n",
       " u'mig',\n",
       " u'miglio',\n",
       " u'mignon',\n",
       " u'mijl',\n",
       " u'mil',\n",
       " u'milk',\n",
       " u'milking',\n",
       " u'mill',\n",
       " u'milling',\n",
       " u'million',\n",
       " u'milo',\n",
       " u'mim',\n",
       " u'min',\n",
       " u'ming',\n",
       " u'minikin',\n",
       " u'minim',\n",
       " u'mining',\n",
       " u'minion',\n",
       " u'mink',\n",
       " u'minning',\n",
       " u'mino',\n",
       " u'mo',\n",
       " u'mog',\n",
       " u'mogo',\n",
       " u'moho',\n",
       " u'moil',\n",
       " u'moiling',\n",
       " u'moio',\n",
       " u'mojo',\n",
       " u'moki',\n",
       " u'moko',\n",
       " u'momo',\n",
       " u'mon',\n",
       " u'mong',\n",
       " u'monk',\n",
       " u'mono',\n",
       " u'moo',\n",
       " u'mooing',\n",
       " u'mool',\n",
       " u'moon',\n",
       " u'mooning',\n",
       " u'n',\n",
       " u'ni',\n",
       " u'nig',\n",
       " u'niggling',\n",
       " u'nigh',\n",
       " u'nil',\n",
       " u'nim',\n",
       " u'ninon',\n",
       " u'niog',\n",
       " u'no',\n",
       " u'nog',\n",
       " u'noggin',\n",
       " u'nogging',\n",
       " u'noil',\n",
       " u'noll',\n",
       " u'nolo',\n",
       " u'non',\n",
       " u'nonillion',\n",
       " u'nonion',\n",
       " u'nook',\n",
       " u'nooking',\n",
       " u'noon',\n",
       " u'nooning',\n",
       " u'o',\n",
       " u'oh',\n",
       " u'ohm',\n",
       " u'oho',\n",
       " u'oii',\n",
       " u'oil',\n",
       " u'oki',\n",
       " u'olio',\n",
       " u'olm',\n",
       " u'om',\n",
       " u'on',\n",
       " u'ongoing',\n",
       " u'onion',\n",
       " u'onlook',\n",
       " u'onlooking',\n",
       " u'oolong']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note\n",
    "\n",
    "# Your Turn: Look for some \"finger-twisters\", by searching for words that only use part of the number-pad. For example \n",
    "# «^[ghijklmno]+$», or more concisely, «^[g-o]+$», will match words that only use keys 4, 5, 6 in the center row, \n",
    "# and «^[a-fj-o]+$» will match words that use keys 2, 3, 5, 6 in the top-right corner. What do - and + mean?\n",
    "\n",
    "[w for w in wordlist if re.search('^[ghijklmno]+$', w)]\n",
    "# + means 1 or more instances of any of the characters in brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'aa',\n",
       " u'aal',\n",
       " u'aam',\n",
       " u'aba',\n",
       " u'abac',\n",
       " u'abaca',\n",
       " u'aback',\n",
       " u'abaff',\n",
       " u'abalone',\n",
       " u'abandon',\n",
       " u'abandonable',\n",
       " u'abandoned',\n",
       " u'abandonee',\n",
       " u'abb',\n",
       " u'abdal',\n",
       " u'abdomen',\n",
       " u'abeam',\n",
       " u'abed',\n",
       " u'abele',\n",
       " u'able',\n",
       " u'abloom',\n",
       " u'abode',\n",
       " u'abolla',\n",
       " u'aboma',\n",
       " u'aboon',\n",
       " u'academe',\n",
       " u'acana',\n",
       " u'acca',\n",
       " u'accede',\n",
       " u'accedence',\n",
       " u'accend',\n",
       " u'accolade',\n",
       " u'accoladed',\n",
       " u'accolle',\n",
       " u'accommodable',\n",
       " u'ace',\n",
       " u'ackman',\n",
       " u'acle',\n",
       " u'acme',\n",
       " u'acne',\n",
       " u'acnodal',\n",
       " u'acnode',\n",
       " u'acock',\n",
       " u'acold',\n",
       " u'acoma',\n",
       " u'acone',\n",
       " u'ad',\n",
       " u'adad',\n",
       " u'adance',\n",
       " u'add',\n",
       " u'adda',\n",
       " u'addable',\n",
       " u'added',\n",
       " u'addend',\n",
       " u'addenda',\n",
       " u'addle',\n",
       " u'ade',\n",
       " u'adead',\n",
       " u'adeem',\n",
       " u'adenocele',\n",
       " u'adenoma',\n",
       " u'adman',\n",
       " u'ado',\n",
       " u'adobe',\n",
       " u'ae',\n",
       " u'aefald',\n",
       " u'aenean',\n",
       " u'aeon',\n",
       " u'aface',\n",
       " u'affa',\n",
       " u'affable',\n",
       " u'aflame',\n",
       " u'afoam',\n",
       " u'ajaja',\n",
       " u'ak',\n",
       " u'aka',\n",
       " u'akala',\n",
       " u'ake',\n",
       " u'akeake',\n",
       " u'akee',\n",
       " u'aknee',\n",
       " u'ako',\n",
       " u'al',\n",
       " u'ala',\n",
       " u'alack',\n",
       " u'alada',\n",
       " u'alala',\n",
       " u'alameda',\n",
       " u'alamo',\n",
       " u'alan',\n",
       " u'aland',\n",
       " u'alb',\n",
       " u'alba',\n",
       " u'alban',\n",
       " u'albe',\n",
       " u'albedo',\n",
       " u'albee',\n",
       " u'alcalde',\n",
       " u'alcanna',\n",
       " u'alclad',\n",
       " u'alco',\n",
       " u'aldane',\n",
       " u'aldol',\n",
       " u'ale',\n",
       " u'aleak',\n",
       " u'alec',\n",
       " u'alee',\n",
       " u'alef',\n",
       " u'alem',\n",
       " u'alemana',\n",
       " u'alemmal',\n",
       " u'alen',\n",
       " u'alf',\n",
       " u'alfa',\n",
       " u'alfaje',\n",
       " u'alfalfa',\n",
       " u'aljoba',\n",
       " u'alk',\n",
       " u'alkane',\n",
       " u'alkene',\n",
       " u'alkenna',\n",
       " u'alkool',\n",
       " u'all',\n",
       " u'allan',\n",
       " u'allbone',\n",
       " u'allele',\n",
       " u'allemand',\n",
       " u'allemande',\n",
       " u'allene',\n",
       " u'allocable',\n",
       " u'alma',\n",
       " u'almanac',\n",
       " u'alme',\n",
       " u'almon',\n",
       " u'almond',\n",
       " u'aln',\n",
       " u'alo',\n",
       " u'alod',\n",
       " u'aloe',\n",
       " u'aloed',\n",
       " u'aloma',\n",
       " u'alone',\n",
       " u'aloof',\n",
       " u'am',\n",
       " u'ama',\n",
       " u'amakebe',\n",
       " u'amala',\n",
       " u'amalaka',\n",
       " u'amba',\n",
       " u'ambalam',\n",
       " u'amban',\n",
       " u'amble',\n",
       " u'ambo',\n",
       " u'ambomalleal',\n",
       " u'ambon',\n",
       " u'ame',\n",
       " u'ameed',\n",
       " u'ameen',\n",
       " u'amen',\n",
       " u'amenable',\n",
       " u'amend',\n",
       " u'amendable',\n",
       " u'amende',\n",
       " u'amene',\n",
       " u'amla',\n",
       " u'amma',\n",
       " u'amman',\n",
       " u'ammo',\n",
       " u'ammonal',\n",
       " u'ammono',\n",
       " u'amoeba',\n",
       " u'amoebae',\n",
       " u'amoebaean',\n",
       " u'amoeban',\n",
       " u'amok',\n",
       " u'amoke',\n",
       " u'amole',\n",
       " u'amomal',\n",
       " u'an',\n",
       " u'ana',\n",
       " u'anabo',\n",
       " u'anaconda',\n",
       " u'anadem',\n",
       " u'anal',\n",
       " u'analemma',\n",
       " u'anam',\n",
       " u'anama',\n",
       " u'anan',\n",
       " u'anana',\n",
       " u'ananda',\n",
       " u'anba',\n",
       " u'ancon',\n",
       " u'anconad',\n",
       " u'anconal',\n",
       " u'ancone',\n",
       " u'anconeal',\n",
       " u'and',\n",
       " u'anda',\n",
       " u'anele',\n",
       " u'anemonal',\n",
       " u'anemone',\n",
       " u'anemonol',\n",
       " u'anend',\n",
       " u'anjan',\n",
       " u'ankee',\n",
       " u'ankle',\n",
       " u'anklebone',\n",
       " u'anklejack',\n",
       " u'anlace',\n",
       " u'ann',\n",
       " u'anna',\n",
       " u'annal',\n",
       " u'annale',\n",
       " u'anneal',\n",
       " u'annona',\n",
       " u'anoa',\n",
       " u'anodal',\n",
       " u'anode',\n",
       " u'anole',\n",
       " u'anon',\n",
       " u'anonol',\n",
       " u'b',\n",
       " u'ba',\n",
       " u'baa',\n",
       " u'baal',\n",
       " u'baba',\n",
       " u'babble',\n",
       " u'babe',\n",
       " u'baboen',\n",
       " u'baboo',\n",
       " u'baboodom',\n",
       " u'baboon',\n",
       " u'bac',\n",
       " u'bacaba',\n",
       " u'bacalao',\n",
       " u'bacao',\n",
       " u'bacca',\n",
       " u'baccae',\n",
       " u'back',\n",
       " u'backband',\n",
       " u'backbone',\n",
       " u'backboned',\n",
       " u'backed',\n",
       " u'backen',\n",
       " u'backfall',\n",
       " u'backfold',\n",
       " u'bacon',\n",
       " u'bad',\n",
       " u'badan',\n",
       " u'baddock',\n",
       " u'bade',\n",
       " u'badland',\n",
       " u'bae',\n",
       " u'baff',\n",
       " u'baffle',\n",
       " u'bajada',\n",
       " u'bajan',\n",
       " u'baka',\n",
       " u'bakal',\n",
       " u'bake',\n",
       " u'baked',\n",
       " u'baken',\n",
       " u'bal',\n",
       " u'balafo',\n",
       " u'balance',\n",
       " u'balanceable',\n",
       " u'balanced',\n",
       " u'balancelle',\n",
       " u'balanceman',\n",
       " u'balanocele',\n",
       " u'balao',\n",
       " u'balboa',\n",
       " u'bald',\n",
       " u'balden',\n",
       " u'bale',\n",
       " u'baleen',\n",
       " u'balk',\n",
       " u'ball',\n",
       " u'ballad',\n",
       " u'ballade',\n",
       " u'ballam',\n",
       " u'ballan',\n",
       " u'balldom',\n",
       " u'balled',\n",
       " u'balloon',\n",
       " u'balm',\n",
       " u'balmacaan',\n",
       " u'balneal',\n",
       " u'balonea',\n",
       " u'baloo',\n",
       " u'bam',\n",
       " u'bamban',\n",
       " u'bamboo',\n",
       " u'ban',\n",
       " u'banaba',\n",
       " u'banak',\n",
       " u'banal',\n",
       " u'banana',\n",
       " u'banc',\n",
       " u'banca',\n",
       " u'bancal',\n",
       " u'banco',\n",
       " u'band',\n",
       " u'banda',\n",
       " u'bandaka',\n",
       " u'bandala',\n",
       " u'bandanna',\n",
       " u'bandannaed',\n",
       " u'bande',\n",
       " u'banded',\n",
       " u'bandle',\n",
       " u'bandman',\n",
       " u'bando',\n",
       " u'bane',\n",
       " u'banjo',\n",
       " u'bank',\n",
       " u'bankable',\n",
       " u'bankbook',\n",
       " u'banked',\n",
       " u'bankman',\n",
       " u'bannock',\n",
       " u'baobab',\n",
       " u'be',\n",
       " u'beacon',\n",
       " u'bead',\n",
       " u'beaded',\n",
       " u'beadle',\n",
       " u'beadledom',\n",
       " u'beadman',\n",
       " u'beak',\n",
       " u'beaked',\n",
       " u'beal',\n",
       " u'beala',\n",
       " u'beam',\n",
       " u'beamed',\n",
       " u'beamman',\n",
       " u'bean',\n",
       " u'beancod',\n",
       " u'beano',\n",
       " u'beback',\n",
       " u'beballed',\n",
       " u'bebed',\n",
       " u'bebled',\n",
       " u'beblood',\n",
       " u'bebloom',\n",
       " u'becall',\n",
       " u'becalm',\n",
       " u'beck',\n",
       " u'beckon',\n",
       " u'beclad',\n",
       " u'becloak',\n",
       " u'becolme',\n",
       " u'becombed',\n",
       " u'become',\n",
       " u'becomma',\n",
       " u'becoom',\n",
       " u'bed',\n",
       " u'bedabble',\n",
       " u'bedad',\n",
       " u'bedamn',\n",
       " u'bedded',\n",
       " u'bedead',\n",
       " u'bedeaf',\n",
       " u'bedeafen',\n",
       " u'bedeck',\n",
       " u'bedel',\n",
       " u'beden',\n",
       " u'bedene',\n",
       " u'bedlam',\n",
       " u'bedman',\n",
       " u'bee',\n",
       " u'beedom',\n",
       " u'beef',\n",
       " u'beek',\n",
       " u'beelol',\n",
       " u'beeman',\n",
       " u'been',\n",
       " u'befall',\n",
       " u'befame',\n",
       " u'befan',\n",
       " u'befanned',\n",
       " u'beflannel',\n",
       " u'beflea',\n",
       " u'befleck',\n",
       " u'befoam',\n",
       " u'befool',\n",
       " u'bejade',\n",
       " u'bejan',\n",
       " u'bejel',\n",
       " u'bekko',\n",
       " u'bel',\n",
       " u'bela',\n",
       " u'belaced',\n",
       " u'beladle',\n",
       " u'belam',\n",
       " u'belanda',\n",
       " u'beld',\n",
       " u'beldam',\n",
       " u'beleaf',\n",
       " u'belee',\n",
       " u'bell',\n",
       " u'belladonna',\n",
       " u'belle',\n",
       " u'belled',\n",
       " u'belledom',\n",
       " u'bellman',\n",
       " u'beloam',\n",
       " u'bema',\n",
       " u'bemad',\n",
       " u'bemadam',\n",
       " u'beman',\n",
       " u'bemeal',\n",
       " u'bemean',\n",
       " u'bemedaled',\n",
       " u'bemedalled',\n",
       " u'bemoan',\n",
       " u'bemoanable',\n",
       " u'bemock',\n",
       " u'bemole',\n",
       " u'bemoon',\n",
       " u'ben',\n",
       " u'bena',\n",
       " u'benab',\n",
       " u'bename',\n",
       " u'benben',\n",
       " u'bend',\n",
       " u'benda',\n",
       " u'bendable',\n",
       " u'bended',\n",
       " u'bene',\n",
       " u'benj',\n",
       " u'benn',\n",
       " u'benne',\n",
       " u'bennel',\n",
       " u'beno',\n",
       " u'beode',\n",
       " u'blab',\n",
       " u'black',\n",
       " u'blackback',\n",
       " u'blackball',\n",
       " u'blackband',\n",
       " u'blackcock',\n",
       " u'blacken',\n",
       " u'blackface',\n",
       " u'blackjack',\n",
       " u'blackland',\n",
       " u'blackneb',\n",
       " u'blackneck',\n",
       " u'blacknob',\n",
       " u'blad',\n",
       " u'blade',\n",
       " u'bladebone',\n",
       " u'bladed',\n",
       " u'blae',\n",
       " u'blaff',\n",
       " u'blake',\n",
       " u'blamable',\n",
       " u'blame',\n",
       " u'blamed',\n",
       " u'blan',\n",
       " u'blanc',\n",
       " u'blanca',\n",
       " u'blanco',\n",
       " u'bland',\n",
       " u'blanda',\n",
       " u'blank',\n",
       " u'blankbook',\n",
       " u'blanked',\n",
       " u'blankeel',\n",
       " u'bleak',\n",
       " u'bleb',\n",
       " u'bleck',\n",
       " u'blee',\n",
       " u'bleed',\n",
       " u'bleekbok',\n",
       " u'blend',\n",
       " u'blende',\n",
       " u'blended',\n",
       " u'blennocele',\n",
       " u'blennoma',\n",
       " u'bleo',\n",
       " u'blo',\n",
       " u'blob',\n",
       " u'blobbed',\n",
       " u'bloc',\n",
       " u'block',\n",
       " u'blockade',\n",
       " u'blocked',\n",
       " u'blockman',\n",
       " u'bloke',\n",
       " u'blonde',\n",
       " u'blood',\n",
       " u'blooded',\n",
       " u'bloodleaf',\n",
       " u'bloom',\n",
       " u'bloomfell',\n",
       " u'bo',\n",
       " u'boa',\n",
       " u'bob',\n",
       " u'boba',\n",
       " u'bobac',\n",
       " u'bobbed',\n",
       " u'bobble',\n",
       " u'bobo',\n",
       " u'bocal',\n",
       " u'bocca',\n",
       " u'boccale',\n",
       " u'bocce',\n",
       " u'boce',\n",
       " u'bock',\n",
       " u'bod',\n",
       " u'bode',\n",
       " u'boden',\n",
       " u'bodle',\n",
       " u'bodock',\n",
       " u'bojo',\n",
       " u'bokadam',\n",
       " u'boke',\n",
       " u'bokom',\n",
       " u'bola',\n",
       " u'bold',\n",
       " u'bolden',\n",
       " u'boldo',\n",
       " u'bole',\n",
       " u'boled',\n",
       " u'bolk',\n",
       " u'boll',\n",
       " u'bolled',\n",
       " u'bollock',\n",
       " u'bolo',\n",
       " u'boloman',\n",
       " u'bom',\n",
       " u'boma',\n",
       " u'bomb',\n",
       " u'bombable',\n",
       " u'bombed',\n",
       " u'bombo',\n",
       " u'bombola',\n",
       " u'bombonne',\n",
       " u'bon',\n",
       " u'bonbon',\n",
       " u'bonce',\n",
       " u'bond',\n",
       " u'bonded',\n",
       " u'bondfolk',\n",
       " u'bondman',\n",
       " u'bone',\n",
       " u'boneblack',\n",
       " u'boned',\n",
       " u'bonk',\n",
       " u'boo',\n",
       " u'boob',\n",
       " u'boobook',\n",
       " u'bood',\n",
       " u'boodle',\n",
       " u'boodledom',\n",
       " u'boof',\n",
       " u'book',\n",
       " u'bookable',\n",
       " u'bookdom',\n",
       " u'booked',\n",
       " u'bookfold',\n",
       " u'bookland',\n",
       " u'bookman',\n",
       " u'bool',\n",
       " u'boom',\n",
       " u'boomable',\n",
       " u'boon',\n",
       " u'boondock',\n",
       " u'boonk',\n",
       " u'c',\n",
       " u'ca',\n",
       " u'caam',\n",
       " u'caama',\n",
       " u'cab',\n",
       " u'caba',\n",
       " u'cabaan',\n",
       " u'caback',\n",
       " u'cabal',\n",
       " u'cabala',\n",
       " u'caban',\n",
       " u'cabana',\n",
       " u'cabble',\n",
       " u'cabda',\n",
       " u'cable',\n",
       " u'cabled',\n",
       " u'cableman',\n",
       " u'cabman',\n",
       " u'cabob',\n",
       " u'cabocle',\n",
       " u'caboodle',\n",
       " u'cabook',\n",
       " u'cacam',\n",
       " u'cacao',\n",
       " u'cack',\n",
       " u'cackle',\n",
       " u'cacodemon',\n",
       " u'cacoon',\n",
       " u'cad',\n",
       " u'cadalene',\n",
       " u'cadamba',\n",
       " u'caddle',\n",
       " u'cade',\n",
       " u'cadelle',\n",
       " u'cadence',\n",
       " u'cadenced',\n",
       " u'cadjan',\n",
       " u'cadlock',\n",
       " u'caeca',\n",
       " u'caecal',\n",
       " u'caeoma',\n",
       " u'caffa',\n",
       " u'caffeol',\n",
       " u'caffeone',\n",
       " u'caffle',\n",
       " u'cajole',\n",
       " u'cake',\n",
       " u'cal',\n",
       " u'calaba',\n",
       " u'calade',\n",
       " u'calamanco',\n",
       " u'calambac',\n",
       " u'calcaneal',\n",
       " u'calced',\n",
       " u'calden',\n",
       " u'calean',\n",
       " u'calendal',\n",
       " u'calf',\n",
       " u'calk',\n",
       " u'call',\n",
       " u'callable',\n",
       " u'callo',\n",
       " u'calm',\n",
       " u'calodemon',\n",
       " u'calomba',\n",
       " u'calomel',\n",
       " u'calool',\n",
       " u'cam',\n",
       " u'camaca',\n",
       " u'caman',\n",
       " u'camb',\n",
       " u'came',\n",
       " u'camel',\n",
       " u'camelback',\n",
       " u'camelman',\n",
       " u'cameo',\n",
       " u'cammed',\n",
       " u'cammock',\n",
       " u'can',\n",
       " u'canaba',\n",
       " u'canada',\n",
       " u'canadol',\n",
       " u'canal',\n",
       " u'canalman',\n",
       " u'canamo',\n",
       " u'cancan',\n",
       " u'cancel',\n",
       " u'cancelable',\n",
       " u'cand',\n",
       " u'candela',\n",
       " u'candle',\n",
       " u'candleball',\n",
       " u'candlebeam',\n",
       " u'candlebomb',\n",
       " u'candock',\n",
       " u'cane',\n",
       " u'canel',\n",
       " u'canella',\n",
       " u'canelo',\n",
       " u'canjac',\n",
       " u'cank',\n",
       " u'canman',\n",
       " u'canna',\n",
       " u'canned',\n",
       " u'cannel',\n",
       " u'cannon',\n",
       " u'cannonade',\n",
       " u'cannoned',\n",
       " u'canoe',\n",
       " u'canoeload',\n",
       " u'canoeman',\n",
       " u'canon',\n",
       " u'canoodle',\n",
       " u'caoba',\n",
       " u'ce',\n",
       " u'cebell',\n",
       " u'cede',\n",
       " u'cee',\n",
       " u'celadon',\n",
       " u'cell',\n",
       " u'cella',\n",
       " u'cellae',\n",
       " u'celled',\n",
       " u'cello',\n",
       " u'cembalo',\n",
       " u'cenacle',\n",
       " u'clack',\n",
       " u'clad',\n",
       " u'cladode',\n",
       " u'clam',\n",
       " u'clamb',\n",
       " u'clambake',\n",
       " u'clame',\n",
       " u'clammed',\n",
       " u'clan',\n",
       " u'clank',\n",
       " u'clanned',\n",
       " u'clead',\n",
       " u'cleaded',\n",
       " u'cleam',\n",
       " u'clean',\n",
       " u'cleanable',\n",
       " u'cleck',\n",
       " u'cled',\n",
       " u'clee',\n",
       " u'cleek',\n",
       " u'cleeked',\n",
       " u'clef',\n",
       " u'clem',\n",
       " u'clemence',\n",
       " u'cloaca',\n",
       " u'cloacal',\n",
       " u'cloacean',\n",
       " u'cloak',\n",
       " u'cloaked',\n",
       " u'cloam',\n",
       " u'cloamen',\n",
       " u'clock',\n",
       " u'clocked',\n",
       " u'clockface',\n",
       " u'clod',\n",
       " u'cloff',\n",
       " u'clomb',\n",
       " u'clomben',\n",
       " u'clonal',\n",
       " u'clone',\n",
       " u'cloof',\n",
       " u'coabode',\n",
       " u'coadjacence',\n",
       " u'coak',\n",
       " u'coal',\n",
       " u'cob',\n",
       " u'cobaea',\n",
       " u'cobbed',\n",
       " u'cobble',\n",
       " u'cobcab',\n",
       " u'coble',\n",
       " u'cobleman',\n",
       " u'cobloaf',\n",
       " u'cobola',\n",
       " u'coca',\n",
       " u'coccal',\n",
       " u'cocco',\n",
       " u'cock',\n",
       " u'cockade',\n",
       " u'cockaded',\n",
       " u'cockal',\n",
       " u'cockbell',\n",
       " u'cocked',\n",
       " u'cockle',\n",
       " u'cockled',\n",
       " u'coco',\n",
       " u'cocoa',\n",
       " u'cocobolo',\n",
       " u'cocoon',\n",
       " u'cod',\n",
       " u'coda',\n",
       " u'codbank',\n",
       " u'coddle',\n",
       " u'code',\n",
       " u'codman',\n",
       " u'codo',\n",
       " u'codol',\n",
       " u'codon',\n",
       " u'coe',\n",
       " u'coecal',\n",
       " u'coed',\n",
       " u'coelom',\n",
       " u'coeloma',\n",
       " u'coembedded',\n",
       " u'coenflame',\n",
       " u'coenobe',\n",
       " u'cofeoffee',\n",
       " u'coff',\n",
       " u'coffee',\n",
       " u'coffeecake',\n",
       " u'coffeeleaf',\n",
       " u'coffle',\n",
       " u'coke',\n",
       " u'cokeman',\n",
       " u'col',\n",
       " u'cola',\n",
       " u'colane',\n",
       " u'colback',\n",
       " u'colcannon',\n",
       " u'cold',\n",
       " u'cole',\n",
       " u'colecannon',\n",
       " u'colk',\n",
       " u'coll',\n",
       " u'colleen',\n",
       " u'collembolan',\n",
       " u'collembole',\n",
       " u'collocal',\n",
       " u'collock',\n",
       " u'coloboma',\n",
       " u'colocola',\n",
       " u'colon',\n",
       " u'colonel',\n",
       " u'colonnade',\n",
       " u'colonnaded',\n",
       " u'coma',\n",
       " u'comal',\n",
       " u'comb',\n",
       " u'combed',\n",
       " u'comble',\n",
       " u'come',\n",
       " u'comeback',\n",
       " u'comedo',\n",
       " u'comma',\n",
       " u'command',\n",
       " u'commandable',\n",
       " u'commando',\n",
       " u'commandoman',\n",
       " u'commeddle',\n",
       " u'commence',\n",
       " u'commenceable',\n",
       " u'commend',\n",
       " u'commendable',\n",
       " u'commendam',\n",
       " u'commode',\n",
       " u'common',\n",
       " u'commonable',\n",
       " u'con',\n",
       " u'conal',\n",
       " u'conamed',\n",
       " u'conceal',\n",
       " u'concealable',\n",
       " u'concealed',\n",
       " u'concede',\n",
       " u'conceded',\n",
       " u'cond',\n",
       " u'condemn',\n",
       " u'condemnable',\n",
       " u'condemned',\n",
       " u'condole',\n",
       " u'condolence',\n",
       " u'condonable',\n",
       " u'condonance',\n",
       " u'condone',\n",
       " u'cone',\n",
       " u'coned',\n",
       " u'coneen',\n",
       " u'confab',\n",
       " u'confocal',\n",
       " u'conjobble',\n",
       " u'conk',\n",
       " u'conkanee',\n",
       " u'conn',\n",
       " u'coo',\n",
       " u'cooba',\n",
       " u'coodle',\n",
       " u'cooee',\n",
       " u'coof',\n",
       " u'cooja',\n",
       " u'cook',\n",
       " u'cookable',\n",
       " u'cookbook',\n",
       " u'cookdom',\n",
       " u'cookee',\n",
       " u'cool',\n",
       " u'coolen',\n",
       " u'coom',\n",
       " u'coomb',\n",
       " u'coon',\n",
       " u'cooncan',\n",
       " u'd',\n",
       " u'da',\n",
       " u'dab',\n",
       " u'dabb',\n",
       " u'dabba',\n",
       " u'dabble',\n",
       " u'dace',\n",
       " u'dad',\n",
       " u'dada',\n",
       " u'daddle',\n",
       " u'daddock',\n",
       " u'dade',\n",
       " u'dado',\n",
       " u'dae',\n",
       " u'daedal',\n",
       " u'daemon',\n",
       " u'daff',\n",
       " u'daffle',\n",
       " u'dak',\n",
       " u'dal',\n",
       " u'dale',\n",
       " u'daleman',\n",
       " u'dalk',\n",
       " u'dallack',\n",
       " u'dalle',\n",
       " u'dam',\n",
       " u'dama',\n",
       " u'daman',\n",
       " u'dame',\n",
       " u'damme',\n",
       " u'damn',\n",
       " u'damnable',\n",
       " u'damned',\n",
       " u'dan',\n",
       " u'dance',\n",
       " u'dand',\n",
       " u'danda',\n",
       " u'dandle',\n",
       " u'dank',\n",
       " u'dannock',\n",
       " u'dao',\n",
       " u'de',\n",
       " u'deacon',\n",
       " u'deaconal',\n",
       " u'dead',\n",
       " u'deaden',\n",
       " u'deadfall',\n",
       " u'deadlock',\n",
       " u'deadman',\n",
       " u'deaf',\n",
       " u'deafen',\n",
       " u'deal',\n",
       " u'dealable',\n",
       " u'dean',\n",
       " u'deb',\n",
       " u'debacle',\n",
       " u'deben',\n",
       " u'decad',\n",
       " u'decadal',\n",
       " u'decade',\n",
       " u'decadence',\n",
       " u'decal',\n",
       " u'decan',\n",
       " u'decanal',\n",
       " u'decane',\n",
       " u'decence',\n",
       " u'decene',\n",
       " u'decennal',\n",
       " u'deck',\n",
       " u'decke',\n",
       " u'decked',\n",
       " u'deckel',\n",
       " u'deckle',\n",
       " u'deckload',\n",
       " u'decode',\n",
       " u'decoke',\n",
       " u'dedo',\n",
       " u'dee',\n",
       " u'deed',\n",
       " u'deedeed',\n",
       " u'deem',\n",
       " u'deface',\n",
       " u'defaceable',\n",
       " u'defalk',\n",
       " u'defame',\n",
       " u'defamed',\n",
       " u'defence',\n",
       " u'defend',\n",
       " u'defendable',\n",
       " u'dekko',\n",
       " u'dekle',\n",
       " u'dele',\n",
       " u'delead',\n",
       " u'delenda',\n",
       " u'delf',\n",
       " u'dell',\n",
       " u'demal',\n",
       " u'demand',\n",
       " u'demandable',\n",
       " u'deme',\n",
       " u'demean',\n",
       " u'demob',\n",
       " u'demoded',\n",
       " u'demon',\n",
       " u'demonland',\n",
       " u'den',\n",
       " u'denda',\n",
       " u'dene',\n",
       " u'deodand',\n",
       " u'do',\n",
       " u'doab',\n",
       " u'doable',\n",
       " u'dob',\n",
       " u'dobbed',\n",
       " u'dobe',\n",
       " u'dobla',\n",
       " u'doblon',\n",
       " u'doc',\n",
       " u'dock',\n",
       " u'docken',\n",
       " u'dockland',\n",
       " u'dockman',\n",
       " u'docmac',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[a-fj-o]+$', w)]\n",
    "# - means a range. So match any letters between a and f or j and o a minumum of 1 instance\n",
    "# alternatively, any word that does not have the letters g, h, i, p, q, r, s, t, u, v, w, x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " u'miiiiiinnnnnnnnnneeeeeeee',\n",
       " u'mine',\n",
       " u'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the + symbol a bit further. Notice that it can be applied to individual letters, or to bracketed sets of letters:\n",
    "\n",
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))\n",
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]\n",
    "# I predict this means [one or more m, one or more i, one or more n, one or more e]\n",
    "# this makes sense when you look at chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a',\n",
       " u'aaaaaaaaaaaaaaaaa',\n",
       " u'aaahhhh',\n",
       " u'ah',\n",
       " u'ahah',\n",
       " u'ahahah',\n",
       " u'ahh',\n",
       " u'ahhahahaha',\n",
       " u'ahhh',\n",
       " u'ahhhh',\n",
       " u'ahhhhhh',\n",
       " u'ahhhhhhhhhhhhhh',\n",
       " u'h',\n",
       " u'ha',\n",
       " u'haaa',\n",
       " u'hah',\n",
       " u'haha',\n",
       " u'hahaaa',\n",
       " u'hahah',\n",
       " u'hahaha',\n",
       " u'hahahaa',\n",
       " u'hahahah',\n",
       " u'hahahaha',\n",
       " u'hahahahaaa',\n",
       " u'hahahahahaha',\n",
       " u'hahahahahahaha',\n",
       " u'hahahahahahahahahahahahahahahaha',\n",
       " u'hahahhahah',\n",
       " u'hahhahahaha']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^[ha]+$', w)]\n",
    "# I predict this is one or more of h or a. This could be words like haha, haaahaaa, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0.0085',\n",
       " u'0.05',\n",
       " u'0.1',\n",
       " u'0.16',\n",
       " u'0.2',\n",
       " u'0.25',\n",
       " u'0.28',\n",
       " u'0.3',\n",
       " u'0.4',\n",
       " u'0.5',\n",
       " u'0.50',\n",
       " u'0.54',\n",
       " u'0.56',\n",
       " u'0.60',\n",
       " u'0.7',\n",
       " u'0.82',\n",
       " u'0.84',\n",
       " u'0.9',\n",
       " u'0.95',\n",
       " u'0.99',\n",
       " u'1.01',\n",
       " u'1.1',\n",
       " u'1.125',\n",
       " u'1.14',\n",
       " u'1.1650',\n",
       " u'1.17',\n",
       " u'1.18',\n",
       " u'1.19',\n",
       " u'1.2',\n",
       " u'1.20',\n",
       " u'1.24',\n",
       " u'1.25',\n",
       " u'1.26',\n",
       " u'1.28',\n",
       " u'1.35',\n",
       " u'1.39',\n",
       " u'1.4',\n",
       " u'1.457',\n",
       " u'1.46',\n",
       " u'1.49',\n",
       " u'1.5',\n",
       " u'1.50',\n",
       " u'1.55',\n",
       " u'1.56',\n",
       " u'1.5755',\n",
       " u'1.5805',\n",
       " u'1.6',\n",
       " u'1.61',\n",
       " u'1.637',\n",
       " u'1.64',\n",
       " u'1.65',\n",
       " u'1.7',\n",
       " u'1.75',\n",
       " u'1.76',\n",
       " u'1.8',\n",
       " u'1.82',\n",
       " u'1.8415',\n",
       " u'1.85',\n",
       " u'1.8500',\n",
       " u'1.9',\n",
       " u'1.916',\n",
       " u'1.92',\n",
       " u'10.19',\n",
       " u'10.2',\n",
       " u'10.5',\n",
       " u'107.03',\n",
       " u'107.9',\n",
       " u'109.73',\n",
       " u'11.10',\n",
       " u'11.5',\n",
       " u'11.57',\n",
       " u'11.6',\n",
       " u'11.72',\n",
       " u'11.95',\n",
       " u'112.9',\n",
       " u'113.2',\n",
       " u'116.3',\n",
       " u'116.4',\n",
       " u'116.7',\n",
       " u'116.9',\n",
       " u'118.6',\n",
       " u'12.09',\n",
       " u'12.5',\n",
       " u'12.52',\n",
       " u'12.68',\n",
       " u'12.7',\n",
       " u'12.82',\n",
       " u'12.97',\n",
       " u'120.7',\n",
       " u'1206.26',\n",
       " u'121.6',\n",
       " u'126.1',\n",
       " u'126.15',\n",
       " u'127.03',\n",
       " u'129.91',\n",
       " u'13.1',\n",
       " u'13.15',\n",
       " u'13.5',\n",
       " u'13.50',\n",
       " u'13.625',\n",
       " u'13.65',\n",
       " u'13.73',\n",
       " u'13.8',\n",
       " u'13.90',\n",
       " u'130.6',\n",
       " u'130.7',\n",
       " u'131.01',\n",
       " u'132.9',\n",
       " u'133.7',\n",
       " u'133.8',\n",
       " u'14.00',\n",
       " u'14.13',\n",
       " u'14.26',\n",
       " u'14.28',\n",
       " u'14.43',\n",
       " u'14.5',\n",
       " u'14.53',\n",
       " u'14.54',\n",
       " u'14.6',\n",
       " u'14.75',\n",
       " u'14.99',\n",
       " u'141.9',\n",
       " u'142.84',\n",
       " u'142.85',\n",
       " u'143.08',\n",
       " u'143.80',\n",
       " u'143.93',\n",
       " u'148.9',\n",
       " u'149.9',\n",
       " u'15.5',\n",
       " u'150.00',\n",
       " u'153.3',\n",
       " u'154.2',\n",
       " u'16.05',\n",
       " u'16.09',\n",
       " u'16.125',\n",
       " u'16.2',\n",
       " u'16.5',\n",
       " u'16.68',\n",
       " u'16.7',\n",
       " u'16.9',\n",
       " u'169.9',\n",
       " u'17.3',\n",
       " u'17.4',\n",
       " u'17.5',\n",
       " u'17.95',\n",
       " u'1738.1',\n",
       " u'176.1',\n",
       " u'18.3',\n",
       " u'18.6',\n",
       " u'18.95',\n",
       " u'185.9',\n",
       " u'188.84',\n",
       " u'19.3',\n",
       " u'19.50',\n",
       " u'19.6',\n",
       " u'19.94',\n",
       " u'19.95',\n",
       " u'191.9',\n",
       " u'2.07',\n",
       " u'2.1',\n",
       " u'2.15',\n",
       " u'2.19',\n",
       " u'2.2',\n",
       " u'2.25',\n",
       " u'2.29',\n",
       " u'2.3',\n",
       " u'2.30',\n",
       " u'2.35',\n",
       " u'2.375',\n",
       " u'2.4',\n",
       " u'2.42',\n",
       " u'2.44',\n",
       " u'2.46',\n",
       " u'2.47',\n",
       " u'2.5',\n",
       " u'2.50',\n",
       " u'2.6',\n",
       " u'2.62',\n",
       " u'2.65',\n",
       " u'2.7',\n",
       " u'2.75',\n",
       " u'2.8',\n",
       " u'2.80',\n",
       " u'2.87',\n",
       " u'2.875',\n",
       " u'2.9',\n",
       " u'2.95',\n",
       " u'20.07',\n",
       " u'20.5',\n",
       " u'21.1',\n",
       " u'21.9',\n",
       " u'2141.7',\n",
       " u'2160.1',\n",
       " u'2163.2',\n",
       " u'22.75',\n",
       " u'220.45',\n",
       " u'221.4',\n",
       " u'225.6',\n",
       " u'23.25',\n",
       " u'23.4',\n",
       " u'23.5',\n",
       " u'23.72',\n",
       " u'234.4',\n",
       " u'236.74',\n",
       " u'236.79',\n",
       " u'24.95',\n",
       " u'25.50',\n",
       " u'25.6',\n",
       " u'251.2',\n",
       " u'26.2',\n",
       " u'26.5',\n",
       " u'26.8',\n",
       " u'263.07',\n",
       " u'2645.90',\n",
       " u'2691.19',\n",
       " u'27.1',\n",
       " u'27.4',\n",
       " u'273.5',\n",
       " u'278.7',\n",
       " u'28.25',\n",
       " u'28.36',\n",
       " u'28.4',\n",
       " u'28.5',\n",
       " u'28.53',\n",
       " u'28.6',\n",
       " u'29.3',\n",
       " u'29.4',\n",
       " u'29.9',\n",
       " u'292.32',\n",
       " u'3.01',\n",
       " u'3.04',\n",
       " u'3.1',\n",
       " u'3.16',\n",
       " u'3.18',\n",
       " u'3.19',\n",
       " u'3.2',\n",
       " u'3.20',\n",
       " u'3.23',\n",
       " u'3.253',\n",
       " u'3.28',\n",
       " u'3.3',\n",
       " u'3.35',\n",
       " u'3.375',\n",
       " u'3.4',\n",
       " u'3.42',\n",
       " u'3.43',\n",
       " u'3.5',\n",
       " u'3.55',\n",
       " u'3.6',\n",
       " u'3.61',\n",
       " u'3.625',\n",
       " u'3.7',\n",
       " u'3.75',\n",
       " u'3.8',\n",
       " u'3.80',\n",
       " u'3.9',\n",
       " u'30.6',\n",
       " u'30.9',\n",
       " u'319.75',\n",
       " u'32.8',\n",
       " u'334.5',\n",
       " u'34.625',\n",
       " u'341.20',\n",
       " u'3436.58',\n",
       " u'35.2',\n",
       " u'35.7',\n",
       " u'352.7',\n",
       " u'352.9',\n",
       " u'35500.64',\n",
       " u'35564.43',\n",
       " u'36.9',\n",
       " u'361.8',\n",
       " u'3648.82',\n",
       " u'37.3',\n",
       " u'37.5',\n",
       " u'372.14',\n",
       " u'372.9',\n",
       " u'374.19',\n",
       " u'374.20',\n",
       " u'377.60',\n",
       " u'38.3',\n",
       " u'38.375',\n",
       " u'38.5',\n",
       " u'38.875',\n",
       " u'387.8',\n",
       " u'4.1',\n",
       " u'4.10',\n",
       " u'4.2',\n",
       " u'4.25',\n",
       " u'4.3',\n",
       " u'4.4',\n",
       " u'4.5',\n",
       " u'4.55',\n",
       " u'4.6',\n",
       " u'4.7',\n",
       " u'4.75',\n",
       " u'4.8',\n",
       " u'4.875',\n",
       " u'4.898',\n",
       " u'4.9',\n",
       " u'40.21',\n",
       " u'41.60',\n",
       " u'415.6',\n",
       " u'415.8',\n",
       " u'42.1',\n",
       " u'42.5',\n",
       " u'422.5',\n",
       " u'43.875',\n",
       " u'434.4',\n",
       " u'436.01',\n",
       " u'446.62',\n",
       " u'449.04',\n",
       " u'45.2',\n",
       " u'45.3',\n",
       " u'45.75',\n",
       " u'456.64',\n",
       " u'46.1',\n",
       " u'47.1',\n",
       " u'47.125',\n",
       " u'47.5',\n",
       " u'47.6',\n",
       " u'49.9',\n",
       " u'494.50',\n",
       " u'497.34',\n",
       " u'5.1',\n",
       " u'5.2180',\n",
       " u'5.276',\n",
       " u'5.29',\n",
       " u'5.3',\n",
       " u'5.39',\n",
       " u'5.4',\n",
       " u'5.435',\n",
       " u'5.5',\n",
       " u'5.57',\n",
       " u'5.6',\n",
       " u'5.63',\n",
       " u'5.7',\n",
       " u'5.70',\n",
       " u'5.8',\n",
       " u'5.82',\n",
       " u'5.9',\n",
       " u'5.92',\n",
       " u'50.1',\n",
       " u'50.38',\n",
       " u'50.45',\n",
       " u'51.25',\n",
       " u'51.6',\n",
       " u'55.1',\n",
       " u'566.54',\n",
       " u'57.50',\n",
       " u'57.6',\n",
       " u'57.7',\n",
       " u'58.64',\n",
       " u'59.6',\n",
       " u'59.9',\n",
       " u'6.03',\n",
       " u'6.1',\n",
       " u'6.20',\n",
       " u'6.21',\n",
       " u'6.25',\n",
       " u'6.4',\n",
       " u'6.40',\n",
       " u'6.44',\n",
       " u'6.5',\n",
       " u'6.50',\n",
       " u'6.53',\n",
       " u'6.6',\n",
       " u'6.7',\n",
       " u'6.70',\n",
       " u'6.79',\n",
       " u'6.84',\n",
       " u'6.9',\n",
       " u'60.36',\n",
       " u'618.1',\n",
       " u'62.1',\n",
       " u'62.5',\n",
       " u'62.625',\n",
       " u'63.79',\n",
       " u'630.9',\n",
       " u'64.5',\n",
       " u'66.5',\n",
       " u'7.15',\n",
       " u'7.2',\n",
       " u'7.20',\n",
       " u'7.272',\n",
       " u'7.3',\n",
       " u'7.4',\n",
       " u'7.40',\n",
       " u'7.422',\n",
       " u'7.45',\n",
       " u'7.458',\n",
       " u'7.5',\n",
       " u'7.50',\n",
       " u'7.52',\n",
       " u'7.55',\n",
       " u'7.60',\n",
       " u'7.62',\n",
       " u'7.63',\n",
       " u'7.65',\n",
       " u'7.74',\n",
       " u'7.78',\n",
       " u'7.79',\n",
       " u'7.8',\n",
       " u'7.80',\n",
       " u'7.84',\n",
       " u'7.88',\n",
       " u'7.90',\n",
       " u'7.95',\n",
       " u'70.2',\n",
       " u'70.7',\n",
       " u'705.6',\n",
       " u'72.7',\n",
       " u'734.9',\n",
       " u'737.5',\n",
       " u'77.56',\n",
       " u'77.6',\n",
       " u'77.70',\n",
       " u'8.04',\n",
       " u'8.06',\n",
       " u'8.07',\n",
       " u'8.1',\n",
       " u'8.12',\n",
       " u'8.14',\n",
       " u'8.15',\n",
       " u'8.19',\n",
       " u'8.2',\n",
       " u'8.22',\n",
       " u'8.25',\n",
       " u'8.30',\n",
       " u'8.35',\n",
       " u'8.45',\n",
       " u'8.467',\n",
       " u'8.47',\n",
       " u'8.48',\n",
       " u'8.5',\n",
       " u'8.50',\n",
       " u'8.53',\n",
       " u'8.55',\n",
       " u'8.56',\n",
       " u'8.575',\n",
       " u'8.60',\n",
       " u'8.64',\n",
       " u'8.65',\n",
       " u'8.70',\n",
       " u'8.75',\n",
       " u'8.9',\n",
       " u'80.50',\n",
       " u'80.8',\n",
       " u'81.8',\n",
       " u'811.9',\n",
       " u'83.4',\n",
       " u'84.29',\n",
       " u'84.9',\n",
       " u'85.1',\n",
       " u'85.7',\n",
       " u'86.12',\n",
       " u'87.5',\n",
       " u'88.32',\n",
       " u'89.7',\n",
       " u'89.9',\n",
       " u'9.3',\n",
       " u'9.32',\n",
       " u'9.37',\n",
       " u'9.45',\n",
       " u'9.5',\n",
       " u'9.625',\n",
       " u'9.75',\n",
       " u'9.8',\n",
       " u'9.82',\n",
       " u'9.9',\n",
       " u'92.9',\n",
       " u'93.3',\n",
       " u'93.9',\n",
       " u'94.2',\n",
       " u'94.8',\n",
       " u'95.09',\n",
       " u'96.4',\n",
       " u'98.3',\n",
       " u'99.1',\n",
       " u'99.3']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It should be clear that + simply means \"one or more instances of the preceding item\", which could be an individual character \n",
    "# like m, a set like [fed] or a range like [d-f]. Now let's replace + with *, which means \"zero or more instances of the preceding \n",
    "# item\". The regular expression «^m*i*n*e*$» will match everything that we found using «^m+i+n+e+$», but also words where some of \n",
    "# the letters don't appear at all, e.g. me, min, and mmmmm. Note that the + and * symbols are sometimes referred to as Kleene \n",
    "# closures, or simply closures.\n",
    "\n",
    "# The ^ operator has another function when it appears as the first character inside square brackets. For example «[^aeiouAEIOU]» \n",
    "# matches any character other than a vowel. We can search the NPS Chat Corpus for words that are made up entirely of non-vowel \n",
    "# characters using «^[^aeiouAEIOU]+$» to find items like these: :):):), grrr, cyb3r and zzzzzzzz. Notice this includes \n",
    "# non-alphabetic characters.\n",
    "\n",
    "# Here are some more examples of regular expressions being used to find tokens that match a particular pattern, illustrating \n",
    "# the use of some new symbols: \\, {}, (), and |:\n",
    "\n",
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
    "# beginning ^ means start\n",
    "# [one or more numbers] . [one or more numbers]\n",
    "# $ means the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'C$', u'US$']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "# Prediction: one or more capital letters followed by $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1614',\n",
       " u'1637',\n",
       " u'1787',\n",
       " u'1901',\n",
       " u'1903',\n",
       " u'1917',\n",
       " u'1925',\n",
       " u'1929',\n",
       " u'1933',\n",
       " u'1934',\n",
       " u'1948',\n",
       " u'1953',\n",
       " u'1955',\n",
       " u'1956',\n",
       " u'1961',\n",
       " u'1965',\n",
       " u'1966',\n",
       " u'1967',\n",
       " u'1968',\n",
       " u'1969',\n",
       " u'1970',\n",
       " u'1971',\n",
       " u'1972',\n",
       " u'1973',\n",
       " u'1975',\n",
       " u'1976',\n",
       " u'1977',\n",
       " u'1979',\n",
       " u'1980',\n",
       " u'1981',\n",
       " u'1982',\n",
       " u'1983',\n",
       " u'1984',\n",
       " u'1985',\n",
       " u'1986',\n",
       " u'1987',\n",
       " u'1988',\n",
       " u'1989',\n",
       " u'1990',\n",
       " u'1991',\n",
       " u'1992',\n",
       " u'1993',\n",
       " u'1994',\n",
       " u'1995',\n",
       " u'1996',\n",
       " u'1997',\n",
       " u'1998',\n",
       " u'1999',\n",
       " u'2000',\n",
       " u'2005',\n",
       " u'2009',\n",
       " u'2017',\n",
       " u'2019',\n",
       " u'2029',\n",
       " u'3057',\n",
       " u'8300']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
    "# Prediction: [start] [four numbers] [end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'10-day',\n",
       " u'10-lap',\n",
       " u'10-year',\n",
       " u'100-share',\n",
       " u'12-point',\n",
       " u'12-year',\n",
       " u'14-hour',\n",
       " u'15-day',\n",
       " u'150-point',\n",
       " u'190-point',\n",
       " u'20-point',\n",
       " u'20-stock',\n",
       " u'21-month',\n",
       " u'237-seat',\n",
       " u'240-page',\n",
       " u'27-year',\n",
       " u'30-day',\n",
       " u'30-point',\n",
       " u'30-share',\n",
       " u'30-year',\n",
       " u'300-day',\n",
       " u'36-day',\n",
       " u'36-store',\n",
       " u'42-year',\n",
       " u'50-state',\n",
       " u'500-stock',\n",
       " u'52-week',\n",
       " u'69-point',\n",
       " u'84-month',\n",
       " u'87-store',\n",
       " u'90-day']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
    "# Prediction: [start] [1 or more numbers] - [3-5 letters] [end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'black-and-white',\n",
       " u'bread-and-butter',\n",
       " u'father-in-law',\n",
       " u'machine-gun-toting',\n",
       " u'savings-and-loan']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
    "# Prediction: [start] [5 or more lowercase letters] - [2-3 lowercase letters] - [no more than 6 lowercase letters] [end]\n",
    "# Yes! I got it right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'62%-owned',\n",
       " u'Absorbed',\n",
       " u'According',\n",
       " u'Adopting',\n",
       " u'Advanced',\n",
       " u'Advancing',\n",
       " u'Alfred',\n",
       " u'Allied',\n",
       " u'Annualized',\n",
       " u'Anything',\n",
       " u'Arbitrage-related',\n",
       " u'Arbitraging',\n",
       " u'Asked',\n",
       " u'Assuming',\n",
       " u'Atlanta-based',\n",
       " u'Baking',\n",
       " u'Banking',\n",
       " u'Beginning',\n",
       " u'Beijing',\n",
       " u'Being',\n",
       " u'Bermuda-based',\n",
       " u'Betting',\n",
       " u'Boeing',\n",
       " u'Broadcasting',\n",
       " u'Bucking',\n",
       " u'Buying',\n",
       " u'Calif.-based',\n",
       " u'Change-ringing',\n",
       " u'Citing',\n",
       " u'Concerned',\n",
       " u'Confronted',\n",
       " u'Conn.based',\n",
       " u'Consolidated',\n",
       " u'Continued',\n",
       " u'Continuing',\n",
       " u'Declining',\n",
       " u'Defending',\n",
       " u'Depending',\n",
       " u'Designated',\n",
       " u'Determining',\n",
       " u'Developed',\n",
       " u'Died',\n",
       " u'During',\n",
       " u'Encouraged',\n",
       " u'Encouraging',\n",
       " u'English-speaking',\n",
       " u'Estimated',\n",
       " u'Everything',\n",
       " u'Excluding',\n",
       " u'Exxon-owned',\n",
       " u'Faulding',\n",
       " u'Fed',\n",
       " u'Feeding',\n",
       " u'Filling',\n",
       " u'Filmed',\n",
       " u'Financing',\n",
       " u'Following',\n",
       " u'Founded',\n",
       " u'Fracturing',\n",
       " u'Francisco-based',\n",
       " u'Fred',\n",
       " u'Funded',\n",
       " u'Funding',\n",
       " u'Generalized',\n",
       " u'Germany-based',\n",
       " u'Getting',\n",
       " u'Guaranteed',\n",
       " u'Having',\n",
       " u'Heating',\n",
       " u'Heightened',\n",
       " u'Holding',\n",
       " u'Housing',\n",
       " u'Illuminating',\n",
       " u'Indeed',\n",
       " u'Indexing',\n",
       " u'Irving',\n",
       " u'Jersey-based',\n",
       " u'Judging',\n",
       " u'Knowing',\n",
       " u'Learning',\n",
       " u'Legislating',\n",
       " u'Leming',\n",
       " u'Limited',\n",
       " u'London-based',\n",
       " u'Manfred',\n",
       " u'Manufacturing',\n",
       " u'Melamed',\n",
       " u'Miami-based',\n",
       " u'Mich.-based',\n",
       " u'Mining',\n",
       " u'Minneapolis-based',\n",
       " u'Mo.-based',\n",
       " u'Mortgage-Backed',\n",
       " u'Moving',\n",
       " u'Muzzling',\n",
       " u'N.J.-based',\n",
       " u'NBC-owned',\n",
       " u'NIH-appointed',\n",
       " u'Named',\n",
       " u'No-Smoking',\n",
       " u'Observing',\n",
       " u'Offering',\n",
       " u'Ohio-based',\n",
       " u'Orleans-based',\n",
       " u'Packaging',\n",
       " u'Performing',\n",
       " u'Philadelphia-based',\n",
       " u'Posted',\n",
       " u'Provided',\n",
       " u'Publishing',\n",
       " u'Purchasing',\n",
       " u'Rated',\n",
       " u'Reached',\n",
       " u'Red',\n",
       " u'Red-blooded',\n",
       " u'Reducing',\n",
       " u'Reed',\n",
       " u'Regarded',\n",
       " u'Rekindled',\n",
       " u'Related',\n",
       " u'Ringing',\n",
       " u'Rolling',\n",
       " u'Sacramento-based',\n",
       " u'Scoring',\n",
       " u'Seattle-based',\n",
       " u'Seed',\n",
       " u'Skilled',\n",
       " u'Smelting',\n",
       " u'Something',\n",
       " u'Spending',\n",
       " u'Standardized',\n",
       " u'Standing',\n",
       " u'Starting',\n",
       " u'Sterling',\n",
       " u'Taking',\n",
       " u'Texas-based',\n",
       " u'Toronto-based',\n",
       " u'Traded',\n",
       " u'Trading',\n",
       " u'Troubled',\n",
       " u'U.N.-supervised',\n",
       " u'U.S.-backed',\n",
       " u'United',\n",
       " u'Used',\n",
       " u'Varying',\n",
       " u'Washington-based',\n",
       " u'Whiting',\n",
       " u'Wilfred',\n",
       " u'Winning',\n",
       " u'Xiaoping',\n",
       " u'York-based',\n",
       " u'Zayed',\n",
       " u'abandoned',\n",
       " u'abating',\n",
       " u'abolishing',\n",
       " u'abortion-related',\n",
       " u'abounding',\n",
       " u'abridging',\n",
       " u'absorbed',\n",
       " u'acceded',\n",
       " u'accelerated',\n",
       " u'accepted',\n",
       " u'accepting',\n",
       " u'according',\n",
       " u'accounted',\n",
       " u'accounting',\n",
       " u'accrued',\n",
       " u'accumulated',\n",
       " u'accused',\n",
       " u'accusing',\n",
       " u'achieved',\n",
       " u'achieving',\n",
       " u'acknowledging',\n",
       " u'acquired',\n",
       " u'acquiring',\n",
       " u'acquisition-minded',\n",
       " u'acted',\n",
       " u'acting',\n",
       " u'adapted',\n",
       " u'adapting',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addressing',\n",
       " u'adjusted',\n",
       " u'adjusting',\n",
       " u'admitted',\n",
       " u'admitting',\n",
       " u'adopted',\n",
       " u'advanced',\n",
       " u'advancing',\n",
       " u'advertised',\n",
       " u'advertising',\n",
       " u'advised',\n",
       " u'advocated',\n",
       " u'advocating',\n",
       " u'affecting',\n",
       " u'afflicted',\n",
       " u'aggravated',\n",
       " u'agreed',\n",
       " u'agreeing',\n",
       " u'ailing',\n",
       " u'aimed',\n",
       " u'aiming',\n",
       " u'aired',\n",
       " u'airline-related',\n",
       " u'alarmed',\n",
       " u'alienated',\n",
       " u'alleged',\n",
       " u'alleging',\n",
       " u'allocated',\n",
       " u'allowed',\n",
       " u'altered',\n",
       " u'altering',\n",
       " u'amended',\n",
       " u'amending',\n",
       " u'amounted',\n",
       " u'amusing',\n",
       " u'angered',\n",
       " u'announced',\n",
       " u'annoyed',\n",
       " u'annualized',\n",
       " u'answered',\n",
       " u'anti-dumping',\n",
       " u'anticipated',\n",
       " u'anticipating',\n",
       " u'anything',\n",
       " u'apologizing',\n",
       " u'appealing',\n",
       " u'appeared',\n",
       " u'appearing',\n",
       " u'applied',\n",
       " u'appointed',\n",
       " u'approached',\n",
       " u'appropriated',\n",
       " u'approved',\n",
       " u'arched',\n",
       " u'argued',\n",
       " u'arguing',\n",
       " u'arising',\n",
       " u'armed',\n",
       " u'arranged',\n",
       " u'arrested',\n",
       " u'arrived',\n",
       " u'asbestos-related',\n",
       " u'asked',\n",
       " u'asking',\n",
       " u'assassinated',\n",
       " u'assembled',\n",
       " u'asserted',\n",
       " u'asserting',\n",
       " u'assessed',\n",
       " u'assigned',\n",
       " u'assisted',\n",
       " u'associated',\n",
       " u'assumed',\n",
       " u'assuming',\n",
       " u'assured',\n",
       " u'attached',\n",
       " u'attacking',\n",
       " u'attempted',\n",
       " u'attempting',\n",
       " u'attended',\n",
       " u'attending',\n",
       " u'attracted',\n",
       " u'attracting',\n",
       " u'attributed',\n",
       " u'auctioned',\n",
       " u'authorized',\n",
       " u'authorizing',\n",
       " u'automated',\n",
       " u'automotive-lighting',\n",
       " u'averaged',\n",
       " u'averted',\n",
       " u'avoiding',\n",
       " u'awarded',\n",
       " u'awarding',\n",
       " u'backed',\n",
       " u'backing',\n",
       " u'balanced',\n",
       " u'bald-faced',\n",
       " u'balkanized',\n",
       " u'balked',\n",
       " u'balloting',\n",
       " u'bank-backed',\n",
       " u'banking',\n",
       " u'banned',\n",
       " u'banning',\n",
       " u'barking',\n",
       " u'barred',\n",
       " u'based',\n",
       " u'battered',\n",
       " u'battery-operated',\n",
       " u'batting',\n",
       " u'bearing',\n",
       " u'becoming',\n",
       " u'bedding',\n",
       " u'befuddled',\n",
       " u'beginning',\n",
       " u'behaving',\n",
       " u'beheading',\n",
       " u'being',\n",
       " u'beleaguered',\n",
       " u'believed',\n",
       " u'bell-ringing',\n",
       " u'belonging',\n",
       " u'benefited',\n",
       " u'best-selling',\n",
       " u'betting',\n",
       " u'bickering',\n",
       " u'bidding',\n",
       " u'billed',\n",
       " u'billing',\n",
       " u'blamed',\n",
       " u'bled',\n",
       " u'blessing',\n",
       " u'blighted',\n",
       " u'blocked',\n",
       " u'blurred',\n",
       " u'boarding',\n",
       " u'bolstered',\n",
       " u'bombarding',\n",
       " u'booked',\n",
       " u'booming',\n",
       " u'boosted',\n",
       " u'boosting',\n",
       " u'borrowed',\n",
       " u'borrowing',\n",
       " u'botched',\n",
       " u'bothered',\n",
       " u'bounced',\n",
       " u'bowed',\n",
       " u'breaking',\n",
       " u'breathed',\n",
       " u'breathtaking',\n",
       " u'breed',\n",
       " u'bribed',\n",
       " u'bribing',\n",
       " u'briefing',\n",
       " u'brightened',\n",
       " u'bring',\n",
       " u'bringing',\n",
       " u'broad-based',\n",
       " u'broadcasting',\n",
       " u'broadened',\n",
       " u'brokering',\n",
       " u'brushed',\n",
       " u'budding',\n",
       " u'building',\n",
       " u'bundling',\n",
       " u'buoyed',\n",
       " u'burned',\n",
       " u'buying',\n",
       " u'calculated',\n",
       " u'called',\n",
       " u'calling',\n",
       " u'campaigning',\n",
       " u'cancer-causing',\n",
       " u'capitalized',\n",
       " u'capped',\n",
       " u'captivating',\n",
       " u'cared',\n",
       " u'carried',\n",
       " u'carrying',\n",
       " u'cascading',\n",
       " u'casting',\n",
       " u'caused',\n",
       " u'causing',\n",
       " u'cautioned',\n",
       " u'ceiling',\n",
       " u'centralized',\n",
       " u'certified',\n",
       " u'chaired',\n",
       " u'challenging',\n",
       " u'championing',\n",
       " u'change-ringing',\n",
       " u'changed',\n",
       " u'changing',\n",
       " u'characterized',\n",
       " u'characterizing',\n",
       " u'charged',\n",
       " u'charging',\n",
       " u'chastised',\n",
       " u'cheating',\n",
       " u'checking',\n",
       " u'cheerleading',\n",
       " u'chilled',\n",
       " u'choosing',\n",
       " u'chopped',\n",
       " u'circulated',\n",
       " u'cited',\n",
       " u'citing',\n",
       " u'citizen-sparked',\n",
       " u'city-owned',\n",
       " u'claimed',\n",
       " u'claiming',\n",
       " u'clamped',\n",
       " u'clarified',\n",
       " u'clashed',\n",
       " u'classed',\n",
       " u'classified',\n",
       " u'cleaned',\n",
       " u'cleaner-burning',\n",
       " u'cleared',\n",
       " u'clearing',\n",
       " u'clicked',\n",
       " u'climbed',\n",
       " u'climbing',\n",
       " u'clipped',\n",
       " u'clobbered',\n",
       " u'closed',\n",
       " u'closing',\n",
       " u'clothing',\n",
       " u'clouding',\n",
       " u'cluttered',\n",
       " u'co-founded',\n",
       " u'coaching',\n",
       " u'coal-fired',\n",
       " u'coated',\n",
       " u'codified',\n",
       " u'collaborated',\n",
       " u'collapsed',\n",
       " u'collected',\n",
       " u'collecting',\n",
       " u'collective-bargaining',\n",
       " u'colored',\n",
       " u'combined',\n",
       " u'coming',\n",
       " u'commanded',\n",
       " u'commenting',\n",
       " u'committed',\n",
       " u'committing',\n",
       " u'compared',\n",
       " u'compelling',\n",
       " u'competed',\n",
       " u'competing',\n",
       " u'compiled',\n",
       " u'complained',\n",
       " u'complaining',\n",
       " u'completed',\n",
       " u'completing',\n",
       " u'complicated',\n",
       " u'composed',\n",
       " u'composting',\n",
       " u'compressed',\n",
       " u'computer-aided',\n",
       " u'computer-assisted',\n",
       " u'computer-generated',\n",
       " u'computerized',\n",
       " u'computing',\n",
       " u'conceding',\n",
       " u'concentrated',\n",
       " u'concentrating',\n",
       " u'concerned',\n",
       " u'concluded',\n",
       " u'condemned',\n",
       " u'condemning',\n",
       " u'conducted',\n",
       " u'conducting',\n",
       " u'confined',\n",
       " u'confirmed',\n",
       " u'confused',\n",
       " u'connected',\n",
       " u'consented',\n",
       " u'considered',\n",
       " u'considering',\n",
       " u'consisting',\n",
       " u'construed',\n",
       " u'consulting',\n",
       " u'contacted',\n",
       " u'contained',\n",
       " u'containing',\n",
       " u'contesting',\n",
       " u'continued',\n",
       " u'continuing',\n",
       " u'contracted',\n",
       " u'contributed',\n",
       " u'contributing',\n",
       " u'controlled',\n",
       " u'controlling',\n",
       " u'converted',\n",
       " u'converting',\n",
       " u'convicted',\n",
       " u'convinced',\n",
       " u'cooled',\n",
       " u'cooperating',\n",
       " u'copied',\n",
       " u'copying',\n",
       " u'corn-buying',\n",
       " u'corrected',\n",
       " u'correcting',\n",
       " u'cost-cutting',\n",
       " u'cost-sharing',\n",
       " u'counseling',\n",
       " u'counting',\n",
       " u'coupled',\n",
       " u'court-ordered',\n",
       " u'covered',\n",
       " u'covering',\n",
       " u'cranked',\n",
       " u'crashing',\n",
       " u'created',\n",
       " u'creating',\n",
       " u'credit-rating',\n",
       " u'crippled',\n",
       " u'criticized',\n",
       " u'crossed',\n",
       " u'crossing',\n",
       " u'crowded',\n",
       " u'cruising',\n",
       " u'crushed',\n",
       " u'crying',\n",
       " u'cultivated',\n",
       " u'curbed',\n",
       " u'curbing',\n",
       " u'curled',\n",
       " u'current-carrying',\n",
       " u'curtailed',\n",
       " u'cushioned',\n",
       " u'customized',\n",
       " u'cutting',\n",
       " u'damaged',\n",
       " u'damaging',\n",
       " u'dancing',\n",
       " u'darned',\n",
       " u'dashed',\n",
       " u'dating',\n",
       " u'dead-eyed',\n",
       " u'dealing',\n",
       " u'decided',\n",
       " u'declared',\n",
       " u'declaring',\n",
       " u'declined',\n",
       " u'declining',\n",
       " u'decorated',\n",
       " u'decried',\n",
       " u'deducting',\n",
       " u'deemed',\n",
       " u'defeated',\n",
       " u'defended',\n",
       " u'defined',\n",
       " u'defying',\n",
       " u'delayed',\n",
       " u'deliberating',\n",
       " u'delisted',\n",
       " u'delivered',\n",
       " u'delivering',\n",
       " u'demanding',\n",
       " u'demonstrating',\n",
       " u'denied',\n",
       " u'denouncing',\n",
       " u'denying',\n",
       " u'depended',\n",
       " u'depending',\n",
       " u'depleted',\n",
       " u'depressed',\n",
       " u'deprived',\n",
       " u'derived',\n",
       " u'descending',\n",
       " u'described',\n",
       " u'deserving',\n",
       " u'designated',\n",
       " u'designed',\n",
       " u'designing',\n",
       " u'desired',\n",
       " u'despised',\n",
       " u'detailed',\n",
       " u'deteriorated',\n",
       " u'deteriorating',\n",
       " u'determined',\n",
       " u'deterring',\n",
       " u'devastating',\n",
       " u'developed',\n",
       " u'developing',\n",
       " u'devised',\n",
       " u'devoted',\n",
       " u'devouring',\n",
       " u'diagnosed',\n",
       " u'died',\n",
       " u'diluted',\n",
       " u'diming',\n",
       " u'diminished',\n",
       " u'directed',\n",
       " u'directing',\n",
       " u'disaffected',\n",
       " u'disagreed',\n",
       " u'disappointed',\n",
       " u'disappointing',\n",
       " u'disapproved',\n",
       " u'discarded',\n",
       " u'disciplined',\n",
       " u'disclosed',\n",
       " u'disclosing',\n",
       " u'discontinued',\n",
       " u'discontinuing',\n",
       " u'discouraging',\n",
       " u'discovered',\n",
       " u'discussed',\n",
       " u'discussing',\n",
       " u'disembodied',\n",
       " u'dismayed',\n",
       " u'dismissed',\n",
       " u'disposed',\n",
       " u'disputed',\n",
       " u'disseminating',\n",
       " u'distinguished',\n",
       " u'distorted',\n",
       " u'distributed',\n",
       " u'disturbing',\n",
       " u'diversified',\n",
       " u'diversifying',\n",
       " u'divided',\n",
       " u'dividing',\n",
       " u'documented',\n",
       " u'doing',\n",
       " u'doling',\n",
       " u'dollar-denominated',\n",
       " u'dominated',\n",
       " u'dominating',\n",
       " u'doubled',\n",
       " u'doubted',\n",
       " u'downgraded',\n",
       " u'downgrading',\n",
       " u'drafted',\n",
       " u'drawing',\n",
       " u'dreamed',\n",
       " u'dressed',\n",
       " u'drifted',\n",
       " u'drinking',\n",
       " u'driving',\n",
       " u'drooled',\n",
       " u'dropped',\n",
       " u'dubbed',\n",
       " u'duckling',\n",
       " u'dumbfounded',\n",
       " u'dumped',\n",
       " u'during',\n",
       " u'dwindling',\n",
       " u'earned',\n",
       " u'earning',\n",
       " u'eased',\n",
       " u'easing',\n",
       " u'eating',\n",
       " u'echoed',\n",
       " u'edged',\n",
       " u'editing',\n",
       " u'educated',\n",
       " u'elected',\n",
       " u'eliminated',\n",
       " u'eliminating',\n",
       " u'embarrassing',\n",
       " u'embroiled',\n",
       " u'emerged',\n",
       " u'emerging',\n",
       " u'emphasized',\n",
       " u'employed',\n",
       " u'empowered',\n",
       " u'enabled',\n",
       " u'enabling',\n",
       " u'enacted',\n",
       " u'encircling',\n",
       " u'enclosed',\n",
       " u'encouraging',\n",
       " u'encroaching',\n",
       " u'ended',\n",
       " u'ending',\n",
       " u'endorsed',\n",
       " u'engaged',\n",
       " u'engaging',\n",
       " u'engineered',\n",
       " u'engineering',\n",
       " u'enhanced',\n",
       " u'enjoyed',\n",
       " u'enjoying',\n",
       " u'enlarged',\n",
       " u'enraged',\n",
       " u'ensnarled',\n",
       " u'entangled',\n",
       " u'entered',\n",
       " u'entering',\n",
       " u'entertaining',\n",
       " u'enticed',\n",
       " u'entitled',\n",
       " u'entrenched',\n",
       " u'entrusted',\n",
       " u'equaling',\n",
       " u'equipped',\n",
       " u'escalated',\n",
       " u'escaped',\n",
       " u'established',\n",
       " u'establishing',\n",
       " u'estimated',\n",
       " u'evaluated',\n",
       " u'evaluating',\n",
       " u'evaporated',\n",
       " u'evening',\n",
       " u'everything',\n",
       " u'evoking',\n",
       " u'evolved',\n",
       " u'exacerbated',\n",
       " u'examined',\n",
       " u'exceed',\n",
       " u'exceeded',\n",
       " u'exceeding',\n",
       " u'exchanging',\n",
       " u'excited',\n",
       " u'exciting',\n",
       " u'executed',\n",
       " u'executing',\n",
       " u'exercised',\n",
       " u'exerting',\n",
       " u'exhausted',\n",
       " u'exhibited',\n",
       " u'existed',\n",
       " u'existing',\n",
       " u'expanded',\n",
       " u'expanding',\n",
       " u'expected',\n",
       " u'expecting',\n",
       " u'expedited',\n",
       " u'expelled',\n",
       " u'experienced',\n",
       " u'experiencing',\n",
       " u'expired',\n",
       " u'explained',\n",
       " u'explaining',\n",
       " u'exploded',\n",
       " u'export-oriented',\n",
       " u'exposed',\n",
       " u'expressed',\n",
       " u'expressing',\n",
       " u'expunged',\n",
       " u'extended',\n",
       " u'extending',\n",
       " u'exuded',\n",
       " u'eyeing',\n",
       " u'fabled',\n",
       " u'faced',\n",
       " u'facing',\n",
       " u'factoring',\n",
       " u'faded',\n",
       " u'failed',\n",
       " u'failing',\n",
       " u'fainting',\n",
       " u'falling',\n",
       " u'faltered',\n",
       " u'famed',\n",
       " u'family-planning',\n",
       " u'fared',\n",
       " u'fashioned',\n",
       " u'fast-growing',\n",
       " u'fastest-growing',\n",
       " u'fattened',\n",
       " u'favored',\n",
       " u'fawning',\n",
       " u'feared',\n",
       " u'featured',\n",
       " u'featuring',\n",
       " u'fed',\n",
       " u'feed',\n",
       " u'feeling',\n",
       " u'fetching',\n",
       " u'fielded',\n",
       " u'fighting',\n",
       " u'filed',\n",
       " u'filing',\n",
       " u'filled',\n",
       " u'filling',\n",
       " u'finalized',\n",
       " u'financed',\n",
       " u'financing',\n",
       " u'finding',\n",
       " u'fined',\n",
       " u'finished',\n",
       " u'fired',\n",
       " u'firmed',\n",
       " u'fixed',\n",
       " u'fizzled',\n",
       " u'fled',\n",
       " u'fledgling',\n",
       " u'fleeting',\n",
       " u'flirted',\n",
       " u'floated',\n",
       " u'flooded',\n",
       " u'focused',\n",
       " u'focusing',\n",
       " u'folded',\n",
       " u'followed',\n",
       " u'following',\n",
       " u'forced',\n",
       " u'forcing',\n",
       " u'forecasting',\n",
       " u'foreign-led',\n",
       " u'formed',\n",
       " u'forthcoming',\n",
       " u'founded',\n",
       " u'foundering',\n",
       " u'fretted',\n",
       " u'frightened',\n",
       " u'frustrating',\n",
       " u'fueled',\n",
       " u'fueling',\n",
       " u'full-fledged',\n",
       " u'fuming',\n",
       " u'functioning',\n",
       " u'funded',\n",
       " u'funding',\n",
       " u'fundraising',\n",
       " u'futures-related',\n",
       " u'gained',\n",
       " u'gaining',\n",
       " u'galling',\n",
       " u'galvanized',\n",
       " u'gambling',\n",
       " u'gauging',\n",
       " u'generated',\n",
       " u'getting',\n",
       " u'giving',\n",
       " u'going',\n",
       " u'good-hearted',\n",
       " u'good-natured',\n",
       " u'gored',\n",
       " u'government-certified',\n",
       " u'government-funded',\n",
       " u'government-owned',\n",
       " u'graduated',\n",
       " u'granted',\n",
       " u'granting',\n",
       " u'greed',\n",
       " u'gripping',\n",
       " u'growing',\n",
       " u'guaranteed',\n",
       " u'guarding',\n",
       " u'guided',\n",
       " u'gut-wrenching',\n",
       " u'hailed',\n",
       " u'hailing',\n",
       " u'halted',\n",
       " u'hampered',\n",
       " u'handed',\n",
       " u'handled',\n",
       " u'handling',\n",
       " u'happened',\n",
       " u'happening',\n",
       " u'hard-charging',\n",
       " u'hard-drinking',\n",
       " u'hard-hitting',\n",
       " u'harmed',\n",
       " u'harped',\n",
       " u'harvested',\n",
       " u'hauled',\n",
       " u'hauling',\n",
       " u'having',\n",
       " u'headed',\n",
       " u'heading',\n",
       " u'headlined',\n",
       " u'healing',\n",
       " u'hearing',\n",
       " u'heated',\n",
       " u'heating',\n",
       " u'hedging',\n",
       " u'heightened',\n",
       " u'helped',\n",
       " u'helping',\n",
       " u'high-flying',\n",
       " u'high-minded',\n",
       " u'high-polluting',\n",
       " u'high-priced',\n",
       " u'high-rolling',\n",
       " u'high-speed',\n",
       " u'higher-salaried',\n",
       " u'highest-pitched',\n",
       " u'hired',\n",
       " u'hitting',\n",
       " u'holding',\n",
       " u'hoped',\n",
       " u'hosted',\n",
       " u'housing',\n",
       " u'hugging',\n",
       " u'hundred',\n",
       " u'hunted',\n",
       " u'hurting',\n",
       " u'identified',\n",
       " u'ignored',\n",
       " u'ignoring',\n",
       " u'impaired',\n",
       " u'impeding',\n",
       " u'impending',\n",
       " u'implemented',\n",
       " u'implied',\n",
       " u'imported',\n",
       " u'imposed',\n",
       " u'imposing',\n",
       " u'impressed',\n",
       " u'improved',\n",
       " u'improving',\n",
       " u'incentive-backed',\n",
       " u'inched',\n",
       " u'inching',\n",
       " u'included',\n",
       " u'including',\n",
       " u'incorporated',\n",
       " u'increased',\n",
       " u'increasing',\n",
       " u'incurred',\n",
       " u'indeed',\n",
       " u'index-related',\n",
       " u'indicated',\n",
       " u'indicating',\n",
       " u'indulging',\n",
       " u'industrialized',\n",
       " u'industry-supported',\n",
       " u'inflated',\n",
       " u'influenced',\n",
       " u'influencing',\n",
       " u'infringed',\n",
       " u'inherited',\n",
       " u'initialing',\n",
       " u'initiated',\n",
       " u'initiating',\n",
       " u'injecting',\n",
       " u'injuring',\n",
       " u'inkling',\n",
       " u'inquiring',\n",
       " u'inserted',\n",
       " u'insider-trading',\n",
       " u'insinuating',\n",
       " u'insisted',\n",
       " u'inspired',\n",
       " u'installed',\n",
       " u'installing',\n",
       " u'instituted',\n",
       " u'instructed',\n",
       " u'insured',\n",
       " u'integrated',\n",
       " u'intended',\n",
       " u'intentioned',\n",
       " u'interest-bearing',\n",
       " u'interested',\n",
       " u'interesting',\n",
       " u'interrogated',\n",
       " u'interviewed',\n",
       " u'intriguing',\n",
       " u'introduced',\n",
       " u'introducing',\n",
       " u'invented',\n",
       " u'inverted',\n",
       " u'invested',\n",
       " u'investigating',\n",
       " u'investing',\n",
       " u'inviting',\n",
       " u'involved',\n",
       " u'involving',\n",
       " u'issued',\n",
       " u'issuing',\n",
       " u'jeopardizing',\n",
       " u'joined',\n",
       " u'joining',\n",
       " u'judged',\n",
       " u'jumped',\n",
       " u'jumping',\n",
       " u'justified',\n",
       " u'justifying',\n",
       " u'keeping',\n",
       " u'kicked',\n",
       " u'kidnapping',\n",
       " u'killed',\n",
       " u'killing',\n",
       " u'knitted',\n",
       " u'knocked',\n",
       " u'labeled',\n",
       " u'labeling',\n",
       " u'labor-backed',\n",
       " u'lacked',\n",
       " u'lagging',\n",
       " u'land-idling',\n",
       " u'landing',\n",
       " u'lasted',\n",
       " u'lasting',\n",
       " u'lauded',\n",
       " u'laughing',\n",
       " u'launched',\n",
       " u'lawmaking',\n",
       " u'laying',\n",
       " u'leading',\n",
       " u'learned',\n",
       " u'learning',\n",
       " u'leasing',\n",
       " u'leaving',\n",
       " u'led',\n",
       " u'lending',\n",
       " u'lengthened',\n",
       " u'lessening',\n",
       " u'letter-writing',\n",
       " u'letting',\n",
       " u'leveling',\n",
       " u'leveraged',\n",
       " u'leveraging',\n",
       " u'licensed',\n",
       " u'licensing',\n",
       " u'lifted',\n",
       " ...]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('(ed|ing)$', w)]\n",
    "# Prediction: any word that ends in ed or ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You probably worked out that a backslash means that the following character is deprived of its special powers and must literally \n",
    "# match a specific character in the word. Thus, while . is special, \\. only matches a period. The braced expressions, like {3,5}, \n",
    "# specify the number of repeats of the previous item. The pipe character indicates a choice between the material on its left or its \n",
    "# right. Parentheses indicate the scope of an operator: they can be used together with the pipe (or disjunction) symbol like this: \n",
    "# «w(i|e|ai|oo)t», matching wit, wet, wait, and woot. It is instructive to see what happens when you omit the parentheses from the \n",
    "# last expression above, and search for «ed|ing$».\n",
    "\n",
    "# The meta-characters we have seen are summarized in 3.3.\n",
    "\n",
    "# Table 3.3:\n",
    "\n",
    "# Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
    "\n",
    "# Operator     Behavior\n",
    "# .            Wildcard, matches any character\n",
    "# ^abc         Matches some pattern abc at the start of a string\n",
    "# abc$         Matches some pattern abc at the end of a string\n",
    "# [abc]        Matches one of a set of characters\n",
    "# [A-Z0-9]     Matches one of a range of characters\n",
    "# ed|ing|s     Matches one of the specified strings (disjunction)\n",
    "# *            Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
    "# +            One or more of previous item, e.g. a+, [a-z]+\n",
    "# ?            Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
    "# {n}          Exactly n repeats where n is a non-negative integer\n",
    "# {n,}         At least n repeats\n",
    "# {,n}         No more than n repeats\n",
    "# {m,n}        At least m and no more than n repeats\n",
    "# a(b|c)+      Parentheses that indicate the scope of the operators\n",
    "\n",
    "# To the Python interpreter, a regular expression is just like any other string. If the string contains a backslash followed by \n",
    "# particular characters, it will interpret these specially. For example \\b would be interpreted as the backspace character. In \n",
    "# general, when using regular expressions containing backslash, we should instruct the interpreter not to look inside the string at \n",
    "# all, but simply to pass it directly to the re library for processing. We do this by prefixing the string with the letter r, to \n",
    "# indicate that it is a raw string. For example, the raw string r'\\band\\b' contains two \\b symbols that are interpreted by the \n",
    "# re library as matching word boundaries instead of backspace characters. If you get into the habit of using r'...' for regular \n",
    "# expressions — as we will do from now on — you will avoid having to think about these complications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5   Useful Applications of Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above examples all involved searching for words w that match some regular expression regexp using re.search(regexp, w). Apart \n",
    "# from checking if a regular expression matches a word, we can use regular expressions to extract material from words, or to modify \n",
    "# words in specific ways.\n",
    "\n",
    "# Extracting Word Pieces\n",
    "\n",
    "# The re.findall() (\"find all\") method finds all (non-overlapping) matches of the given regular expression. Let's find all the \n",
    "# vowels in a word, then count them:\n",
    "\n",
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look for all sequences of two or more vowels in some text, and determine their relative frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                   for vs in re.findall(r'[aeiou]{2,}', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'io', 549),\n",
       " (u'ea', 476),\n",
       " (u'ie', 331),\n",
       " (u'ou', 329),\n",
       " (u'ai', 261),\n",
       " (u'ia', 253),\n",
       " (u'ee', 217),\n",
       " (u'oo', 174),\n",
       " (u'ua', 109),\n",
       " (u'au', 106),\n",
       " (u'ue', 105),\n",
       " (u'ui', 95)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "# Doing More with Word Pieces\n",
    "\n",
    "# Once we can use re.findall() to extract material from words, there's interesting things to do with the pieces, like glue them \n",
    "# back together or plot them.\n",
    "\n",
    "# It is sometimes noted that English text is highly redundant, and it is still easy to read when word-internal vowels are left \n",
    "# out. For example, declaration becomes dclrtn, and inalienable becomes inlnble, retaining any initial or final vowel sequences. \n",
    "# The regular expression in our next example matches initial vowel sequences, final vowel sequences, and all consonants; everything \n",
    "# else is ignored. This three-way disjunction is processed left-to-right, if one of the three parts matches the word, any later\n",
    "# parts of the regular expression are ignored. We use re.findall() to extract all the matching pieces, and ''.join() to join them \n",
    "# together (see 3.9 for more about the join operation).\n",
    "\n",
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I skipped the rest of this small section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding Word Stems\n",
    "\n",
    "# When we use a web search engine, we usually don't mind (or even notice) if the words in the document differ from our search terms \n",
    "# in having different endings. A query for laptops finds documents containing laptop and vice versa. Indeed, laptop and laptops are \n",
    "# just two forms of the same dictionary word (or lemma). For some language processing tasks we want to ignore word endings, and just \n",
    "# deal with word stems.\n",
    "\n",
    "# There are various ways we can pull out the stem of a word. Here's a simple-minded approach which just strips off anything that \n",
    "# looks like a suffix:\n",
    "\n",
    "def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        return word\n",
    "\n",
    "# Take in a word\n",
    "# define a list suffix with 9 common suffixes\n",
    "# Setup a loop to go through each suffix\n",
    "# if the word ends with the suffix, return the word with that suffix removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Although we will ultimately use NLTK's built-in stemmers, it's interesting to see how we can use regular expressions for this \n",
    "# task. Our first step is to build up a disjunction of all the suffixes. We need to enclose it in parentheses in order to limit \n",
    "# the scope of the disjunction.\n",
    "\n",
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')\n",
    "\n",
    "# Here, we say that we should match the string in 'processing' where we have 0 or more characters\n",
    "# followed by one of 9 possible suffixes\n",
    "# Here, we see that it is 'ing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, re.findall() just gave us the suffix even though the regular expression matched the entire word. This is because the \n",
    "# parentheses have a second function, to select substrings to be extracted. If we want to use the parentheses to specify the \n",
    "# scope of the disjunction, but not to select the material to be output, we have to add ?:, which is just one of many arcane \n",
    "# subtleties of regular expressions. Here's the revised version.\n",
    "\n",
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'ing')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# However, we'd actually like to split the word into stem and suffix. So we should just parenthesize both parts of the regular \n",
    "# expression:\n",
    "\n",
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This looks promising, but still has a problem. Let's look at a different word, processes:\n",
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The regular expression incorrectly found an -s suffix instead of an -es suffix. This demonstrates another subtlety: the star \n",
    "# operator is \"greedy\" and the .* part of the expression tries to consume as much of the input as possible. If we use the \n",
    "# \"non-greedy\" version of the star operator, written *?, we get what we want:\n",
    "\n",
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', '')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works even when we allow an empty suffix, by making the content of the second parentheses optional:\n",
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'ly',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'i',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This approach still has many problems (can you spot them?) but we will move on to define a function to perform stemming, and \n",
    "# apply it to a whole text:\n",
    "\n",
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem\n",
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "\n",
    "tokens = word_tokenize(raw)\n",
    "\n",
    "[stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notice that our regular expression removed the s from ponds but also from is and basis. It produced some non-words like distribut \n",
    "# and deriv, but these are acceptable stems in some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n",
      "artificial; any; that; a; monied; nervous; a; old; decent; This; a;\n",
      "this; No; the; dangerous; a; white; a; white; this; the; a; a; any;\n",
      "one; the; that; That; every; a; a; old; worsted; the; faithful;\n",
      "Miserable; the; the; the; honest; the; is; a; a; a; fellow; fellow;\n",
      "fellow; no; white; that; first; a; the; the; elderly; !; young; young;\n",
      "Young; young; the; a; that; a; a; pious; our; young; young; young;\n",
      "impenitent; ,; young; young; queer; like; good; good; good; young;\n",
      "old; young; young; a; young; young; Young; Young; the; a; crazy; the;\n",
      "a; good; a; the; of; a; that; a; mature; that; earnest; the;\n",
      "steadfast; no; fearless; a; a; a; mighty; but; ruined; -; unfearing;\n",
      "white; -; Cape; a; sepulchral; other; sleeping; less; old; old; old;\n",
      "old; old; old; old; little; little; !; ,; great; wise; wise; old; ,;\n",
      "better; by; are; from; handed; and; by; no; a; that; that; old;\n",
      "butterless; first; meditative; old; old; ,; ,; If; ,; ,; ,; every;\n",
      "that; !; old; white; old; old; mortal; to; old; of; very; fiendish;\n",
      "old; old; any; white; for; Albino; no; mortal; no; the; pale; old;\n",
      "that; old; the; This; great; of; spiritual; manufactured; of; old;\n",
      "Every; a; little; dead; that; a; a; a; last; old; little; legs;\n",
      "maimed; to; first; best; old; each; old; old; monomaniac; old; a; ,;\n",
      "a; that; a; Any; infatuated; your; their; a; first; one; a; pale; the;\n",
      "infatuated; the; Teneriffe; Teneriffe; furious; one; of; half;\n",
      "experienced; mortal; that; a; baby; ,; to; of; every; by; every; this;\n",
      "that; no; each; killed; old; brack; old; mortal; a; first; any; a;\n",
      "single; like; to; ,; O; timid; better; ,; of; a; youngish; certain; a;\n",
      "a; ,; to; the; the; old; ,; the; a; a; drowned; old; old; old; same;\n",
      "by; a; a; a; than; a; any; ,; than; in; in; every; This; a; best; the;\n",
      "stoutest; no; Any; a; a; a; In; a; a; the; In; with; of; of; no; ,;\n",
      "by; the; common; old; old; -; -; -; -; -; -; looking; -; -; -; -; the;\n",
      "-; though; yet; So; ,; cases; -; -; one; O; mortal; mortal; that; the;\n",
      "last; is; every; that; old; of; old; looking; ornamented; legged; ,;\n",
      "other; abstinence; a; this; learned; per; untravelled; with; to; last;\n",
      "of; from; of; abstracted; this; ,; complete; ,; dismasted; ,; old; ,;\n",
      "better; younger; old; in; a; sick; a; civilized; old; old; old; old;\n",
      "old; old; ,; old; ,; ,; old; old; old; old; one; cast; of; old; Old;\n",
      "brave; brave; brave; ,; ,; ,; old; old; old; little; ,; every; any; a;\n",
      "the; old; upright; old; old; old; old; old; old; old; old; old; a; a;\n",
      "that; a; in; suffering; and; this; the; first; that; ,; old; So; the;\n",
      "other; ,; of; old; old; one; old; one; only; very; old; old; and; old;\n",
      "a; ,; ,; ,; old; ,; ,; than; old; ,; old; ,; to; that; one; this;\n",
      "that; one; old; nor; ,; old; old; last; ,; old; -; mortal; mortal;\n",
      "between; ,; brave; old; third; mortal\n"
     ]
    }
   ],
   "source": [
    "# Searching Tokenized Text\n",
    "\n",
    "# You can use a special kind of regular expression for searching across multiple words in a text (where a text is a list of tokens). \n",
    "# For example, \"<a> <man>\" finds all instances of a man in the text. The angle brackets are used to mark token boundaries, and any \n",
    "# whitespace between the angle brackets is ignored (behaviors that are unique to NLTK's findall() method for texts). In the following \n",
    "# example, we include <.*> [1] which will match any single token, and enclose it in parentheses so only the matched word \n",
    "# (e.g. monied) and not the matched phrase (e.g. a monied man) is produced. The second example finds three-word phrases ending with \n",
    "# the word bro [2]. The last example finds sequences of three or more words starting with the letter l [3].\n",
    "\n",
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "moby.findall(r\"<a> (<.*>) <man>\")\n",
    "moby.findall(r\"(<.*>) <man>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat = nltk.Text(nps_chat.words())\n",
    "chat.findall(r\"<.*> <.*> <bro>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "# It is easy to build search patterns when the linguistic phenomenon we're studying is tied to particular words. In some cases, \n",
    "# a little creativity will go a long way. For instance, searching a large text corpus for expressions of the form x and other ys \n",
    "# allows us to discover hypernyms (cf 5):\n",
    "\n",
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With enough text, this approach would give us a useful store of information about the taxonomy of objects, without the need for \n",
    "# any manual labor. However, our search results will usually contain false positives, i.e. cases that we would want to exclude. \n",
    "# For example, the result: demands and other factors suggests that demand is an instance of the type factor, but this sentence is \n",
    "# actually about wage demands. Nevertheless, we could construct our own ontology of English concepts by manually correcting the \n",
    "# output of such searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6   Normalizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'ponds',\n",
       " 'distributing',\n",
       " 'swords',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'masses',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In earlier program examples we have often converted text to lowercase before doing anything with its words, \n",
    "# e.g. set(w.lower() for w in text). By using lower(), we have normalized the text to lowercase so that the distinction between \n",
    "# The and the is ignored. Often we want to go further than this, and strip off any affixes, a task known as stemming. A further step \n",
    "# is to make sure that the resulting form is a known word in a dictionary, a task known as lemmatization. We discuss each of these in \n",
    "# turn. First, we need to define the data we will use in this section:\n",
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'DENNI',\n",
       " u':',\n",
       " u'Listen',\n",
       " u',',\n",
       " u'strang',\n",
       " u'women',\n",
       " u'lie',\n",
       " u'in',\n",
       " u'pond',\n",
       " u'distribut',\n",
       " u'sword',\n",
       " u'is',\n",
       " u'no',\n",
       " u'basi',\n",
       " u'for',\n",
       " u'a',\n",
       " u'system',\n",
       " u'of',\n",
       " u'govern',\n",
       " u'.',\n",
       " u'Suprem',\n",
       " u'execut',\n",
       " u'power',\n",
       " u'deriv',\n",
       " u'from',\n",
       " u'a',\n",
       " u'mandat',\n",
       " u'from',\n",
       " u'the',\n",
       " u'mass',\n",
       " u',',\n",
       " u'not',\n",
       " u'from',\n",
       " u'some',\n",
       " u'farcic',\n",
       " u'aquat',\n",
       " u'ceremoni',\n",
       " u'.']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemmers\n",
    "\n",
    "# NLTK includes several off-the-shelf stemmers, and if you ever need a stemmer you should use one of these in preference to \n",
    "# crafting your own using regular expressions, since these handle a wide range of irregular cases. The Porter and Lancaster \n",
    "# stemmers follow their own rules for stripping affixes. Observe that the Porter stemmer correctly handles the word lying \n",
    "# (mapping it to lie), while the Lancaster stemmer does not.\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "[porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den',\n",
       " ':',\n",
       " 'list',\n",
       " ',',\n",
       " 'strange',\n",
       " 'wom',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'bas',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'pow',\n",
       " 'der',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mand',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'som',\n",
       " 'farc',\n",
       " 'aqu',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IndexedText(object):\n",
    "\n",
    "    def __init__(self, stemmer, text):\n",
    "        self._text = text\n",
    "        self._stemmer = stemmer\n",
    "        self._index = nltk.Index((self._stem(word), i)\n",
    "                                 for (i, word) in enumerate(text))\n",
    "\n",
    "    def concordance(self, word, width=40):\n",
    "        key = self._stem(word)\n",
    "        wc = int(width/4)                # words of context\n",
    "        for i in self._index[key]:\n",
    "            lcontext = ' '.join(self._text[i-wc:i])\n",
    "            rcontext = ' '.join(self._text[i:i+wc])\n",
    "            ldisplay = '{:>{width}}'.format(lcontext[-width:], width=width)\n",
    "            rdisplay = '{:{width}}'.format(rcontext[:width], width=width)\n",
    "            print(ldisplay, rdisplay)\n",
    "\n",
    "    def _stem(self, word):\n",
    "        return self._stemmer.stem(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r king ! DENNIS : Listen , strange women', 'lying in ponds distributing swords is no')\n",
      "(' beat a very brave retreat . ROBIN : All', 'lies ! MINSTREL : [ singing ] Bravest of')\n",
      "('       Nay . Nay . Come . Come . You may', 'lie here . Oh , but you are wounded !   ')\n",
      "('doctors immediately ! No , no , please !', 'Lie down . [ clap clap ] PIGLET : Well  ')\n",
      "('ere is much danger , for beyond the cave', 'lies the Gorge of Eternal Peril , which ')\n",
      "('   you . Oh ... TIM : To the north there', 'lies a cave -- the cave of Caerbannog --')\n",
      "('h it and lived ! Bones of full fifty men', 'lie strewn about its lair . So , brave k')\n",
      "(\"not stop our fight ' til each one of you\", 'lies dead , and the Holy Grail returns t')\n"
     ]
    }
   ],
   "source": [
    "# Stemming is not a well-defined process, and we typically pick the stemmer that best suits the application we have in mind. The \n",
    "# Porter Stemmer is a good choice if you are indexing some texts and want to support search using alternative forms of words \n",
    "# (illustrated in 3.6, which uses object oriented programming techniques that are outside the scope of this book, string formatting \n",
    "# techniques to be covered in 3.9, and the enumerate() function to be explained in 4.2).\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "grail = nltk.corpus.webtext.words('grail.txt')\n",
    "text = IndexedText(porter, grail)\n",
    "text.concordance('lie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " u'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " u'pond',\n",
       " 'distributing',\n",
       " u'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " u'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "# The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. This additional checking process makes \n",
    "# the lemmatizer slower than the above stemmers. Notice that it doesn't handle lying, but it converts women to woman.\n",
    "\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The WordNet lemmatizer is a good choice if you want to compile the vocabulary of some texts and want a list of valid lemmas \n",
    "# (or lexicon headwords).\n",
    "\n",
    "# Note\n",
    "\n",
    "# Another normalization task involves identifying non-standard words including numbers, abbreviations, and dates, and mapping any \n",
    "# such tokens to a special vocabulary. For example, every decimal number could be mapped to a single token 0.0, and every acronym \n",
    "# could be mapped to AAA. This keeps the vocabulary small and improves the accuracy of many language modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7   Regular Expressions for Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenization is the task of cutting a string into identifiable linguistic units that constitute a piece of language data. Although \n",
    "# it is a fundamental task, we have been able to delay it until now because many corpora are already tokenized, and because NLTK \n",
    "# includes some tokenizers. Now that you are familiar with regular expressions, you can learn how to use them to tokenize text, \n",
    "# and to have much more control over the process.\n",
    "\n",
    "# Simple Approaches to Tokenization\n",
    "\n",
    "# The very simplest method for tokenizing text is to split on whitespace. Consider the following text from Alice's Adventures in \n",
    "# Wonderland:\n",
    "\n",
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\nthough),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\nwell',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could split this raw text on whitespace using raw.split(). To do the same using a regular expression, it is not enough to match \n",
    "# any space characters in the string [1] since this results in tokens that contain a \\n newline character; instead we need to match \n",
    "# any number of spaces, tabs, or newlines [2]:\n",
    "\n",
    "re.split(r' ', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[ \\t\\n]+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The regular expression «[ \\t\\n]+» matches one or more space, tab (\\t) or newline (\\n). Other whitespace characters, such as \n",
    "# carriage-return and form-feed should really be included too. Instead, we will use a built-in re abbreviation, \\s, which means any \n",
    "# whitespace character. The above statement can be rewritten as re.split(r'\\s+', raw).\n",
    "\n",
    "# Note\n",
    "\n",
    "# Important: Remember to prefix regular expressions with the letter r (meaning \"raw\"), which instructs the Python interpreter to \n",
    "# treat the string literally, rather than processing any backslashed characters it contains.\n",
    "\n",
    "# Splitting on whitespace gives us tokens like '(not' and 'herself,'. An alternative is to use the fact that Python provides us with \n",
    "# a character class \\w for word characters, equivalent to [a-zA-Z0-9_]. It also defines the complement of this class \\W, i.e. all \n",
    "# characters other than letters, digits or underscore. We can use \\W in a simple regular expression to split the input on anything \n",
    "# other than a word character:\n",
    "\n",
    "re.split(r'\\W+', raw)\n",
    "# Split raw text on anything other than word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe that this gives us empty strings at the start and the end (to understand why, try doing 'xx'.split('x')). We get the same \n",
    "# tokens, but without the empty strings, with re.findall(r'\\w+', raw), using a pattern that matches the words instead of the spaces. \n",
    "# Now that we're matching the words, we're in a position to extend the regular expression to cover a wider range of cases. The regular \n",
    "# expression «\\w+|\\S\\w*» will first try to match any sequence of word characters. If no match is found, it will try to match any \n",
    "# non-whitespace character (\\S is the complement of \\s) followed by further word characters. This means that punctuation is grouped \n",
    "# with any following letters (e.g. 's) but that sequences of two or more punctuation characters are separated.\n",
    "\n",
    "re.findall(r'\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
     ]
    }
   ],
   "source": [
    "# Let's generalize the \\w+ in the above expression to permit word-internal hyphens and apostrophes: «\\w+([-']\\w+)*». This expression \n",
    "# means \\w+ followed by zero or more instances of [-']\\w+; it would match hot-tempered and it's. (We need to include ?: in this \n",
    "# expression for reasons discussed earlier.) We'll also add a pattern to match quote characters so these are kept separate from the \n",
    "# text they enclose.\n",
    "\n",
    "print(re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The above expression also included «[-.(]+» which causes the double hyphen, ellipsis, and open parenthesis to be tokenized \n",
    "# separately.\n",
    "\n",
    "# 3.4 lists the regular expression character class symbols we have seen in this section, in addition to some other useful symbols.\n",
    "\n",
    "# Table 3.4:\n",
    "\n",
    "# Regular Expression Symbols\n",
    "\n",
    "# Symbol Function\n",
    "# \\b     Word boundary (zero width)\n",
    "# \\d     Any decimal digit (equivalent to [0-9])\n",
    "# \\D     Any non-digit character (equivalent to [^0-9])\n",
    "# \\s     Any whitespace character (equivalent to [ \\t\\n\\r\\f\\v])\n",
    "# \\S     Any non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v])\n",
    "# \\w     Any alphanumeric character (equivalent to [a-zA-Z0-9_])\n",
    "# \\W     Any non-alphanumeric character (equivalent to [^a-zA-Z0-9_])\n",
    "# \\t     The tab character\n",
    "# \\n     The newline character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK's Regular Expression Tokenizer\n",
    "\n",
    "# The function nltk.regexp_tokenize() is similar to re.findall() (as we've been using it for tokenization). However, \n",
    "# nltk.regexp_tokenize() is more efficient for this task, and avoids the need for special treatment of parentheses. For readability \n",
    "# we break up the regular expression over several lines and add a comment about each line. The special (?x) \"verbose flag\" tells \n",
    "# Python to strip out the embedded whitespace and comments.\n",
    "\n",
    "text = 'That U.S.A. poster-print costs $12.40...'\n",
    "pattern = r'''(?x)     # set flag to allow verbose regexps\n",
    "     ([A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''\n",
    "nltk.regexp_tokenize(text, pattern)\n",
    "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When using the verbose flag, you can no longer use ' ' to match a space character; use \\s instead. The regexp_tokenize() function \n",
    "# has an optional gaps parameter. When set to True, the regular expression specifies the gaps between tokens, as with re.split().\n",
    "\n",
    "# Note\n",
    "\n",
    "# We can evaluate a tokenizer by comparing the resulting tokens with a wordlist, and reporting any tokens that don't appear in the \n",
    "# wordlist, using set(tokens).difference(wordlist). You'll probably want to lowercase all the tokens first.\n",
    "\n",
    "# Further Issues with Tokenization\n",
    "\n",
    "# Tokenization turns out to be a far more difficult task than you might have expected. No single solution works well across-the-board, \n",
    "# and we must decide what counts as a token depending on the application domain.\n",
    "\n",
    "# When developing a tokenizer it helps to have access to raw text which has been manually tokenized, in order to compare the output \n",
    "# of your tokenizer with high-quality (or \"gold-standard\") tokens. The NLTK corpus collection includes a sample of Penn Treebank \n",
    "# data, including the raw Wall Street Journal text (nltk.corpus.treebank_raw.raw()) and the tokenized version \n",
    "# (nltk.corpus.treebank.words()).\n",
    "\n",
    "# A final issue for tokenization is the presence of contractions, such as didn't. If we are analyzing the meaning of a sentence, \n",
    "# it would probably be more useful to normalize this form to two separate forms: did and n't (or not). We can do this work with the \n",
    "# help of a lookup table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8   Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This section discusses more advanced concepts, which you may prefer to skip on the first time through this chapter.\n",
    "\n",
    "# Tokenization is an instance of a more general problem of segmentation. In this section we will look at two other instances of this \n",
    "# problem, which use radically different techniques to the ones we have seen so far in this chapter.\n",
    "\n",
    "# Sentence Segmentation\n",
    "\n",
    "# Manipulating texts at the level of individual words often presupposes the ability to divide a text into individual sentences. As \n",
    "# we have seen, some corpora already provide access at the sentence level. In the following example, we compute the average number \n",
    "# of words per sentence in the Brown Corpus:\n",
    "\n",
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\"Nonsense!\"',\n",
      " u'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
      " u'\"Why do all the clerks and navvies in the\\nrailway trains look so sad and tired, so very sad and tired?',\n",
      " u'I will\\ntell you.',\n",
      " u'It is because they know that the train is going right.',\n",
      " u'It\\nis because they know that whatever place they have taken a ticket\\nfor that place they will reach.',\n",
      " u'It is because after they have\\npassed Sloane Square they know that the next station must be\\nVictoria, and nothing but Victoria.',\n",
      " u'Oh, their wild rapture!',\n",
      " u'oh,\\ntheir eyes like stars and their souls again in Eden, if the next\\nstation were unaccountably Baker Street!\"',\n",
      " u'\"It is you who are unpoetical,\" replied the poet Syme.']\n"
     ]
    }
   ],
   "source": [
    "# In other cases, the text is only available as a stream of characters. Before tokenizing the text into words, we need to segment \n",
    "# it into sentences. NLTK facilitates this by including the Punkt sentence segmenter (Kiss & Strunk, 2006). Here is an example \n",
    "# of its use in segmenting the text of a novel. (Note that if the segmenter's internal data has been updated by the time you read \n",
    "# this, you will see different output):\n",
    "\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = nltk.sent_tokenize(text)\n",
    "pprint.pprint(sents[79:89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notice that this example is really a single sentence, reporting the speech of Mr Lucian Gregory. However, the quoted speech \n",
    "# contains several sentences, and these have been split into individual strings. This is reasonable behavior for most applications.\n",
    "\n",
    "# Sentence segmentation is difficult because period is used to mark abbreviations, and some periods simultaneously mark an \n",
    "# abbreviation and terminate a sentence, as often happens with acronyms like U.S.A.\n",
    "\n",
    "# For another approach to sentence segmentation, see 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Skipped the small section on Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Skipped 3.9   Formatting: From Lists to Strings\n",
    "# Instead of formatting the strings for display to some screen, I will store the results in a graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are many online resources for Unicode. Useful discussions of Python's facilities for handling Unicode are:\n",
    "\n",
    "#    Ned Batchelder, Pragmatic Unicode, http://nedbatchelder.com/text/unipain.html\n",
    "#    Unicode HOWTO, Python Documentation, http://docs.python.org/3/howto/unicode.html\n",
    "#    David Beazley, Mastering Python 3 I/O, http://pyvideo.org/video/289/pycon-2010--mastering-python-3-i-o\n",
    "#    Joel Spolsky, The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character \n",
    "#    Sets (No Excuses!), http://www.joelonsoftware.com/articles/Unicode.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
